{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, KFold, GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dropout, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import seaborn as sns\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Current directory:\", os.getcwd())\n",
    "#print(\"Directory contents:\", os.listdir('.'))\n",
    "\n",
    "from src.models import lstm, LSTM2\n",
    "from src.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(y):\n",
    "    enc = OneHotEncoder(sparse_output=False)  \n",
    "    return enc.fit_transform(y.reshape(-1, 1)) \n",
    "\n",
    "\n",
    "def normalization(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_shape = X.shape\n",
    "    if len(X_shape) == 3:\n",
    "        X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "        X_scaled = scaler.fit_transform(X_reshaped)\n",
    "        X = X_scaled.reshape(X_shape[0], X_shape[1], X_shape[2])\n",
    "        return X\n",
    "    else:\n",
    "        print(\"Debería ser dimenison 3\")\n",
    "\n",
    "def SMOTE_(X, y):\n",
    "    x_shape = X.shape\n",
    "    if len(x_shape) ==3:\n",
    "        X = X.reshape((x_shape[0], -1))\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "    if len(x_shape) == 3:\n",
    "        X = X.reshape((-1, x_shape[1], x_shape[2]))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "speech_unprocessed_path = r'data/Audio_Speech_Actors_01-24/*/*.wav'\n",
    "song_unprocessed_path = r'data/Audio_Song_Actors_01-24/*/*.wav'\n",
    "\n",
    "speech_dataset_path = \"data/speech_dataset.npy\"\n",
    "song_dataset_path = \"data/song_dataset.npy\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Dataloader():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        # super(AudioDataloader, self).__init__(*args, **kwargs)\n",
    "        # self.collate_fn = collate_fn\n",
    "\n",
    "    def segment_audio(self, audio, num_parts):\n",
    "        segment_length = len(audio) // num_parts\n",
    "        segments = [audio[i * segment_length:(i + 1) * segment_length] for i in range(num_parts)]\n",
    "        \n",
    "        # Si el audio no se divide exactamente en partes iguales, añade el residuo al último segmento\n",
    "        if len(audio) % num_parts != 0:\n",
    "            segments[-1] = np.concatenate([segments[-1], audio[num_parts * segment_length:]])\n",
    "        \n",
    "        return segments\n",
    "\n",
    "\n",
    "    def process_dataset(self, data_path, save_path, n_segments = 1):\n",
    "        files = glob(data_path)\n",
    "\n",
    "        smile = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        )\n",
    "        extracted_features = smile.process_files(files)\n",
    "\n",
    "        x_ = extracted_features.values\n",
    "        y_ = np.array([int(os.path.basename(path).split('-')[2]) for path in files])\n",
    "        y_reshaped = y_[:, np.newaxis] \n",
    "        dataset = np.concatenate((x_, y_reshaped), axis=1)\n",
    "        \n",
    "        actors = np.array([int(os.path.dirname(path)[-2:]) for path in files])\n",
    "        np.save(save_path, dataset)\n",
    "        actors_save_path = f\"data/{os.path.basename(save_path).split('_')[0]}_actors.npy\"\n",
    "        np.save(actors_save_path, actors)\n",
    "\n",
    "        #np.savez(save_path, array1=dataset, array2=actors)\n",
    "        return np.load(save_path), np.load(actors_save_path)\n",
    "    \n",
    "    def get_dataset(self, dataset_path_list):\n",
    "        dataset = np.load(dataset_path_list[0])\n",
    "        actors_path_list = f\"{os.path.dirname(dataset_path_list[0])}/{os.path.basename(dataset_path_list[0]).split('_')[0]}_actors{os.path.splitext(dataset_path_list[0])[1]}\"\n",
    "        actors = np.load(actors_path_list)\n",
    "        for i in range(1, len(dataset_path_list)):\n",
    "            dataset = np.concatenate((dataset, np.load(dataset_path_list[i])))\n",
    "            actors_path_list = f\"{os.path.dirname(dataset_path_list[i])}/{os.path.basename(dataset_path_list[i]).split('_')[0]}_actors{os.path.splitext(dataset_path_list[i])[1]}\"\n",
    "            actors = np.concatenate((actors, np.load(actors_path_list)))\n",
    "        x = dataset[:, :-1]\n",
    "        y = dataset[:,-1]\n",
    "\n",
    "        \n",
    "        return x, y, actors\n",
    "\n",
    "    def split_dataset(self, x, y, actors = [], n_splits =1):\n",
    "        if len(actors) >0:\n",
    "            gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "            train_idx, test_idx = next(gss.split(x, y, actors))\n",
    "            X_train, X_test = x[train_idx], x[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            actors_train = actors[train_idx]\n",
    "            actors_test = actors[test_idx]\n",
    "       \n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, shuffle=42)\n",
    "            actors_train = None\n",
    "            actors_test = None\n",
    "        return X_train, X_test, y_train, y_test, actors_train, actors_test\n",
    "\n",
    "DL = Dataloader()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def calculate_energy(audio, frame_size, hop_length):\n",
    "    energy = np.array([np.sum(np.abs(audio[i:i+frame_size]**2)) for i in range(0, len(audio), hop_length)])\n",
    "    return energy\n",
    "\n",
    "def trim_silence(audio, frame_size=1024, hop_length=512, energy_threshold=0.01):\n",
    "    energy = calculate_energy(audio, frame_size, hop_length)\n",
    "    frames = np.nonzero(energy > energy_threshold)[0]\n",
    "    \n",
    "    if len(frames) > 0:\n",
    "        start = max(0, frames[0] * hop_length)\n",
    "        end = min(len(audio), frames[-1] * hop_length + frame_size)\n",
    "        return audio[start:end]\n",
    "    else:\n",
    "        return audio  # No recortar si no se encuentran frames con energía suficiente\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tendria qeu hacer el split de train y test antes para que siempre sea el mismo test\n",
    "\"\"\"\n",
    "class AudioProcessor:\n",
    "    def segment_audio(self, audio, num_parts, frame_size=1024, hop_length=512, energy_threshold=0.01):\n",
    "        # Recortar los silencios basados en la energía\n",
    "        #print(\"\")\n",
    "        #print(\"audio largo\", len(audio))\n",
    "        trimmed_audio = trim_silence(audio, frame_size, hop_length, energy_threshold)\n",
    "        #print(\"trimmed largo\", len(trimmed_audio))\n",
    "        print(\"Largo trimmed\", len(trimmed_audio))\n",
    "        if len(trimmed_audio) < 10000:\n",
    "            plt.plot(audio)\n",
    "            plt.show()\n",
    "            print(\"Largo trimmed\", len(trimmed_audio))\n",
    "            plt.plot(trimmed_audio)\n",
    "            plt.show()\n",
    "\n",
    "        # Segmentar el audio recortado\n",
    "        segment_length = len(trimmed_audio) // num_parts\n",
    "        segments = []\n",
    "\n",
    "        for i in range(num_parts):\n",
    "            start = i * segment_length\n",
    "            end = (i + 1) * segment_length\n",
    "            segment = trimmed_audio[start:end]\n",
    "            \n",
    "            # Si el segmento es demasiado corto, rellenar con ceros\n",
    "            if len(segment) < segment_length:\n",
    "                segment = np.pad(segment, (0, segment_length - len(segment)), 'constant')\n",
    "            \n",
    "            segments.append(segment)\n",
    "        \n",
    "        return segments\n",
    "\n",
    "\n",
    "\n",
    "    def segment_audio2(self, audio, num_parts, top_db=30):\n",
    "        # Recortar los silencios\n",
    "        #print(\"\")\n",
    "        #print(\"audio largo\", len(audio))\n",
    "        trimmed_audio, _ = librosa.effects.trim(audio, top_db=top_db)\n",
    "\n",
    "        #print(\"trimmed largo\", len(trimmed_audio))\n",
    "        if len(trimmed_audio) == len(audio):\n",
    "            plt.plot(audio)\n",
    "            plt.show()\n",
    "            print(audio)\n",
    "            plt.plot(trimmed_audio)\n",
    "            plt.show()\n",
    "        segment_length = len(trimmed_audio) // num_parts\n",
    "        segments = []\n",
    "\n",
    "        for i in range(num_parts):\n",
    "            start = i * segment_length\n",
    "            end = (i + 1) * segment_length\n",
    "            segment = trimmed_audio[start:end]\n",
    "            #print(\"start\", start)\n",
    "            #print(\"end\", end)\n",
    "            \n",
    "            # Si el segmento es demasiado corto, rellenar con ceros\n",
    "            if len(segment) < segment_length:\n",
    "                segment = np.pad(segment, (0, segment_length - len(segment)), 'constant')\n",
    "            \n",
    "            segments.append(segment)\n",
    "        \n",
    "        return segments\n",
    "\n",
    "\n",
    "    def process_dataset(self, data_path, save_path, n_segments=1):\n",
    "\n",
    "        files = glob(data_path)\n",
    "        #files = [data_path]\n",
    "\n",
    "        smile = opensmile.Smile(\n",
    "            feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "            feature_level=opensmile.FeatureLevel.Functionals,\n",
    "        )\n",
    "\n",
    "        features_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        for file in files:\n",
    "            # Cargar y segmentar el audio\n",
    "            audio, sr = sf.read(file)\n",
    "            print(file)\n",
    "            segments = self.segment_audio2(audio, n_segments) ## CAMBIO sacar el 2\n",
    "\n",
    "            for segment in segments:\n",
    "                #print(len(segment))\n",
    "                segment_file = 'temp_segment.wav'\n",
    "                sf.write(segment_file, segment, sr)\n",
    "                features = smile.process_file(segment_file)\n",
    "                features_list.append(features.values.flatten())\n",
    "                labels_list.append(int(os.path.basename(file).split('-')[2]))\n",
    "\n",
    "        x_ = np.array(features_list)\n",
    "        y_ = np.array(labels_list)\n",
    "        \n",
    "        y_reshaped = y_[:, np.newaxis]\n",
    "        dataset = np.concatenate((x_, y_reshaped), axis=1)\n",
    "\n",
    "        actors = np.array([int(os.path.dirname(path)[-2:]) for path in files])\n",
    "        np.save(save_path, dataset)\n",
    "        print('guardo el dataset en,', save_path)\n",
    "        actors_save_path = define_actors_path(save_path)\n",
    "        np.save(actors_save_path, actors)\n",
    "\n",
    "        return np.load(save_path)\n",
    "\n",
    "    def get_dataset(self, dataset_path_list):\n",
    "        n_segments = int(os.path.basename(dataset_path_list[0])[0])\n",
    "        dataset = np.load(dataset_path_list[0])\n",
    "        actors_path = define_actors_path(dataset_path_list[0])\n",
    "        print(actors_path)\n",
    "        actors = np.load(actors_path)\n",
    "        \n",
    "        for i in range(1, len(dataset_path_list)):\n",
    "            dataset = np.concatenate((dataset, np.load(dataset_path_list[i])))\n",
    "            actors_path = actors_path = define_actors_path(dataset_path_list[i])\n",
    "            actors = np.concatenate((actors, np.load(actors_path)))\n",
    "\n",
    "        # Extraer características (x) y etiquetas (y)\n",
    "        x = dataset[:, :-1]\n",
    "        y = dataset[:, -1]\n",
    "        # Realizar reshape de x\n",
    "        num_samples = x.shape[0] // n_segments\n",
    "        num_features = x.shape[1]\n",
    "        x = x.reshape(num_samples, n_segments, num_features)\n",
    "        \n",
    "        # Realizar reshape de y\n",
    "        y = y.reshape(num_samples, n_segments).mean(axis=1).astype(int)\n",
    "        \n",
    "        # Ajustar actores al nuevo número de muestras\n",
    "        #actors_reshaped = actors.reshape(num_samples, n_segments).mean(axis=1).astype(int)\n",
    "\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        print(actors.shape)\n",
    "        return x, y, actors\n",
    "\n",
    "    def split_dataset(self, x, y, test_size = 0.2, actors=[]):\n",
    "        if len(actors) > 0:\n",
    "            gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "            train_idx, test_idx = next(gss.split(x, y, actors))\n",
    "            X_train, X_test = x[train_idx], x[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            actors_train = actors[train_idx]\n",
    "            print(\"ACTORES\", len(np.unique(actors_train)))\n",
    "            actors_test = actors[test_idx]\n",
    "\n",
    "            train_shuffle_idx = np.random.permutation(len(X_train))\n",
    "            test_shuffle_idx = np.random.permutation(len(X_test))\n",
    "            \n",
    "            X_train, y_train, actors_train = X_train[train_shuffle_idx], y_train[train_shuffle_idx], actors_train[train_shuffle_idx]\n",
    "            X_test, y_test, actors_test = X_test[test_shuffle_idx], y_test[test_shuffle_idx], actors_test[test_shuffle_idx]\n",
    "\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "            actors_train = None\n",
    "            actors_test = None\n",
    "\n",
    "        return X_train, X_test, y_train, y_test, actors_train, actors_test\n",
    "    \n",
    "def define_actors_path(dataset_path):\n",
    "    file_name = os.path.basename(dataset_path).split('_')\n",
    "    file_name[-1] = file_name[-1].split('.')[0]\n",
    "    actors_save_path = f\"data/{file_name[0]}_{file_name[1]}_actors_{file_name[3]}.npy\"\n",
    "    return actors_save_path\n",
    "\n",
    "\n",
    "AP = AudioProcessor()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se inicializo\n"
     ]
    }
   ],
   "source": [
    "DL = DataLoader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\Audio_Speech_Actors_01-24\\\\Actor_09\\\\03-01-02-01-02-01-09(1).wav'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech1_dataset_dev = \"data/1part_Speech_dataset_dev.npy\"\n",
    "speech2_dataset_dev = \"data/2part_Speech_dataset_dev.npy\"\n",
    "speech4_dataset_dev = \"data/4part_Speech_dataset_dev.npy\"\n",
    "speech8_dataset_dev = \"data/8part_Speech_dataset_dev.npy\"\n",
    "song1_dataset_dev = \"data/1part_Song_dataset_dev.npy\"\n",
    "song2_dataset_dev = \"data/2part_Song_dataset_dev.npy\"\n",
    "song4_dataset_dev = \"data/4part_Song_dataset_dev.npy\"\n",
    "song8_dataset_dev = \"data/8part_Song_dataset_dev.npy\"\n",
    "\n",
    "speech1_dataset_test = \"data/1part_Speech_dataset_test.npy\"\n",
    "speech2_dataset_test = \"data/2part_Speech_dataset_test.npy\"\n",
    "speech4_dataset_test = \"data/4part_Speech_dataset_test.npy\"\n",
    "speech8_dataset_test = \"data/8part_Speech_dataset_test.npy\"\n",
    "song1_dataset_test = \"data/1part_Song_dataset_test.npy\"\n",
    "song2_dataset_test = \"data/2part_Song_dataset_test.npy\"\n",
    "song4_dataset_test = \"data/4part_Song_dataset_test.npy\"\n",
    "song8_dataset_test = \"data/8part_Song_dataset_test.npy\"\n",
    "\n",
    "path_speech_dev = r\"data\\Audio_Speech_Actors_01-24\\*\\*\"\n",
    "path_song_dev = r\"data\\Audio_Song_Actors_01-24\\*\\*\"\n",
    "path_speech_test = r\"data/data_test/speech/*/*\"\n",
    "path_song_test = r\"data/data_test/song/*/*\"\n",
    "\n",
    "\n",
    "\"data\\Audio_Speech_Actors_01-24\\Actor_09\\03-01-04-01-01-01-09.wav\"\n",
    "r\"data\\Audio_Speech_Actors_01-24\\Actor_09\\03-01-02-01-02-01-09(1).wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guardo el dataset en, data/4part_Song_dataset_test.npy\n",
      "guardo los actores en, data/4part_Song_actors_test.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.11422253e+01,  3.99349108e-02,  3.00285034e+01, ...,\n",
       "         0.00000000e+00, -3.60493202e+01,  1.00000000e+00],\n",
       "       [ 3.41217766e+01,  6.97675534e-03,  3.38987045e+01, ...,\n",
       "         0.00000000e+00, -3.60063057e+01,  1.00000000e+00],\n",
       "       [ 3.14534035e+01,  2.33630072e-02,  3.10289383e+01, ...,\n",
       "         0.00000000e+00, -3.34794579e+01,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 3.50479050e+01,  1.02217672e-02,  3.47092400e+01, ...,\n",
       "         0.00000000e+00, -3.55332832e+01,  6.00000000e+00],\n",
       "       [ 3.20958290e+01,  2.54291166e-02,  3.13136368e+01, ...,\n",
       "         0.00000000e+00, -3.31812820e+01,  6.00000000e+00],\n",
       "       [ 3.19794197e+01,  1.40045602e-02,  3.16250820e+01, ...,\n",
       "         0.00000000e+00, -3.72598381e+01,  6.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DL.process_dataset(path_song_test, song4_dataset_test, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/4part_Speech_actors_dev.npy\n",
      "X shape (1948, 4, 88)\n",
      "y shape (1948,)\n",
      "actors shape (1948,)\n",
      "data/4part_Speech_actors_dev.npy\n",
      "X shape (1376, 4, 88)\n",
      "y shape (1376,)\n",
      "actors shape (1376,)\n",
      "Distribución de clases antes de SMOTE train: Counter({2: 238, 3: 238, 6: 232, 4: 232, 5: 232, 8: 123, 7: 121, 1: 116})\n",
      "Distribución de clases antes de SMOTE valid: Counter({4: 64, 3: 64, 2: 64, 5: 64, 6: 64, 7: 32, 8: 32, 1: 32})\n",
      "Distribución de clases antes de SMOTE test: Counter({2: 198, 3: 198, 4: 192, 5: 192, 6: 192, 8: 155, 7: 153, 1: 96})\n",
      "Distribución de clases despues de SMOTE train: Counter({6: 238, 2: 238, 8: 238, 1: 238, 4: 238, 3: 238, 5: 238, 7: 238})\n",
      "Distribución de clases despues de SMOTE train: Counter({4: 64, 3: 64, 2: 64, 5: 64, 6: 64, 7: 32, 8: 32, 1: 32})\n",
      "Distribución de clases despues de SMOTE train: Counter({2: 198, 3: 198, 4: 192, 5: 192, 6: 192, 8: 155, 7: 153, 1: 96})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "(1904, 4, 88)\n",
      "(416, 4, 88)\n"
     ]
    }
   ],
   "source": [
    "X_dev, y_dev, actors_dev = DL.get_dataset([speech4_dataset_dev, song4_dataset_dev])\n",
    "X_train, X_valid, y_train, y_valid, actors_train, actors_valid = DL.split_dataset(X_dev, y_dev, test_size=0.2, actors=actors_dev)\n",
    "X_test, y_test, actors_test = DL.get_dataset([speech4_dataset_dev, song4_dataset_test])\n",
    "\n",
    "print('Distribución de clases antes de SMOTE train:', Counter(y_train))\n",
    "print('Distribución de clases antes de SMOTE valid:', Counter(y_valid))\n",
    "print('Distribución de clases antes de SMOTE test:', Counter(y_test))\n",
    "\n",
    "\n",
    "X_train, y_train = SMOTE_(X_train, y_train)\n",
    "#X_valid, y_valid = SMOTE_(X_valid, y_valid)\n",
    "#X_test, y_test = SMOTE_(X_test, y_test)\n",
    "\n",
    "\n",
    "print('Distribución de clases despues de SMOTE train:', Counter(y_train))\n",
    "print('Distribución de clases despues de SMOTE train:', Counter(y_valid))\n",
    "print('Distribución de clases despues de SMOTE train:', Counter(y_test))\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"s\")\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "\n",
    "X_train = normalization(X_train)\n",
    "X_valid = normalization(X_valid)\n",
    "X_test = normalization(X_test)\n",
    "\n",
    "y_train_ohe  = one_hot_encoder(y_train)\n",
    "y_valid_ohe = one_hot_encoder(y_valid)\n",
    "y_test_ohe = one_hot_encoder(y_test)\n",
    "y_dev_ohe = one_hot_encoder(y_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM con keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_validate_rnn(X, y, groups, n_splits=5, epochs=25, batch_size=32, learning_rate = 0.001, dropout = 0.5):\n",
    "    valid_loss = []\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    fold_no = 1\n",
    "    print(y.shape)\n",
    "    for train_index, val_index in gkf.split(X, y, groups):\n",
    "        print(f'Training fold {fold_no} ...')\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "        X_val, y_val = shuffle(X_val, y_val, random_state=42)\n",
    "\n",
    "        print(y_train)\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "        print(X_val.shape)\n",
    "        print(y_val.shape)\n",
    "        model = lstm.rnnLSTM(X_train, y_train, lr= learning_rate, dropout_rate=dropout)\n",
    "        model.train(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "        print(f'Fold {fold_no} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "        valid_loss.append(val_loss)\n",
    "        fold_no += 1\n",
    "    return np.mean(valid_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1948, 8)\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 7s 24ms/step - loss: 3.2607 - accuracy: 0.1522 - val_loss: 3.1581 - val_accuracy: 0.2778\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 3.0904 - accuracy: 0.2287 - val_loss: 3.0085 - val_accuracy: 0.2487\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.9445 - accuracy: 0.2223 - val_loss: 2.8671 - val_accuracy: 0.2407\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 2.8137 - accuracy: 0.2439 - val_loss: 2.7435 - val_accuracy: 0.2328\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 2s 15ms/step - loss: 2.7049 - accuracy: 0.2580 - val_loss: 2.6420 - val_accuracy: 0.2222\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 2.5927 - accuracy: 0.2586 - val_loss: 2.5453 - val_accuracy: 0.2698\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 2.5154 - accuracy: 0.2611 - val_loss: 2.4685 - val_accuracy: 0.2778\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 2.4513 - accuracy: 0.2764 - val_loss: 2.3991 - val_accuracy: 0.2751\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 2.3866 - accuracy: 0.2720 - val_loss: 2.3570 - val_accuracy: 0.2566\n",
      "Epoch 10/25\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 2.3255 - accuracy: 0.2796 - val_loss: 2.2972 - val_accuracy: 0.2857\n",
      "Epoch 11/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.2891 - accuracy: 0.2771 - val_loss: 2.2554 - val_accuracy: 0.2725\n",
      "Epoch 12/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.2345 - accuracy: 0.2841 - val_loss: 2.2125 - val_accuracy: 0.2937\n",
      "Epoch 13/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.1931 - accuracy: 0.2873 - val_loss: 2.1524 - val_accuracy: 0.3042\n",
      "Epoch 14/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.1610 - accuracy: 0.2943 - val_loss: 2.1259 - val_accuracy: 0.3042\n",
      "Epoch 15/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.1202 - accuracy: 0.2987 - val_loss: 2.1073 - val_accuracy: 0.3095\n",
      "Epoch 16/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0813 - accuracy: 0.3146 - val_loss: 2.0872 - val_accuracy: 0.2910\n",
      "Epoch 17/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0541 - accuracy: 0.3134 - val_loss: 2.0510 - val_accuracy: 0.3122\n",
      "Epoch 18/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0317 - accuracy: 0.3070 - val_loss: 2.0284 - val_accuracy: 0.3175\n",
      "Epoch 19/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0208 - accuracy: 0.2962 - val_loss: 2.0285 - val_accuracy: 0.3280\n",
      "Epoch 20/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9899 - accuracy: 0.3134 - val_loss: 2.0071 - val_accuracy: 0.3122\n",
      "Epoch 21/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9743 - accuracy: 0.3121 - val_loss: 1.9803 - val_accuracy: 0.3228\n",
      "Epoch 22/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9427 - accuracy: 0.3204 - val_loss: 1.9721 - val_accuracy: 0.3122\n",
      "Epoch 23/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9276 - accuracy: 0.3363 - val_loss: 1.9717 - val_accuracy: 0.3095\n",
      "Epoch 24/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9107 - accuracy: 0.3229 - val_loss: 1.9546 - val_accuracy: 0.3148\n",
      "Epoch 25/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.8908 - accuracy: 0.3363 - val_loss: 1.9531 - val_accuracy: 0.3122\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9531 - accuracy: 0.3122\n",
      "Fold 1 - Validation Loss: 1.9531, Validation Accuracy: 0.3122\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 16ms/step - loss: 3.2701 - accuracy: 0.1601 - val_loss: 3.1547 - val_accuracy: 0.1887\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 3.0860 - accuracy: 0.2166 - val_loss: 2.9917 - val_accuracy: 0.2421\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.9333 - accuracy: 0.2362 - val_loss: 2.8441 - val_accuracy: 0.2579\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.8182 - accuracy: 0.2313 - val_loss: 2.7214 - val_accuracy: 0.2642\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.6955 - accuracy: 0.2607 - val_loss: 2.6133 - val_accuracy: 0.2579\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.5960 - accuracy: 0.2681 - val_loss: 2.5241 - val_accuracy: 0.3050\n",
      "Epoch 7/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.5181 - accuracy: 0.2718 - val_loss: 2.4358 - val_accuracy: 0.2830\n",
      "Epoch 8/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.4531 - accuracy: 0.2785 - val_loss: 2.3984 - val_accuracy: 0.2830\n",
      "Epoch 9/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.3900 - accuracy: 0.2736 - val_loss: 2.3121 - val_accuracy: 0.2925\n",
      "Epoch 10/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.3302 - accuracy: 0.2945 - val_loss: 2.2670 - val_accuracy: 0.3113\n",
      "Epoch 11/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2733 - accuracy: 0.2945 - val_loss: 2.2187 - val_accuracy: 0.2893\n",
      "Epoch 12/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2273 - accuracy: 0.3018 - val_loss: 2.1865 - val_accuracy: 0.2987\n",
      "Epoch 13/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1727 - accuracy: 0.3123 - val_loss: 2.1570 - val_accuracy: 0.2799\n",
      "Epoch 14/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1497 - accuracy: 0.3258 - val_loss: 2.1269 - val_accuracy: 0.3050\n",
      "Epoch 15/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1157 - accuracy: 0.3264 - val_loss: 2.1115 - val_accuracy: 0.3019\n",
      "Epoch 16/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0761 - accuracy: 0.3239 - val_loss: 2.0723 - val_accuracy: 0.2736\n",
      "Epoch 17/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0490 - accuracy: 0.3233 - val_loss: 2.0419 - val_accuracy: 0.2830\n",
      "Epoch 18/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0149 - accuracy: 0.3067 - val_loss: 2.0141 - val_accuracy: 0.3113\n",
      "Epoch 19/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9983 - accuracy: 0.3227 - val_loss: 1.9901 - val_accuracy: 0.3176\n",
      "Epoch 20/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9643 - accuracy: 0.3380 - val_loss: 1.9700 - val_accuracy: 0.3019\n",
      "Epoch 21/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9477 - accuracy: 0.3215 - val_loss: 1.9523 - val_accuracy: 0.3333\n",
      "Epoch 22/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9118 - accuracy: 0.3485 - val_loss: 1.9576 - val_accuracy: 0.3145\n",
      "Epoch 23/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9151 - accuracy: 0.3399 - val_loss: 1.9415 - val_accuracy: 0.2925\n",
      "Epoch 24/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.8926 - accuracy: 0.3540 - val_loss: 1.9308 - val_accuracy: 0.2925\n",
      "Epoch 25/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.8588 - accuracy: 0.3479 - val_loss: 1.9331 - val_accuracy: 0.2925\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9331 - accuracy: 0.2925\n",
      "Fold 2 - Validation Loss: 1.9331, Validation Accuracy: 0.2925\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 3.2695 - accuracy: 0.1708 - val_loss: 3.1735 - val_accuracy: 0.2333\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1042 - accuracy: 0.2369 - val_loss: 3.0387 - val_accuracy: 0.2024\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.9682 - accuracy: 0.2552 - val_loss: 2.9184 - val_accuracy: 0.2357\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8505 - accuracy: 0.2480 - val_loss: 2.8183 - val_accuracy: 0.2381\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7286 - accuracy: 0.2736 - val_loss: 2.7405 - val_accuracy: 0.2429\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6449 - accuracy: 0.2703 - val_loss: 2.6651 - val_accuracy: 0.2667\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5864 - accuracy: 0.2683 - val_loss: 2.5956 - val_accuracy: 0.2857\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5073 - accuracy: 0.2775 - val_loss: 2.5334 - val_accuracy: 0.2643\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4420 - accuracy: 0.2866 - val_loss: 2.4900 - val_accuracy: 0.2762\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4049 - accuracy: 0.2860 - val_loss: 2.4138 - val_accuracy: 0.2810\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3477 - accuracy: 0.2873 - val_loss: 2.3788 - val_accuracy: 0.2810\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3003 - accuracy: 0.2847 - val_loss: 2.3246 - val_accuracy: 0.2881\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2591 - accuracy: 0.3050 - val_loss: 2.2895 - val_accuracy: 0.2810\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2133 - accuracy: 0.2932 - val_loss: 2.2562 - val_accuracy: 0.3000\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1786 - accuracy: 0.3154 - val_loss: 2.2118 - val_accuracy: 0.3024\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1422 - accuracy: 0.3181 - val_loss: 2.1821 - val_accuracy: 0.3071\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1134 - accuracy: 0.3168 - val_loss: 2.1586 - val_accuracy: 0.3238\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0946 - accuracy: 0.3200 - val_loss: 2.1440 - val_accuracy: 0.2905\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0491 - accuracy: 0.3246 - val_loss: 2.0957 - val_accuracy: 0.3310\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0322 - accuracy: 0.3331 - val_loss: 2.1024 - val_accuracy: 0.3143\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0108 - accuracy: 0.3403 - val_loss: 2.0587 - val_accuracy: 0.3262\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9812 - accuracy: 0.3266 - val_loss: 2.0362 - val_accuracy: 0.3262\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9611 - accuracy: 0.3338 - val_loss: 2.0232 - val_accuracy: 0.3190\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9389 - accuracy: 0.3429 - val_loss: 1.9957 - val_accuracy: 0.3119\n",
      "Epoch 25/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9262 - accuracy: 0.3351 - val_loss: 1.9858 - val_accuracy: 0.3167\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.9858 - accuracy: 0.3167\n",
      "Fold 3 - Validation Loss: 1.9858, Validation Accuracy: 0.3167\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 3.2652 - accuracy: 0.1580 - val_loss: 3.1571 - val_accuracy: 0.2284\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 3.0989 - accuracy: 0.1965 - val_loss: 3.0078 - val_accuracy: 0.2428\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9477 - accuracy: 0.2500 - val_loss: 2.8611 - val_accuracy: 0.2452\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8183 - accuracy: 0.2422 - val_loss: 2.7270 - val_accuracy: 0.2740\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6999 - accuracy: 0.2644 - val_loss: 2.6185 - val_accuracy: 0.2837\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5989 - accuracy: 0.2585 - val_loss: 2.5349 - val_accuracy: 0.2837\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5184 - accuracy: 0.2807 - val_loss: 2.4633 - val_accuracy: 0.2861\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4411 - accuracy: 0.2657 - val_loss: 2.4018 - val_accuracy: 0.2861\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3881 - accuracy: 0.2813 - val_loss: 2.3494 - val_accuracy: 0.2837\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3316 - accuracy: 0.2905 - val_loss: 2.2922 - val_accuracy: 0.2909\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2888 - accuracy: 0.3003 - val_loss: 2.2815 - val_accuracy: 0.3029\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2452 - accuracy: 0.2852 - val_loss: 2.2262 - val_accuracy: 0.2933\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1959 - accuracy: 0.2970 - val_loss: 2.1903 - val_accuracy: 0.2957\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1651 - accuracy: 0.2911 - val_loss: 2.1620 - val_accuracy: 0.3005\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1308 - accuracy: 0.3048 - val_loss: 2.1343 - val_accuracy: 0.2933\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1057 - accuracy: 0.3166 - val_loss: 2.1037 - val_accuracy: 0.2957\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0662 - accuracy: 0.3094 - val_loss: 2.0879 - val_accuracy: 0.2909\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0369 - accuracy: 0.3133 - val_loss: 2.0528 - val_accuracy: 0.3077\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0068 - accuracy: 0.3192 - val_loss: 2.0410 - val_accuracy: 0.3077\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9931 - accuracy: 0.3205 - val_loss: 2.0097 - val_accuracy: 0.2957\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9680 - accuracy: 0.3133 - val_loss: 2.0130 - val_accuracy: 0.3245\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9438 - accuracy: 0.3368 - val_loss: 1.9871 - val_accuracy: 0.3077\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9343 - accuracy: 0.3185 - val_loss: 1.9461 - val_accuracy: 0.3173\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9070 - accuracy: 0.3309 - val_loss: 1.9289 - val_accuracy: 0.2981\n",
      "Epoch 25/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8945 - accuracy: 0.3322 - val_loss: 1.9265 - val_accuracy: 0.3101\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.9265 - accuracy: 0.3101\n",
      "Fold 4 - Validation Loss: 1.9265, Validation Accuracy: 0.3101\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 3.2828 - accuracy: 0.1456 - val_loss: 3.1748 - val_accuracy: 0.2260\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0948 - accuracy: 0.2076 - val_loss: 3.0203 - val_accuracy: 0.2188\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9256 - accuracy: 0.2461 - val_loss: 2.8738 - val_accuracy: 0.2548\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7901 - accuracy: 0.2611 - val_loss: 2.7651 - val_accuracy: 0.2380\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6770 - accuracy: 0.2689 - val_loss: 2.6685 - val_accuracy: 0.2668\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5846 - accuracy: 0.2826 - val_loss: 2.6016 - val_accuracy: 0.2524\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5030 - accuracy: 0.2826 - val_loss: 2.5400 - val_accuracy: 0.2524\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4423 - accuracy: 0.2813 - val_loss: 2.4893 - val_accuracy: 0.2452\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3748 - accuracy: 0.2911 - val_loss: 2.4449 - val_accuracy: 0.2452\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3182 - accuracy: 0.2937 - val_loss: 2.3976 - val_accuracy: 0.2500\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2666 - accuracy: 0.3003 - val_loss: 2.3540 - val_accuracy: 0.2572\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2139 - accuracy: 0.3048 - val_loss: 2.3488 - val_accuracy: 0.2356\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1893 - accuracy: 0.3094 - val_loss: 2.2896 - val_accuracy: 0.2572\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1420 - accuracy: 0.3094 - val_loss: 2.2447 - val_accuracy: 0.2764\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1062 - accuracy: 0.3172 - val_loss: 2.2398 - val_accuracy: 0.2524\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0819 - accuracy: 0.3257 - val_loss: 2.2567 - val_accuracy: 0.2428\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0565 - accuracy: 0.3120 - val_loss: 2.1562 - val_accuracy: 0.2524\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0288 - accuracy: 0.3303 - val_loss: 2.1717 - val_accuracy: 0.2500\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9964 - accuracy: 0.3309 - val_loss: 2.0988 - val_accuracy: 0.2788\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9838 - accuracy: 0.3322 - val_loss: 2.1312 - val_accuracy: 0.2308\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9563 - accuracy: 0.3414 - val_loss: 2.1253 - val_accuracy: 0.2380\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9401 - accuracy: 0.3322 - val_loss: 2.1265 - val_accuracy: 0.2668\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.0988 - accuracy: 0.2788\n",
      "Fold 5 - Validation Loss: 2.0988, Validation Accuracy: 0.2788\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 5s 17ms/step - loss: 3.2874 - accuracy: 0.1561 - val_loss: 3.2022 - val_accuracy: 0.1614\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 3.1384 - accuracy: 0.1510 - val_loss: 3.0762 - val_accuracy: 0.2116\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 3.0123 - accuracy: 0.1892 - val_loss: 2.9611 - val_accuracy: 0.2222\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.9032 - accuracy: 0.2038 - val_loss: 2.8506 - val_accuracy: 0.2354\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.8000 - accuracy: 0.2280 - val_loss: 2.7482 - val_accuracy: 0.2143\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.6994 - accuracy: 0.2344 - val_loss: 2.6382 - val_accuracy: 0.2407\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.6040 - accuracy: 0.2490 - val_loss: 2.5512 - val_accuracy: 0.2513\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.5390 - accuracy: 0.2541 - val_loss: 2.4668 - val_accuracy: 0.2513\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.4505 - accuracy: 0.2726 - val_loss: 2.4051 - val_accuracy: 0.2460\n",
      "Epoch 10/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.3909 - accuracy: 0.2790 - val_loss: 2.3353 - val_accuracy: 0.2646\n",
      "Epoch 11/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.3323 - accuracy: 0.2873 - val_loss: 2.2987 - val_accuracy: 0.2698\n",
      "Epoch 12/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.2911 - accuracy: 0.2936 - val_loss: 2.2389 - val_accuracy: 0.2646\n",
      "Epoch 13/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.2443 - accuracy: 0.2815 - val_loss: 2.2117 - val_accuracy: 0.2751\n",
      "Epoch 14/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.2110 - accuracy: 0.2949 - val_loss: 2.1603 - val_accuracy: 0.2751\n",
      "Epoch 15/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.1674 - accuracy: 0.3057 - val_loss: 2.1369 - val_accuracy: 0.2910\n",
      "Epoch 16/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.1538 - accuracy: 0.2904 - val_loss: 2.1372 - val_accuracy: 0.2672\n",
      "Epoch 17/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.1314 - accuracy: 0.3076 - val_loss: 2.0807 - val_accuracy: 0.3042\n",
      "Epoch 18/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0959 - accuracy: 0.3051 - val_loss: 2.0709 - val_accuracy: 0.2989\n",
      "Epoch 19/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0667 - accuracy: 0.3057 - val_loss: 2.0479 - val_accuracy: 0.2989\n",
      "Epoch 20/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0524 - accuracy: 0.3025 - val_loss: 2.0279 - val_accuracy: 0.2910\n",
      "Epoch 21/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0236 - accuracy: 0.3159 - val_loss: 2.0037 - val_accuracy: 0.3042\n",
      "Epoch 22/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0155 - accuracy: 0.3185 - val_loss: 1.9759 - val_accuracy: 0.3069\n",
      "Epoch 23/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9941 - accuracy: 0.3089 - val_loss: 1.9782 - val_accuracy: 0.2910\n",
      "Epoch 24/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9720 - accuracy: 0.3166 - val_loss: 1.9524 - val_accuracy: 0.3148\n",
      "Epoch 25/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9651 - accuracy: 0.3083 - val_loss: 1.9467 - val_accuracy: 0.2937\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9467 - accuracy: 0.2937\n",
      "Fold 1 - Validation Loss: 1.9467, Validation Accuracy: 0.2937\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 17ms/step - loss: 3.2740 - accuracy: 0.1509 - val_loss: 3.1695 - val_accuracy: 0.2233\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 3.1186 - accuracy: 0.1804 - val_loss: 3.0291 - val_accuracy: 0.2642\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.9849 - accuracy: 0.2117 - val_loss: 2.8986 - val_accuracy: 0.2547\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.8644 - accuracy: 0.2104 - val_loss: 2.7732 - val_accuracy: 0.2579\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.7544 - accuracy: 0.2313 - val_loss: 2.6557 - val_accuracy: 0.2547\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.6559 - accuracy: 0.2344 - val_loss: 2.5645 - val_accuracy: 0.2484\n",
      "Epoch 7/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.5697 - accuracy: 0.2313 - val_loss: 2.4730 - val_accuracy: 0.2547\n",
      "Epoch 8/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.4898 - accuracy: 0.2454 - val_loss: 2.3906 - val_accuracy: 0.2862\n",
      "Epoch 9/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.4321 - accuracy: 0.2460 - val_loss: 2.3276 - val_accuracy: 0.2956\n",
      "Epoch 10/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.3733 - accuracy: 0.2742 - val_loss: 2.2736 - val_accuracy: 0.3239\n",
      "Epoch 11/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.3167 - accuracy: 0.2699 - val_loss: 2.2290 - val_accuracy: 0.3050\n",
      "Epoch 12/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.2730 - accuracy: 0.2693 - val_loss: 2.1846 - val_accuracy: 0.3082\n",
      "Epoch 13/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2401 - accuracy: 0.2798 - val_loss: 2.1358 - val_accuracy: 0.3302\n",
      "Epoch 14/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2138 - accuracy: 0.2834 - val_loss: 2.1061 - val_accuracy: 0.3145\n",
      "Epoch 15/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1761 - accuracy: 0.2804 - val_loss: 2.0888 - val_accuracy: 0.3082\n",
      "Epoch 16/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.1434 - accuracy: 0.2865 - val_loss: 2.0565 - val_accuracy: 0.3208\n",
      "Epoch 17/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1203 - accuracy: 0.2761 - val_loss: 2.0281 - val_accuracy: 0.3428\n",
      "Epoch 18/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.1056 - accuracy: 0.2773 - val_loss: 2.0097 - val_accuracy: 0.3270\n",
      "Epoch 19/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0840 - accuracy: 0.2890 - val_loss: 1.9833 - val_accuracy: 0.3302\n",
      "Epoch 20/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0517 - accuracy: 0.2914 - val_loss: 1.9664 - val_accuracy: 0.3208\n",
      "Epoch 21/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0306 - accuracy: 0.2933 - val_loss: 1.9555 - val_accuracy: 0.3082\n",
      "Epoch 22/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0227 - accuracy: 0.2865 - val_loss: 1.9329 - val_accuracy: 0.3208\n",
      "Epoch 23/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9942 - accuracy: 0.2939 - val_loss: 1.9157 - val_accuracy: 0.3208\n",
      "Epoch 24/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9807 - accuracy: 0.3025 - val_loss: 1.9224 - val_accuracy: 0.3113\n",
      "Epoch 25/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9540 - accuracy: 0.3123 - val_loss: 1.9022 - val_accuracy: 0.3176\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.9022 - accuracy: 0.3176\n",
      "Fold 2 - Validation Loss: 1.9022, Validation Accuracy: 0.3176\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 3.2329 - accuracy: 0.1675 - val_loss: 3.1460 - val_accuracy: 0.2476\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 3.0867 - accuracy: 0.2029 - val_loss: 3.0107 - val_accuracy: 0.2524\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9455 - accuracy: 0.2382 - val_loss: 2.8867 - val_accuracy: 0.2619\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.8185 - accuracy: 0.2513 - val_loss: 2.7851 - val_accuracy: 0.2476\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.7058 - accuracy: 0.2670 - val_loss: 2.6935 - val_accuracy: 0.2500\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6107 - accuracy: 0.2768 - val_loss: 2.6174 - val_accuracy: 0.2571\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5381 - accuracy: 0.2755 - val_loss: 2.5417 - val_accuracy: 0.2381\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4628 - accuracy: 0.2795 - val_loss: 2.4829 - val_accuracy: 0.2714\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4116 - accuracy: 0.2723 - val_loss: 2.4456 - val_accuracy: 0.2690\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3638 - accuracy: 0.2781 - val_loss: 2.3924 - val_accuracy: 0.2714\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3113 - accuracy: 0.2749 - val_loss: 2.3348 - val_accuracy: 0.2738\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2764 - accuracy: 0.2808 - val_loss: 2.2971 - val_accuracy: 0.2738\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2361 - accuracy: 0.2965 - val_loss: 2.2618 - val_accuracy: 0.3048\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1883 - accuracy: 0.2945 - val_loss: 2.2370 - val_accuracy: 0.2690\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1648 - accuracy: 0.2925 - val_loss: 2.2007 - val_accuracy: 0.2762\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1415 - accuracy: 0.2893 - val_loss: 2.1738 - val_accuracy: 0.2714\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1063 - accuracy: 0.2932 - val_loss: 2.1421 - val_accuracy: 0.2762\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0959 - accuracy: 0.3056 - val_loss: 2.1155 - val_accuracy: 0.2786\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0699 - accuracy: 0.3069 - val_loss: 2.1068 - val_accuracy: 0.3000\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0530 - accuracy: 0.3043 - val_loss: 2.0823 - val_accuracy: 0.3000\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0148 - accuracy: 0.3082 - val_loss: 2.0732 - val_accuracy: 0.2857\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0036 - accuracy: 0.2906 - val_loss: 2.0284 - val_accuracy: 0.2905\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9714 - accuracy: 0.3181 - val_loss: 2.0110 - val_accuracy: 0.3071\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9652 - accuracy: 0.3089 - val_loss: 2.0015 - val_accuracy: 0.3024\n",
      "Epoch 25/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9502 - accuracy: 0.3233 - val_loss: 1.9780 - val_accuracy: 0.3167\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.9780 - accuracy: 0.3167\n",
      "Fold 3 - Validation Loss: 1.9780, Validation Accuracy: 0.3167\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 3.2910 - accuracy: 0.1403 - val_loss: 3.1879 - val_accuracy: 0.2284\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1444 - accuracy: 0.1775 - val_loss: 3.0562 - val_accuracy: 0.1851\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0114 - accuracy: 0.2148 - val_loss: 2.9270 - val_accuracy: 0.2668\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.9157 - accuracy: 0.2089 - val_loss: 2.8184 - val_accuracy: 0.2837\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8013 - accuracy: 0.2278 - val_loss: 2.7155 - val_accuracy: 0.2788\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6968 - accuracy: 0.2546 - val_loss: 2.6259 - val_accuracy: 0.2788\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.6140 - accuracy: 0.2526 - val_loss: 2.5595 - val_accuracy: 0.2764\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.5396 - accuracy: 0.2604 - val_loss: 2.4882 - val_accuracy: 0.2885\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4669 - accuracy: 0.2826 - val_loss: 2.4347 - val_accuracy: 0.2764\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4138 - accuracy: 0.2631 - val_loss: 2.3869 - val_accuracy: 0.2885\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3604 - accuracy: 0.2689 - val_loss: 2.3496 - val_accuracy: 0.2837\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3058 - accuracy: 0.2892 - val_loss: 2.3039 - val_accuracy: 0.2957\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2770 - accuracy: 0.2768 - val_loss: 2.2584 - val_accuracy: 0.2837\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2289 - accuracy: 0.2924 - val_loss: 2.2315 - val_accuracy: 0.2740\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2067 - accuracy: 0.2879 - val_loss: 2.2079 - val_accuracy: 0.3077\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1807 - accuracy: 0.2957 - val_loss: 2.1766 - val_accuracy: 0.2885\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1487 - accuracy: 0.2911 - val_loss: 2.1502 - val_accuracy: 0.2812\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1142 - accuracy: 0.2898 - val_loss: 2.1214 - val_accuracy: 0.2837\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0884 - accuracy: 0.3068 - val_loss: 2.1210 - val_accuracy: 0.2957\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0746 - accuracy: 0.3048 - val_loss: 2.0776 - val_accuracy: 0.2837\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0364 - accuracy: 0.3146 - val_loss: 2.0616 - val_accuracy: 0.2861\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0215 - accuracy: 0.3009 - val_loss: 2.0480 - val_accuracy: 0.2764\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0034 - accuracy: 0.3094 - val_loss: 2.0294 - val_accuracy: 0.2861\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9788 - accuracy: 0.3159 - val_loss: 1.9976 - val_accuracy: 0.3029\n",
      "Epoch 25/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9676 - accuracy: 0.3133 - val_loss: 1.9935 - val_accuracy: 0.2933\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.9935 - accuracy: 0.2933\n",
      "Fold 4 - Validation Loss: 1.9935, Validation Accuracy: 0.2933\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 8s 49ms/step - loss: 3.2831 - accuracy: 0.1632 - val_loss: 3.1849 - val_accuracy: 0.2043\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1248 - accuracy: 0.1958 - val_loss: 3.0453 - val_accuracy: 0.2091\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.9755 - accuracy: 0.2272 - val_loss: 2.9163 - val_accuracy: 0.2188\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8415 - accuracy: 0.2454 - val_loss: 2.8129 - val_accuracy: 0.2260\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7206 - accuracy: 0.2657 - val_loss: 2.7025 - val_accuracy: 0.2476\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6418 - accuracy: 0.2657 - val_loss: 2.6366 - val_accuracy: 0.2452\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5549 - accuracy: 0.2800 - val_loss: 2.5769 - val_accuracy: 0.2524\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4800 - accuracy: 0.2800 - val_loss: 2.5417 - val_accuracy: 0.2308\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4095 - accuracy: 0.2820 - val_loss: 2.4724 - val_accuracy: 0.2452\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3551 - accuracy: 0.2963 - val_loss: 2.4471 - val_accuracy: 0.2356\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3189 - accuracy: 0.2879 - val_loss: 2.4045 - val_accuracy: 0.2428\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2648 - accuracy: 0.2983 - val_loss: 2.3649 - val_accuracy: 0.2380\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2150 - accuracy: 0.3094 - val_loss: 2.3722 - val_accuracy: 0.2284\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1826 - accuracy: 0.3068 - val_loss: 2.2936 - val_accuracy: 0.2380\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1468 - accuracy: 0.3101 - val_loss: 2.2767 - val_accuracy: 0.2452\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1261 - accuracy: 0.3029 - val_loss: 2.2594 - val_accuracy: 0.2476\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0996 - accuracy: 0.3185 - val_loss: 2.1920 - val_accuracy: 0.2668\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0733 - accuracy: 0.3179 - val_loss: 2.1987 - val_accuracy: 0.2236\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0368 - accuracy: 0.3303 - val_loss: 2.1540 - val_accuracy: 0.2620\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0352 - accuracy: 0.3198 - val_loss: 2.1643 - val_accuracy: 0.2284\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0036 - accuracy: 0.3238 - val_loss: 2.1097 - val_accuracy: 0.2596\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9791 - accuracy: 0.3251 - val_loss: 2.1351 - val_accuracy: 0.2356\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9542 - accuracy: 0.3251 - val_loss: 2.1156 - val_accuracy: 0.2500\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9441 - accuracy: 0.3322 - val_loss: 2.1234 - val_accuracy: 0.2428\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.1097 - accuracy: 0.2596\n",
      "Fold 5 - Validation Loss: 2.1097, Validation Accuracy: 0.2596\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 5s 17ms/step - loss: 3.3537 - accuracy: 0.1318 - val_loss: 3.2442 - val_accuracy: 0.2354\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 3.2377 - accuracy: 0.1471 - val_loss: 3.1465 - val_accuracy: 0.2540\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 3.1316 - accuracy: 0.1701 - val_loss: 3.0575 - val_accuracy: 0.2328\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 3.0398 - accuracy: 0.1815 - val_loss: 2.9687 - val_accuracy: 0.2593\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.9608 - accuracy: 0.1732 - val_loss: 2.8861 - val_accuracy: 0.2566\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.8749 - accuracy: 0.2153 - val_loss: 2.8131 - val_accuracy: 0.2487\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.8097 - accuracy: 0.2070 - val_loss: 2.7436 - val_accuracy: 0.2328\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.7505 - accuracy: 0.2115 - val_loss: 2.6884 - val_accuracy: 0.2249\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.6876 - accuracy: 0.2210 - val_loss: 2.6255 - val_accuracy: 0.2302\n",
      "Epoch 10/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.6223 - accuracy: 0.2293 - val_loss: 2.5770 - val_accuracy: 0.2275\n",
      "Epoch 11/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.5619 - accuracy: 0.2484 - val_loss: 2.5139 - val_accuracy: 0.2434\n",
      "Epoch 12/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.5151 - accuracy: 0.2350 - val_loss: 2.4704 - val_accuracy: 0.2275\n",
      "Epoch 13/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.4758 - accuracy: 0.2229 - val_loss: 2.4350 - val_accuracy: 0.2249\n",
      "Epoch 14/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.4393 - accuracy: 0.2548 - val_loss: 2.3861 - val_accuracy: 0.2381\n",
      "Epoch 15/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.3983 - accuracy: 0.2561 - val_loss: 2.3551 - val_accuracy: 0.2302\n",
      "Epoch 16/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.3623 - accuracy: 0.2497 - val_loss: 2.3242 - val_accuracy: 0.2302\n",
      "Epoch 17/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.3364 - accuracy: 0.2541 - val_loss: 2.2904 - val_accuracy: 0.2460\n",
      "Epoch 18/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.3016 - accuracy: 0.2561 - val_loss: 2.2473 - val_accuracy: 0.2513\n",
      "Epoch 19/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.2768 - accuracy: 0.2510 - val_loss: 2.2092 - val_accuracy: 0.2804\n",
      "Epoch 20/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.2464 - accuracy: 0.2541 - val_loss: 2.1870 - val_accuracy: 0.2857\n",
      "Epoch 21/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.2176 - accuracy: 0.2605 - val_loss: 2.1728 - val_accuracy: 0.2619\n",
      "Epoch 22/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.1901 - accuracy: 0.2637 - val_loss: 2.1401 - val_accuracy: 0.2831\n",
      "Epoch 23/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.1785 - accuracy: 0.2650 - val_loss: 2.1307 - val_accuracy: 0.2434\n",
      "Epoch 24/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.1432 - accuracy: 0.2688 - val_loss: 2.0909 - val_accuracy: 0.2778\n",
      "Epoch 25/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.1262 - accuracy: 0.2911 - val_loss: 2.0742 - val_accuracy: 0.2910\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0742 - accuracy: 0.2910\n",
      "Fold 1 - Validation Loss: 2.0742, Validation Accuracy: 0.2910\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 17ms/step - loss: 3.3263 - accuracy: 0.1337 - val_loss: 3.2142 - val_accuracy: 0.2610\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 3.1981 - accuracy: 0.1626 - val_loss: 3.1039 - val_accuracy: 0.3019\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 3.0882 - accuracy: 0.1859 - val_loss: 3.0026 - val_accuracy: 0.3208\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 3.0109 - accuracy: 0.1914 - val_loss: 2.9069 - val_accuracy: 0.3082\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.9163 - accuracy: 0.2012 - val_loss: 2.8110 - val_accuracy: 0.3208\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.8215 - accuracy: 0.2276 - val_loss: 2.7228 - val_accuracy: 0.2830\n",
      "Epoch 7/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.7537 - accuracy: 0.2319 - val_loss: 2.6352 - val_accuracy: 0.3208\n",
      "Epoch 8/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.6723 - accuracy: 0.2515 - val_loss: 2.5738 - val_accuracy: 0.3113\n",
      "Epoch 9/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.6142 - accuracy: 0.2571 - val_loss: 2.4903 - val_accuracy: 0.3333\n",
      "Epoch 10/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.5452 - accuracy: 0.2534 - val_loss: 2.4392 - val_accuracy: 0.3050\n",
      "Epoch 11/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.4950 - accuracy: 0.2472 - val_loss: 2.3903 - val_accuracy: 0.3396\n",
      "Epoch 12/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.4513 - accuracy: 0.2534 - val_loss: 2.3361 - val_accuracy: 0.3208\n",
      "Epoch 13/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.4140 - accuracy: 0.2564 - val_loss: 2.2998 - val_accuracy: 0.3428\n",
      "Epoch 14/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.3744 - accuracy: 0.2595 - val_loss: 2.2613 - val_accuracy: 0.3208\n",
      "Epoch 15/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.3383 - accuracy: 0.2491 - val_loss: 2.2368 - val_accuracy: 0.3396\n",
      "Epoch 16/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.3140 - accuracy: 0.2601 - val_loss: 2.2126 - val_accuracy: 0.3113\n",
      "Epoch 17/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2621 - accuracy: 0.2589 - val_loss: 2.1676 - val_accuracy: 0.3302\n",
      "Epoch 18/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2478 - accuracy: 0.2620 - val_loss: 2.1354 - val_accuracy: 0.3208\n",
      "Epoch 19/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2312 - accuracy: 0.2607 - val_loss: 2.1128 - val_accuracy: 0.3365\n",
      "Epoch 20/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1877 - accuracy: 0.2755 - val_loss: 2.1006 - val_accuracy: 0.3019\n",
      "Epoch 21/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1637 - accuracy: 0.2785 - val_loss: 2.0675 - val_accuracy: 0.3113\n",
      "Epoch 22/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1348 - accuracy: 0.2755 - val_loss: 2.0584 - val_accuracy: 0.3113\n",
      "Epoch 23/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1332 - accuracy: 0.2681 - val_loss: 2.0312 - val_accuracy: 0.3365\n",
      "Epoch 24/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0947 - accuracy: 0.2877 - val_loss: 2.0205 - val_accuracy: 0.3302\n",
      "Epoch 25/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0958 - accuracy: 0.2847 - val_loss: 1.9975 - val_accuracy: 0.3113\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.9975 - accuracy: 0.3113\n",
      "Fold 2 - Validation Loss: 1.9975, Validation Accuracy: 0.3113\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 3.3122 - accuracy: 0.1420 - val_loss: 3.2236 - val_accuracy: 0.1929\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.2023 - accuracy: 0.1545 - val_loss: 3.1266 - val_accuracy: 0.2048\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 3.0972 - accuracy: 0.1832 - val_loss: 3.0379 - val_accuracy: 0.2119\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.0104 - accuracy: 0.1865 - val_loss: 2.9569 - val_accuracy: 0.2000\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.9247 - accuracy: 0.2107 - val_loss: 2.8769 - val_accuracy: 0.2214\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8437 - accuracy: 0.2114 - val_loss: 2.8022 - val_accuracy: 0.1952\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7766 - accuracy: 0.2232 - val_loss: 2.7314 - val_accuracy: 0.2095\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 2.6938 - accuracy: 0.2513 - val_loss: 2.6694 - val_accuracy: 0.2167\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6359 - accuracy: 0.2572 - val_loss: 2.6102 - val_accuracy: 0.2381\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5863 - accuracy: 0.2572 - val_loss: 2.5607 - val_accuracy: 0.2333\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5305 - accuracy: 0.2421 - val_loss: 2.5187 - val_accuracy: 0.2357\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4711 - accuracy: 0.2592 - val_loss: 2.4725 - val_accuracy: 0.2452\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4501 - accuracy: 0.2533 - val_loss: 2.4210 - val_accuracy: 0.2500\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.4127 - accuracy: 0.2651 - val_loss: 2.3822 - val_accuracy: 0.2548\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.3732 - accuracy: 0.2631 - val_loss: 2.3470 - val_accuracy: 0.2548\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3306 - accuracy: 0.2611 - val_loss: 2.3156 - val_accuracy: 0.2476\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2989 - accuracy: 0.2637 - val_loss: 2.2906 - val_accuracy: 0.2524\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2794 - accuracy: 0.2670 - val_loss: 2.2678 - val_accuracy: 0.2548\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2544 - accuracy: 0.2585 - val_loss: 2.2368 - val_accuracy: 0.2738\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2104 - accuracy: 0.2886 - val_loss: 2.2299 - val_accuracy: 0.2619\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1860 - accuracy: 0.2860 - val_loss: 2.2065 - val_accuracy: 0.2786\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1776 - accuracy: 0.2755 - val_loss: 2.1889 - val_accuracy: 0.2524\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1635 - accuracy: 0.2814 - val_loss: 2.1624 - val_accuracy: 0.2667\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1445 - accuracy: 0.2716 - val_loss: 2.1487 - val_accuracy: 0.2690\n",
      "Epoch 25/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1111 - accuracy: 0.2886 - val_loss: 2.1319 - val_accuracy: 0.2595\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.1319 - accuracy: 0.2595\n",
      "Fold 3 - Validation Loss: 2.1319, Validation Accuracy: 0.2595\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 3.2986 - accuracy: 0.1443 - val_loss: 3.2065 - val_accuracy: 0.2043\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 3.1804 - accuracy: 0.1534 - val_loss: 3.1002 - val_accuracy: 0.2284\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 3.0731 - accuracy: 0.1926 - val_loss: 3.0021 - val_accuracy: 0.2163\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.9789 - accuracy: 0.2089 - val_loss: 2.9084 - val_accuracy: 0.2308\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8994 - accuracy: 0.2167 - val_loss: 2.8209 - val_accuracy: 0.2404\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8158 - accuracy: 0.2121 - val_loss: 2.7390 - val_accuracy: 0.2812\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7369 - accuracy: 0.2272 - val_loss: 2.6662 - val_accuracy: 0.2524\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6779 - accuracy: 0.2324 - val_loss: 2.6055 - val_accuracy: 0.2524\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6114 - accuracy: 0.2317 - val_loss: 2.5425 - val_accuracy: 0.2716\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5658 - accuracy: 0.2369 - val_loss: 2.4908 - val_accuracy: 0.2620\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5067 - accuracy: 0.2448 - val_loss: 2.4434 - val_accuracy: 0.2668\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4785 - accuracy: 0.2376 - val_loss: 2.4124 - val_accuracy: 0.2764\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4279 - accuracy: 0.2487 - val_loss: 2.3745 - val_accuracy: 0.2764\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3883 - accuracy: 0.2493 - val_loss: 2.3281 - val_accuracy: 0.2861\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 2.3578 - accuracy: 0.2350 - val_loss: 2.3137 - val_accuracy: 0.2788\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3166 - accuracy: 0.2448 - val_loss: 2.2836 - val_accuracy: 0.2788\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 2.2860 - accuracy: 0.2533 - val_loss: 2.2483 - val_accuracy: 0.2788\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 2.2472 - accuracy: 0.2611 - val_loss: 2.2222 - val_accuracy: 0.2716\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2351 - accuracy: 0.2552 - val_loss: 2.2016 - val_accuracy: 0.2861\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2019 - accuracy: 0.2448 - val_loss: 2.1778 - val_accuracy: 0.2861\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 15ms/step - loss: 2.1796 - accuracy: 0.2807 - val_loss: 2.1512 - val_accuracy: 0.2861\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1603 - accuracy: 0.2644 - val_loss: 2.1469 - val_accuracy: 0.2885\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 2.1192 - accuracy: 0.2722 - val_loss: 2.1282 - val_accuracy: 0.2837\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 13ms/step - loss: 2.1213 - accuracy: 0.2774 - val_loss: 2.1024 - val_accuracy: 0.2909\n",
      "Epoch 25/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0977 - accuracy: 0.2657 - val_loss: 2.0880 - val_accuracy: 0.2957\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.0880 - accuracy: 0.2957\n",
      "Fold 4 - Validation Loss: 2.0880, Validation Accuracy: 0.2957\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 19ms/step - loss: 3.3323 - accuracy: 0.1390 - val_loss: 3.2352 - val_accuracy: 0.1779\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 3.2093 - accuracy: 0.1482 - val_loss: 3.1346 - val_accuracy: 0.1899\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 14ms/step - loss: 3.1109 - accuracy: 0.1802 - val_loss: 3.0458 - val_accuracy: 0.2067\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 3.0206 - accuracy: 0.1769 - val_loss: 2.9608 - val_accuracy: 0.2236\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.9402 - accuracy: 0.1893 - val_loss: 2.8820 - val_accuracy: 0.2332\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.8531 - accuracy: 0.2108 - val_loss: 2.8073 - val_accuracy: 0.2163\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7849 - accuracy: 0.2017 - val_loss: 2.7353 - val_accuracy: 0.2212\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7038 - accuracy: 0.2219 - val_loss: 2.6680 - val_accuracy: 0.2452\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.6365 - accuracy: 0.2285 - val_loss: 2.6052 - val_accuracy: 0.2332\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5766 - accuracy: 0.2311 - val_loss: 2.5639 - val_accuracy: 0.2067\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5279 - accuracy: 0.2500 - val_loss: 2.5116 - val_accuracy: 0.2284\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4731 - accuracy: 0.2513 - val_loss: 2.4695 - val_accuracy: 0.2356\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4191 - accuracy: 0.2461 - val_loss: 2.4200 - val_accuracy: 0.2332\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 2.3791 - accuracy: 0.2761 - val_loss: 2.4087 - val_accuracy: 0.2163\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3541 - accuracy: 0.2617 - val_loss: 2.3674 - val_accuracy: 0.2236\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.3215 - accuracy: 0.2722 - val_loss: 2.3335 - val_accuracy: 0.2308\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2958 - accuracy: 0.2644 - val_loss: 2.2828 - val_accuracy: 0.2452\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2473 - accuracy: 0.2885 - val_loss: 2.2749 - val_accuracy: 0.2356\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2289 - accuracy: 0.2768 - val_loss: 2.2374 - val_accuracy: 0.2548\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1988 - accuracy: 0.2728 - val_loss: 2.2238 - val_accuracy: 0.2500\n",
      "Epoch 21/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1782 - accuracy: 0.2696 - val_loss: 2.2121 - val_accuracy: 0.2404\n",
      "Epoch 22/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1370 - accuracy: 0.2735 - val_loss: 2.2134 - val_accuracy: 0.2284\n",
      "Epoch 23/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1167 - accuracy: 0.2944 - val_loss: 2.1932 - val_accuracy: 0.2260\n",
      "Epoch 24/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1083 - accuracy: 0.2833 - val_loss: 2.1707 - val_accuracy: 0.2452\n",
      "Epoch 25/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1000 - accuracy: 0.2852 - val_loss: 2.1335 - val_accuracy: 0.2500\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.1335 - accuracy: 0.2500\n",
      "Fold 5 - Validation Loss: 2.1335, Validation Accuracy: 0.2500\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 5s 18ms/step - loss: 2.7530 - accuracy: 0.2089 - val_loss: 2.2990 - val_accuracy: 0.2407\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.2192 - accuracy: 0.2580 - val_loss: 2.0937 - val_accuracy: 0.2434\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0533 - accuracy: 0.2503 - val_loss: 2.1959 - val_accuracy: 0.1693\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9836 - accuracy: 0.2624 - val_loss: 1.9254 - val_accuracy: 0.2804\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9351 - accuracy: 0.2739 - val_loss: 1.8891 - val_accuracy: 0.2698\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9142 - accuracy: 0.2637 - val_loss: 1.9105 - val_accuracy: 0.2275\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9331 - accuracy: 0.2541 - val_loss: 1.8513 - val_accuracy: 0.3148\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.8911 - accuracy: 0.2713 - val_loss: 1.9045 - val_accuracy: 0.2328\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9056 - accuracy: 0.2739 - val_loss: 1.8674 - val_accuracy: 0.2937\n",
      "Epoch 10/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.8943 - accuracy: 0.2694 - val_loss: 1.8551 - val_accuracy: 0.2884\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8513 - accuracy: 0.3148\n",
      "Fold 1 - Validation Loss: 1.8513, Validation Accuracy: 0.3148\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 17ms/step - loss: 2.7557 - accuracy: 0.2110 - val_loss: 2.3362 - val_accuracy: 0.2358\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1890 - accuracy: 0.2356 - val_loss: 2.0152 - val_accuracy: 0.2987\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0333 - accuracy: 0.2497 - val_loss: 1.9024 - val_accuracy: 0.3019\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9759 - accuracy: 0.2509 - val_loss: 1.8664 - val_accuracy: 0.2862\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9233 - accuracy: 0.2595 - val_loss: 1.8619 - val_accuracy: 0.2956\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9031 - accuracy: 0.2601 - val_loss: 1.8064 - val_accuracy: 0.2767\n",
      "Epoch 7/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9030 - accuracy: 0.2650 - val_loss: 1.7909 - val_accuracy: 0.3050\n",
      "Epoch 8/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.8970 - accuracy: 0.2779 - val_loss: 1.8065 - val_accuracy: 0.3113\n",
      "Epoch 9/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.8760 - accuracy: 0.2779 - val_loss: 1.8015 - val_accuracy: 0.3082\n",
      "Epoch 10/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.8653 - accuracy: 0.2773 - val_loss: 1.7934 - val_accuracy: 0.3019\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7909 - accuracy: 0.3050\n",
      "Fold 2 - Validation Loss: 1.7909, Validation Accuracy: 0.3050\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 2.7502 - accuracy: 0.2094 - val_loss: 2.3693 - val_accuracy: 0.2238\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1938 - accuracy: 0.2349 - val_loss: 2.2032 - val_accuracy: 0.2095\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0303 - accuracy: 0.2539 - val_loss: 2.0421 - val_accuracy: 0.2452\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9607 - accuracy: 0.2592 - val_loss: 1.9776 - val_accuracy: 0.2357\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9038 - accuracy: 0.2664 - val_loss: 1.9700 - val_accuracy: 0.2619\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9058 - accuracy: 0.2703 - val_loss: 1.9775 - val_accuracy: 0.2095\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9032 - accuracy: 0.2579 - val_loss: 1.9384 - val_accuracy: 0.2690\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8764 - accuracy: 0.2808 - val_loss: 1.9221 - val_accuracy: 0.2667\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8569 - accuracy: 0.2827 - val_loss: 1.9231 - val_accuracy: 0.2524\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8660 - accuracy: 0.2788 - val_loss: 1.9247 - val_accuracy: 0.2833\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8419 - accuracy: 0.3030 - val_loss: 1.8969 - val_accuracy: 0.2810\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8522 - accuracy: 0.2814 - val_loss: 1.9099 - val_accuracy: 0.2619\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8927 - accuracy: 0.2768 - val_loss: 1.8844 - val_accuracy: 0.2571\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8481 - accuracy: 0.2827 - val_loss: 1.8936 - val_accuracy: 0.2857\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8442 - accuracy: 0.2860 - val_loss: 1.8733 - val_accuracy: 0.3000\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8352 - accuracy: 0.2938 - val_loss: 1.9186 - val_accuracy: 0.2643\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8322 - accuracy: 0.2984 - val_loss: 1.8288 - val_accuracy: 0.3214\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8303 - accuracy: 0.2814 - val_loss: 1.8577 - val_accuracy: 0.2976\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8519 - accuracy: 0.2821 - val_loss: 1.8840 - val_accuracy: 0.2595\n",
      "Epoch 20/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8214 - accuracy: 0.2932 - val_loss: 1.8401 - val_accuracy: 0.2810\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.8288 - accuracy: 0.3214\n",
      "Fold 3 - Validation Loss: 1.8288, Validation Accuracy: 0.3214\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 2.7710 - accuracy: 0.2193 - val_loss: 2.3169 - val_accuracy: 0.2668\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2108 - accuracy: 0.2396 - val_loss: 2.0873 - val_accuracy: 0.2380\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0477 - accuracy: 0.2461 - val_loss: 1.9751 - val_accuracy: 0.2812\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9833 - accuracy: 0.2604 - val_loss: 1.9271 - val_accuracy: 0.2885\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9466 - accuracy: 0.2552 - val_loss: 1.9134 - val_accuracy: 0.2716\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8922 - accuracy: 0.2598 - val_loss: 1.8786 - val_accuracy: 0.2764\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8869 - accuracy: 0.2768 - val_loss: 1.8829 - val_accuracy: 0.2740\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8829 - accuracy: 0.2709 - val_loss: 1.8281 - val_accuracy: 0.3125\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8581 - accuracy: 0.2761 - val_loss: 1.8282 - val_accuracy: 0.2981\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8463 - accuracy: 0.2846 - val_loss: 1.8769 - val_accuracy: 0.2668\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8732 - accuracy: 0.2689 - val_loss: 1.8705 - val_accuracy: 0.2812\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.8281 - accuracy: 0.3125\n",
      "Fold 4 - Validation Loss: 1.8281, Validation Accuracy: 0.3125\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 2.8127 - accuracy: 0.1971 - val_loss: 2.3954 - val_accuracy: 0.2476\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2311 - accuracy: 0.2480 - val_loss: 2.1250 - val_accuracy: 0.2380\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0658 - accuracy: 0.2480 - val_loss: 2.0450 - val_accuracy: 0.2188\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9727 - accuracy: 0.2617 - val_loss: 2.0048 - val_accuracy: 0.2115\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9469 - accuracy: 0.2500 - val_loss: 2.0069 - val_accuracy: 0.2163\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8997 - accuracy: 0.2748 - val_loss: 1.9467 - val_accuracy: 0.2404\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9476 - accuracy: 0.2520 - val_loss: 1.9187 - val_accuracy: 0.2404\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9143 - accuracy: 0.2617 - val_loss: 1.9321 - val_accuracy: 0.2476\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8838 - accuracy: 0.2761 - val_loss: 1.9727 - val_accuracy: 0.2212\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8812 - accuracy: 0.2768 - val_loss: 1.9280 - val_accuracy: 0.2380\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.9187 - accuracy: 0.2404\n",
      "Fold 5 - Validation Loss: 1.9187, Validation Accuracy: 0.2404\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 5s 22ms/step - loss: 2.8249 - accuracy: 0.1707 - val_loss: 2.4069 - val_accuracy: 0.2381\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 2.2773 - accuracy: 0.2242 - val_loss: 2.1082 - val_accuracy: 0.2381\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 2.0980 - accuracy: 0.2325 - val_loss: 2.1376 - val_accuracy: 0.1561\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0142 - accuracy: 0.2382 - val_loss: 1.9609 - val_accuracy: 0.2725\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9707 - accuracy: 0.2465 - val_loss: 1.9127 - val_accuracy: 0.2831\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9246 - accuracy: 0.2522 - val_loss: 1.9143 - val_accuracy: 0.2593\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9104 - accuracy: 0.2783 - val_loss: 1.8647 - val_accuracy: 0.2884\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9267 - accuracy: 0.2643 - val_loss: 1.8855 - val_accuracy: 0.2566\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9066 - accuracy: 0.2701 - val_loss: 1.8511 - val_accuracy: 0.2857\n",
      "Epoch 10/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.8947 - accuracy: 0.2599 - val_loss: 1.8492 - val_accuracy: 0.2910\n",
      "Epoch 11/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.8776 - accuracy: 0.2739 - val_loss: 1.8770 - val_accuracy: 0.2540\n",
      "Epoch 12/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.8783 - accuracy: 0.2771 - val_loss: 1.8367 - val_accuracy: 0.2937\n",
      "Epoch 13/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.8828 - accuracy: 0.2745 - val_loss: 1.8597 - val_accuracy: 0.2778\n",
      "Epoch 14/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9013 - accuracy: 0.2573 - val_loss: 1.8536 - val_accuracy: 0.2698\n",
      "Epoch 15/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.8423 - accuracy: 0.2917 - val_loss: 1.8427 - val_accuracy: 0.2937\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8367 - accuracy: 0.2937\n",
      "Fold 1 - Validation Loss: 1.8367, Validation Accuracy: 0.2937\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 18ms/step - loss: 2.8105 - accuracy: 0.1982 - val_loss: 2.3989 - val_accuracy: 0.2830\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2729 - accuracy: 0.2294 - val_loss: 2.0916 - val_accuracy: 0.2799\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.1028 - accuracy: 0.2282 - val_loss: 1.9766 - val_accuracy: 0.2830\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0316 - accuracy: 0.2319 - val_loss: 1.8867 - val_accuracy: 0.3208\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9678 - accuracy: 0.2466 - val_loss: 1.8320 - val_accuracy: 0.3208\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9476 - accuracy: 0.2509 - val_loss: 1.8550 - val_accuracy: 0.3113\n",
      "Epoch 7/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9244 - accuracy: 0.2675 - val_loss: 1.8163 - val_accuracy: 0.3208\n",
      "Epoch 8/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9294 - accuracy: 0.2515 - val_loss: 1.9141 - val_accuracy: 0.2201\n",
      "Epoch 9/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9051 - accuracy: 0.2607 - val_loss: 1.7993 - val_accuracy: 0.3270\n",
      "Epoch 10/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.8952 - accuracy: 0.2626 - val_loss: 1.8325 - val_accuracy: 0.2799\n",
      "Epoch 11/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9151 - accuracy: 0.2509 - val_loss: 1.7810 - val_accuracy: 0.3302\n",
      "Epoch 12/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.8797 - accuracy: 0.2730 - val_loss: 1.7616 - val_accuracy: 0.3082\n",
      "Epoch 13/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.8638 - accuracy: 0.2761 - val_loss: 1.7882 - val_accuracy: 0.2736\n",
      "Epoch 14/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.8526 - accuracy: 0.2816 - val_loss: 1.7921 - val_accuracy: 0.2925\n",
      "Epoch 15/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.8761 - accuracy: 0.2785 - val_loss: 1.7371 - val_accuracy: 0.3145\n",
      "Epoch 16/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.8620 - accuracy: 0.2963 - val_loss: 1.7650 - val_accuracy: 0.3113\n",
      "Epoch 17/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.8609 - accuracy: 0.2773 - val_loss: 1.7540 - val_accuracy: 0.2987\n",
      "Epoch 18/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.8512 - accuracy: 0.2908 - val_loss: 1.7381 - val_accuracy: 0.3145\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.7371 - accuracy: 0.3145\n",
      "Fold 2 - Validation Loss: 1.7371, Validation Accuracy: 0.3145\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 21ms/step - loss: 2.8086 - accuracy: 0.2205 - val_loss: 2.4942 - val_accuracy: 0.1905\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2733 - accuracy: 0.2415 - val_loss: 2.2486 - val_accuracy: 0.2000\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0907 - accuracy: 0.2382 - val_loss: 2.1112 - val_accuracy: 0.2286\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9872 - accuracy: 0.2579 - val_loss: 1.9866 - val_accuracy: 0.2524\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9507 - accuracy: 0.2572 - val_loss: 1.9730 - val_accuracy: 0.2310\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8941 - accuracy: 0.2749 - val_loss: 1.9378 - val_accuracy: 0.2429\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9221 - accuracy: 0.2552 - val_loss: 1.9334 - val_accuracy: 0.2381\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9104 - accuracy: 0.2565 - val_loss: 1.9091 - val_accuracy: 0.2595\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8879 - accuracy: 0.2781 - val_loss: 1.9286 - val_accuracy: 0.2643\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8814 - accuracy: 0.2677 - val_loss: 1.9312 - val_accuracy: 0.2857\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8596 - accuracy: 0.2853 - val_loss: 1.9482 - val_accuracy: 0.2619\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.9091 - accuracy: 0.2595\n",
      "Fold 3 - Validation Loss: 1.9091, Validation Accuracy: 0.2595\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 2.8523 - accuracy: 0.1886 - val_loss: 2.4454 - val_accuracy: 0.2308\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2878 - accuracy: 0.2317 - val_loss: 2.1281 - val_accuracy: 0.2500\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1138 - accuracy: 0.2428 - val_loss: 2.0166 - val_accuracy: 0.2764\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0336 - accuracy: 0.2285 - val_loss: 1.9689 - val_accuracy: 0.2692\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9720 - accuracy: 0.2526 - val_loss: 1.9281 - val_accuracy: 0.2716\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9409 - accuracy: 0.2572 - val_loss: 1.9099 - val_accuracy: 0.2548\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9280 - accuracy: 0.2650 - val_loss: 1.9950 - val_accuracy: 0.2404\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9502 - accuracy: 0.2441 - val_loss: 1.9363 - val_accuracy: 0.2428\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9152 - accuracy: 0.2637 - val_loss: 1.9073 - val_accuracy: 0.2572\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9111 - accuracy: 0.2598 - val_loss: 1.9084 - val_accuracy: 0.2692\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8982 - accuracy: 0.2585 - val_loss: 1.8880 - val_accuracy: 0.2764\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8845 - accuracy: 0.2650 - val_loss: 1.8440 - val_accuracy: 0.3197\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8607 - accuracy: 0.2774 - val_loss: 1.8431 - val_accuracy: 0.3029\n",
      "Epoch 14/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8616 - accuracy: 0.2768 - val_loss: 1.9418 - val_accuracy: 0.2476\n",
      "Epoch 15/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8705 - accuracy: 0.2735 - val_loss: 1.8237 - val_accuracy: 0.3125\n",
      "Epoch 16/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8453 - accuracy: 0.2957 - val_loss: 1.8096 - val_accuracy: 0.3077\n",
      "Epoch 17/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8736 - accuracy: 0.2742 - val_loss: 1.8396 - val_accuracy: 0.3197\n",
      "Epoch 18/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8808 - accuracy: 0.2683 - val_loss: 1.8439 - val_accuracy: 0.2981\n",
      "Epoch 19/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8578 - accuracy: 0.2774 - val_loss: 1.8921 - val_accuracy: 0.3221\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.8096 - accuracy: 0.3077\n",
      "Fold 4 - Validation Loss: 1.8096, Validation Accuracy: 0.3077\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 2.8186 - accuracy: 0.2213 - val_loss: 2.4491 - val_accuracy: 0.2236\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2544 - accuracy: 0.2454 - val_loss: 2.1930 - val_accuracy: 0.2115\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0585 - accuracy: 0.2617 - val_loss: 2.0731 - val_accuracy: 0.2212\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9723 - accuracy: 0.2650 - val_loss: 2.0326 - val_accuracy: 0.1947\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9214 - accuracy: 0.2637 - val_loss: 2.0424 - val_accuracy: 0.2067\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8814 - accuracy: 0.2859 - val_loss: 1.9655 - val_accuracy: 0.2236\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8851 - accuracy: 0.2676 - val_loss: 1.9096 - val_accuracy: 0.2428\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.8650 - accuracy: 0.2898 - val_loss: 1.9064 - val_accuracy: 0.2524\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8772 - accuracy: 0.2937 - val_loss: 1.9937 - val_accuracy: 0.1995\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8696 - accuracy: 0.2748 - val_loss: 1.9534 - val_accuracy: 0.2332\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.8414 - accuracy: 0.2918 - val_loss: 1.9313 - val_accuracy: 0.2476\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.9064 - accuracy: 0.2524\n",
      "Fold 5 - Validation Loss: 1.9064, Validation Accuracy: 0.2524\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 5s 17ms/step - loss: 2.9690 - accuracy: 0.1726 - val_loss: 2.6318 - val_accuracy: 0.1508\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.4533 - accuracy: 0.2006 - val_loss: 2.2590 - val_accuracy: 0.2037\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.2186 - accuracy: 0.2019 - val_loss: 2.1811 - val_accuracy: 0.1667\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.1206 - accuracy: 0.2261 - val_loss: 2.0421 - val_accuracy: 0.2116\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0772 - accuracy: 0.2325 - val_loss: 1.9776 - val_accuracy: 0.2619\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0108 - accuracy: 0.2293 - val_loss: 1.9244 - val_accuracy: 0.2884\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9901 - accuracy: 0.2395 - val_loss: 1.9580 - val_accuracy: 0.2434\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9845 - accuracy: 0.2427 - val_loss: 1.9622 - val_accuracy: 0.2037\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9669 - accuracy: 0.2395 - val_loss: 1.8857 - val_accuracy: 0.2751\n",
      "Epoch 10/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9588 - accuracy: 0.2382 - val_loss: 1.8832 - val_accuracy: 0.2646\n",
      "Epoch 11/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9560 - accuracy: 0.2401 - val_loss: 1.8576 - val_accuracy: 0.2937\n",
      "Epoch 12/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 1.9435 - accuracy: 0.2573 - val_loss: 1.8727 - val_accuracy: 0.2672\n",
      "Epoch 13/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9660 - accuracy: 0.2427 - val_loss: 1.8762 - val_accuracy: 0.2619\n",
      "Epoch 14/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 1.9071 - accuracy: 0.2707 - val_loss: 1.8668 - val_accuracy: 0.2989\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8576 - accuracy: 0.2937\n",
      "Fold 1 - Validation Loss: 1.8576, Validation Accuracy: 0.2937\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 17ms/step - loss: 2.9205 - accuracy: 0.1883 - val_loss: 2.5310 - val_accuracy: 0.2704\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.3911 - accuracy: 0.2184 - val_loss: 2.1569 - val_accuracy: 0.2925\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.2013 - accuracy: 0.2160 - val_loss: 2.0429 - val_accuracy: 0.3019\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0896 - accuracy: 0.2276 - val_loss: 1.9405 - val_accuracy: 0.2987\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0319 - accuracy: 0.2288 - val_loss: 1.9111 - val_accuracy: 0.2987\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9906 - accuracy: 0.2380 - val_loss: 1.8748 - val_accuracy: 0.2673\n",
      "Epoch 7/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9850 - accuracy: 0.2258 - val_loss: 1.8965 - val_accuracy: 0.2893\n",
      "Epoch 8/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9803 - accuracy: 0.2356 - val_loss: 1.8699 - val_accuracy: 0.2987\n",
      "Epoch 9/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9624 - accuracy: 0.2380 - val_loss: 1.8665 - val_accuracy: 0.3208\n",
      "Epoch 10/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9564 - accuracy: 0.2393 - val_loss: 1.9256 - val_accuracy: 0.2673\n",
      "Epoch 11/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9728 - accuracy: 0.2417 - val_loss: 1.8387 - val_accuracy: 0.2987\n",
      "Epoch 12/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9439 - accuracy: 0.2693 - val_loss: 1.8049 - val_accuracy: 0.3302\n",
      "Epoch 13/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9366 - accuracy: 0.2564 - val_loss: 1.8305 - val_accuracy: 0.2799\n",
      "Epoch 14/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 1.9454 - accuracy: 0.2546 - val_loss: 1.8451 - val_accuracy: 0.2925\n",
      "Epoch 15/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 1.9209 - accuracy: 0.2497 - val_loss: 1.8144 - val_accuracy: 0.2862\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.8049 - accuracy: 0.3302\n",
      "Fold 2 - Validation Loss: 1.8049, Validation Accuracy: 0.3302\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 2.9520 - accuracy: 0.1787 - val_loss: 2.6054 - val_accuracy: 0.2095\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4216 - accuracy: 0.2304 - val_loss: 2.2787 - val_accuracy: 0.2643\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1957 - accuracy: 0.2232 - val_loss: 2.1072 - val_accuracy: 0.2310\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0766 - accuracy: 0.2402 - val_loss: 2.0359 - val_accuracy: 0.2214\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9953 - accuracy: 0.2546 - val_loss: 2.0470 - val_accuracy: 0.2429\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9693 - accuracy: 0.2461 - val_loss: 1.9654 - val_accuracy: 0.2405\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9795 - accuracy: 0.2546 - val_loss: 1.9811 - val_accuracy: 0.2548\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9305 - accuracy: 0.2546 - val_loss: 1.9289 - val_accuracy: 0.2381\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9068 - accuracy: 0.2768 - val_loss: 1.9178 - val_accuracy: 0.2619\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9048 - accuracy: 0.2709 - val_loss: 1.9196 - val_accuracy: 0.2667\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9097 - accuracy: 0.2559 - val_loss: 1.9271 - val_accuracy: 0.2595\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9111 - accuracy: 0.2513 - val_loss: 1.9338 - val_accuracy: 0.2405\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.9178 - accuracy: 0.2619\n",
      "Fold 3 - Validation Loss: 1.9178, Validation Accuracy: 0.2619\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 19ms/step - loss: 2.9606 - accuracy: 0.1782 - val_loss: 2.6368 - val_accuracy: 0.1683\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4710 - accuracy: 0.1834 - val_loss: 2.2925 - val_accuracy: 0.2620\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.2420 - accuracy: 0.2076 - val_loss: 2.1611 - val_accuracy: 0.1683\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1514 - accuracy: 0.2017 - val_loss: 2.0631 - val_accuracy: 0.2740\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0721 - accuracy: 0.2174 - val_loss: 2.0083 - val_accuracy: 0.2837\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0241 - accuracy: 0.2056 - val_loss: 1.9823 - val_accuracy: 0.2596\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9903 - accuracy: 0.2272 - val_loss: 1.9213 - val_accuracy: 0.2740\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9792 - accuracy: 0.2422 - val_loss: 1.9866 - val_accuracy: 0.2452\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9508 - accuracy: 0.2422 - val_loss: 1.9299 - val_accuracy: 0.2788\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9689 - accuracy: 0.2383 - val_loss: 1.9381 - val_accuracy: 0.2692\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.9213 - accuracy: 0.2740\n",
      "Fold 4 - Validation Loss: 1.9213, Validation Accuracy: 0.2740\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 2.9605 - accuracy: 0.1514 - val_loss: 2.6230 - val_accuracy: 0.1635\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.4494 - accuracy: 0.1873 - val_loss: 2.2921 - val_accuracy: 0.2212\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2228 - accuracy: 0.2278 - val_loss: 2.1463 - val_accuracy: 0.2067\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1073 - accuracy: 0.2258 - val_loss: 2.0592 - val_accuracy: 0.2043\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0516 - accuracy: 0.2213 - val_loss: 2.0768 - val_accuracy: 0.2019\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0019 - accuracy: 0.2343 - val_loss: 2.0469 - val_accuracy: 0.1659\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9958 - accuracy: 0.2311 - val_loss: 1.9601 - val_accuracy: 0.2452\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9548 - accuracy: 0.2650 - val_loss: 1.9583 - val_accuracy: 0.2236\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9316 - accuracy: 0.2676 - val_loss: 1.9536 - val_accuracy: 0.2380\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9427 - accuracy: 0.2604 - val_loss: 1.9758 - val_accuracy: 0.2163\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 1.9698 - accuracy: 0.2500 - val_loss: 1.9545 - val_accuracy: 0.2404\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 1.9279 - accuracy: 0.2644 - val_loss: 1.9830 - val_accuracy: 0.2091\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 1.9536 - accuracy: 0.2380\n",
      "Fold 5 - Validation Loss: 1.9536, Validation Accuracy: 0.2380\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 5s 18ms/step - loss: 5.4501 - accuracy: 0.1401 - val_loss: 2.3900 - val_accuracy: 0.1640\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.1183 - accuracy: 0.1414 - val_loss: 2.0510 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0509 - accuracy: 0.1522 - val_loss: 2.0637 - val_accuracy: 0.1481\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0541 - accuracy: 0.1376 - val_loss: 2.0480 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0512 - accuracy: 0.1408 - val_loss: 2.0446 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0510 - accuracy: 0.1484 - val_loss: 2.0442 - val_accuracy: 0.1481\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0468 - accuracy: 0.1624 - val_loss: 2.0507 - val_accuracy: 0.1481\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0475 - accuracy: 0.1548 - val_loss: 2.0471 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 2.0533 - accuracy: 0.1414 - val_loss: 2.0595 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0442 - accuracy: 0.1481\n",
      "Fold 1 - Validation Loss: 2.0442, Validation Accuracy: 0.1481\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 18ms/step - loss: 4.3585 - accuracy: 0.1436 - val_loss: 2.0777 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0541 - accuracy: 0.1564 - val_loss: 2.0406 - val_accuracy: 0.1509\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0472 - accuracy: 0.1552 - val_loss: 2.0307 - val_accuracy: 0.1698\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0536 - accuracy: 0.1429 - val_loss: 2.0358 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0506 - accuracy: 0.1405 - val_loss: 2.0325 - val_accuracy: 0.1698\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0557 - accuracy: 0.1534 - val_loss: 2.0426 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0307 - accuracy: 0.1698\n",
      "Fold 2 - Validation Loss: 2.0307, Validation Accuracy: 0.1698\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 4.0074 - accuracy: 0.1446 - val_loss: 2.2609 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1035 - accuracy: 0.1329 - val_loss: 2.0548 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0466 - accuracy: 0.1499 - val_loss: 2.0461 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0461 - accuracy: 0.1649 - val_loss: 2.0451 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0509 - accuracy: 0.1486 - val_loss: 2.0447 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0406 - accuracy: 0.1630 - val_loss: 2.0555 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0562 - accuracy: 0.1545 - val_loss: 2.0468 - val_accuracy: 0.1524\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0519 - accuracy: 0.1551 - val_loss: 2.0455 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.0447 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0447, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 4.3054 - accuracy: 0.1573 - val_loss: 2.2663 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0761 - accuracy: 0.1292 - val_loss: 2.0405 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0575 - accuracy: 0.1469 - val_loss: 2.0401 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0564 - accuracy: 0.1449 - val_loss: 2.0480 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0515 - accuracy: 0.1456 - val_loss: 2.0414 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 2.0520 - accuracy: 0.1580 - val_loss: 2.0372 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0536 - accuracy: 0.1586 - val_loss: 2.0499 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0571 - accuracy: 0.1501 - val_loss: 2.0409 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0483 - accuracy: 0.1606 - val_loss: 2.0449 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.0372 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0372, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 3.7406 - accuracy: 0.1593 - val_loss: 2.2168 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.1019 - accuracy: 0.1312 - val_loss: 2.0425 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0592 - accuracy: 0.1430 - val_loss: 2.0468 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0542 - accuracy: 0.1443 - val_loss: 2.0407 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0525 - accuracy: 0.1364 - val_loss: 2.0428 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 2.0505 - accuracy: 0.1612 - val_loss: 2.0401 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0548 - accuracy: 0.1501 - val_loss: 2.0504 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0577 - accuracy: 0.1501 - val_loss: 2.0363 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0485 - accuracy: 0.1573 - val_loss: 2.0399 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0497 - accuracy: 0.1540 - val_loss: 2.0340 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0447 - accuracy: 0.1521 - val_loss: 2.0474 - val_accuracy: 0.1538\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0488 - accuracy: 0.1638 - val_loss: 2.0429 - val_accuracy: 0.1538\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0484 - accuracy: 0.1462 - val_loss: 2.0396 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.0340 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0340, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 8s 19ms/step - loss: 4.0611 - accuracy: 0.1605 - val_loss: 2.3325 - val_accuracy: 0.1481\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 15ms/step - loss: 2.1678 - accuracy: 0.1433 - val_loss: 2.0501 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0486 - accuracy: 0.1516 - val_loss: 2.0647 - val_accuracy: 0.1640\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0547 - accuracy: 0.1389 - val_loss: 2.0485 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0519 - accuracy: 0.1401 - val_loss: 2.0451 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0514 - accuracy: 0.1484 - val_loss: 2.0444 - val_accuracy: 0.1481\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0471 - accuracy: 0.1624 - val_loss: 2.0506 - val_accuracy: 0.1481\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0477 - accuracy: 0.1554 - val_loss: 2.0472 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0536 - accuracy: 0.1408 - val_loss: 2.0595 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0444 - accuracy: 0.1481\n",
      "Fold 1 - Validation Loss: 2.0444, Validation Accuracy: 0.1481\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 17ms/step - loss: 4.9551 - accuracy: 0.1503 - val_loss: 2.4395 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.1436 - accuracy: 0.1546 - val_loss: 2.0413 - val_accuracy: 0.1698\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0473 - accuracy: 0.1521 - val_loss: 2.0313 - val_accuracy: 0.1698\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0538 - accuracy: 0.1417 - val_loss: 2.0356 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0507 - accuracy: 0.1374 - val_loss: 2.0323 - val_accuracy: 0.1698\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0558 - accuracy: 0.1534 - val_loss: 2.0429 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0313 - accuracy: 0.1698\n",
      "Fold 2 - Validation Loss: 2.0313, Validation Accuracy: 0.1698\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 21ms/step - loss: 4.0880 - accuracy: 0.1283 - val_loss: 2.2993 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 12ms/step - loss: 2.2197 - accuracy: 0.1381 - val_loss: 2.0672 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0482 - accuracy: 0.1479 - val_loss: 2.0462 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0456 - accuracy: 0.1708 - val_loss: 2.0466 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0510 - accuracy: 0.1486 - val_loss: 2.0444 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0407 - accuracy: 0.1649 - val_loss: 2.0557 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0562 - accuracy: 0.1545 - val_loss: 2.0469 - val_accuracy: 0.1524\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0520 - accuracy: 0.1564 - val_loss: 2.0460 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.0444 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0444, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 17ms/step - loss: 5.1339 - accuracy: 0.1508 - val_loss: 2.6395 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1870 - accuracy: 0.1325 - val_loss: 2.0406 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0569 - accuracy: 0.1416 - val_loss: 2.0395 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0558 - accuracy: 0.1462 - val_loss: 2.0473 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0511 - accuracy: 0.1462 - val_loss: 2.0408 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0517 - accuracy: 0.1580 - val_loss: 2.0372 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0534 - accuracy: 0.1586 - val_loss: 2.0498 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0568 - accuracy: 0.1495 - val_loss: 2.0408 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0481 - accuracy: 0.1599 - val_loss: 2.0447 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 1s 5ms/step - loss: 2.0372 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0372, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 4.9701 - accuracy: 0.1488 - val_loss: 2.5533 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.2327 - accuracy: 0.1351 - val_loss: 2.0680 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0610 - accuracy: 0.1436 - val_loss: 2.0447 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0540 - accuracy: 0.1449 - val_loss: 2.0402 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0523 - accuracy: 0.1371 - val_loss: 2.0428 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0503 - accuracy: 0.1612 - val_loss: 2.0404 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0543 - accuracy: 0.1534 - val_loss: 2.0504 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.0402 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0402, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 5s 18ms/step - loss: 5.0986 - accuracy: 0.1446 - val_loss: 2.6774 - val_accuracy: 0.1481\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.1790 - accuracy: 0.1452 - val_loss: 2.0505 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0487 - accuracy: 0.1516 - val_loss: 2.0643 - val_accuracy: 0.1640\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0547 - accuracy: 0.1376 - val_loss: 2.0482 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0520 - accuracy: 0.1401 - val_loss: 2.0450 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0513 - accuracy: 0.1484 - val_loss: 2.0445 - val_accuracy: 0.1481\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0471 - accuracy: 0.1624 - val_loss: 2.0506 - val_accuracy: 0.1481\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 1s 11ms/step - loss: 2.0477 - accuracy: 0.1548 - val_loss: 2.0472 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 1s 12ms/step - loss: 2.0536 - accuracy: 0.1408 - val_loss: 2.0595 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0445 - accuracy: 0.1481\n",
      "Fold 1 - Validation Loss: 2.0445, Validation Accuracy: 0.1481\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "102/102 [==============================] - 5s 17ms/step - loss: 4.7741 - accuracy: 0.1380 - val_loss: 2.5943 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.2223 - accuracy: 0.1558 - val_loss: 2.1098 - val_accuracy: 0.1698\n",
      "Epoch 3/25\n",
      "102/102 [==============================] - 1s 10ms/step - loss: 2.0554 - accuracy: 0.1540 - val_loss: 2.0313 - val_accuracy: 0.1698\n",
      "Epoch 4/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0539 - accuracy: 0.1429 - val_loss: 2.0357 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0508 - accuracy: 0.1405 - val_loss: 2.0323 - val_accuracy: 0.1698\n",
      "Epoch 6/25\n",
      "102/102 [==============================] - 1s 11ms/step - loss: 2.0558 - accuracy: 0.1534 - val_loss: 2.0428 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.0313 - accuracy: 0.1698\n",
      "Fold 2 - Validation Loss: 2.0313, Validation Accuracy: 0.1698\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 4.4803 - accuracy: 0.1387 - val_loss: 2.1793 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0684 - accuracy: 0.1342 - val_loss: 2.0555 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0466 - accuracy: 0.1473 - val_loss: 2.0463 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0458 - accuracy: 0.1669 - val_loss: 2.0467 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0512 - accuracy: 0.1486 - val_loss: 2.0444 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0408 - accuracy: 0.1649 - val_loss: 2.0557 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0564 - accuracy: 0.1545 - val_loss: 2.0471 - val_accuracy: 0.1524\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0521 - accuracy: 0.1551 - val_loss: 2.0459 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.0444 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0444, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 5.0004 - accuracy: 0.1482 - val_loss: 3.5000 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.7260 - accuracy: 0.1377 - val_loss: 2.2597 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.1061 - accuracy: 0.1462 - val_loss: 2.0410 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0567 - accuracy: 0.1469 - val_loss: 2.0477 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0513 - accuracy: 0.1456 - val_loss: 2.0409 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0519 - accuracy: 0.1580 - val_loss: 2.0371 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0537 - accuracy: 0.1606 - val_loss: 2.0498 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0570 - accuracy: 0.1501 - val_loss: 2.0410 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0483 - accuracy: 0.1606 - val_loss: 2.0448 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.0371 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0371, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "96/96 [==============================] - 5s 18ms/step - loss: 5.0423 - accuracy: 0.1638 - val_loss: 3.2742 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.5294 - accuracy: 0.1358 - val_loss: 2.0692 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0874 - accuracy: 0.1423 - val_loss: 2.0462 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 2.0544 - accuracy: 0.1430 - val_loss: 2.0405 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0526 - accuracy: 0.1358 - val_loss: 2.0430 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0506 - accuracy: 0.1612 - val_loss: 2.0401 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0546 - accuracy: 0.1540 - val_loss: 2.0503 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0577 - accuracy: 0.1488 - val_loss: 2.0363 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0485 - accuracy: 0.1573 - val_loss: 2.0398 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0496 - accuracy: 0.1527 - val_loss: 2.0340 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0447 - accuracy: 0.1547 - val_loss: 2.0473 - val_accuracy: 0.1538\n",
      "Epoch 12/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0488 - accuracy: 0.1638 - val_loss: 2.0429 - val_accuracy: 0.1538\n",
      "Epoch 13/25\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 2.0484 - accuracy: 0.1488 - val_loss: 2.0395 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 1s 4ms/step - loss: 2.0340 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0340, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 4s 28ms/step - loss: 3.3059 - accuracy: 0.1497 - val_loss: 3.2255 - val_accuracy: 0.2222\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 3.1917 - accuracy: 0.1758 - val_loss: 3.1316 - val_accuracy: 0.2566\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 3.0977 - accuracy: 0.1968 - val_loss: 3.0455 - val_accuracy: 0.2302\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 3.0154 - accuracy: 0.2223 - val_loss: 2.9591 - val_accuracy: 0.2381\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.9362 - accuracy: 0.2401 - val_loss: 2.8750 - val_accuracy: 0.2354\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.8553 - accuracy: 0.2535 - val_loss: 2.7928 - val_accuracy: 0.2672\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.7799 - accuracy: 0.2611 - val_loss: 2.7284 - val_accuracy: 0.2566\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.7184 - accuracy: 0.2720 - val_loss: 2.6750 - val_accuracy: 0.2513\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.6598 - accuracy: 0.2758 - val_loss: 2.6128 - val_accuracy: 0.2725\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.6065 - accuracy: 0.2815 - val_loss: 2.5600 - val_accuracy: 0.2672\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.5563 - accuracy: 0.2771 - val_loss: 2.5164 - val_accuracy: 0.2778\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.5207 - accuracy: 0.2790 - val_loss: 2.4790 - val_accuracy: 0.2804\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.4695 - accuracy: 0.2783 - val_loss: 2.4468 - val_accuracy: 0.2804\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.4439 - accuracy: 0.2752 - val_loss: 2.4068 - val_accuracy: 0.2857\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.4086 - accuracy: 0.2885 - val_loss: 2.3607 - val_accuracy: 0.2910\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.3681 - accuracy: 0.2987 - val_loss: 2.3619 - val_accuracy: 0.2698\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.3434 - accuracy: 0.2930 - val_loss: 2.3102 - val_accuracy: 0.3042\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.3013 - accuracy: 0.2987 - val_loss: 2.2657 - val_accuracy: 0.3175\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.2694 - accuracy: 0.3038 - val_loss: 2.2558 - val_accuracy: 0.3042\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.2588 - accuracy: 0.3000 - val_loss: 2.2343 - val_accuracy: 0.2937\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.2237 - accuracy: 0.3102 - val_loss: 2.2212 - val_accuracy: 0.2989\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.1991 - accuracy: 0.3025 - val_loss: 2.2011 - val_accuracy: 0.2937\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.1881 - accuracy: 0.2981 - val_loss: 2.2048 - val_accuracy: 0.2698\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.1506 - accuracy: 0.3070 - val_loss: 2.1451 - val_accuracy: 0.2989\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.1422 - accuracy: 0.3070 - val_loss: 2.1337 - val_accuracy: 0.3148\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1337 - accuracy: 0.3148\n",
      "Fold 1 - Validation Loss: 2.1337, Validation Accuracy: 0.3148\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 5s 28ms/step - loss: 3.3290 - accuracy: 0.1558 - val_loss: 3.2384 - val_accuracy: 0.1792\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.1982 - accuracy: 0.1736 - val_loss: 3.1229 - val_accuracy: 0.2421\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 3.0955 - accuracy: 0.1890 - val_loss: 3.0182 - val_accuracy: 0.2547\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.9979 - accuracy: 0.2325 - val_loss: 2.9208 - val_accuracy: 0.2987\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.9142 - accuracy: 0.2294 - val_loss: 2.8234 - val_accuracy: 0.3050\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.8310 - accuracy: 0.2417 - val_loss: 2.7387 - val_accuracy: 0.2799\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.7612 - accuracy: 0.2466 - val_loss: 2.6631 - val_accuracy: 0.2642\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.6908 - accuracy: 0.2620 - val_loss: 2.6042 - val_accuracy: 0.3019\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.6137 - accuracy: 0.2816 - val_loss: 2.5321 - val_accuracy: 0.3050\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.5604 - accuracy: 0.2828 - val_loss: 2.4787 - val_accuracy: 0.3019\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.5115 - accuracy: 0.2853 - val_loss: 2.4171 - val_accuracy: 0.3019\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 2.4563 - accuracy: 0.2883 - val_loss: 2.3672 - val_accuracy: 0.3113\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 2.4203 - accuracy: 0.2804 - val_loss: 2.3411 - val_accuracy: 0.2987\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3752 - accuracy: 0.2994 - val_loss: 2.2928 - val_accuracy: 0.3113\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3395 - accuracy: 0.2933 - val_loss: 2.2522 - val_accuracy: 0.3176\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3047 - accuracy: 0.2926 - val_loss: 2.2241 - val_accuracy: 0.3270\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.2680 - accuracy: 0.3025 - val_loss: 2.1854 - val_accuracy: 0.3208\n",
      "Epoch 18/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.2447 - accuracy: 0.2975 - val_loss: 2.1659 - val_accuracy: 0.3365\n",
      "Epoch 19/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.2107 - accuracy: 0.2969 - val_loss: 2.1413 - val_accuracy: 0.3176\n",
      "Epoch 20/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1780 - accuracy: 0.3037 - val_loss: 2.1276 - val_accuracy: 0.3270\n",
      "Epoch 21/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1587 - accuracy: 0.3227 - val_loss: 2.0910 - val_accuracy: 0.3396\n",
      "Epoch 22/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1457 - accuracy: 0.3049 - val_loss: 2.0663 - val_accuracy: 0.3239\n",
      "Epoch 23/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1098 - accuracy: 0.3110 - val_loss: 2.0650 - val_accuracy: 0.3145\n",
      "Epoch 24/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0906 - accuracy: 0.3153 - val_loss: 2.0328 - val_accuracy: 0.3270\n",
      "Epoch 25/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0569 - accuracy: 0.3258 - val_loss: 2.0201 - val_accuracy: 0.3176\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.0201 - accuracy: 0.3176\n",
      "Fold 2 - Validation Loss: 2.0201, Validation Accuracy: 0.3176\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 30ms/step - loss: 3.2882 - accuracy: 0.1590 - val_loss: 3.2285 - val_accuracy: 0.1810\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1769 - accuracy: 0.2068 - val_loss: 3.1333 - val_accuracy: 0.1976\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0810 - accuracy: 0.2291 - val_loss: 3.0446 - val_accuracy: 0.2095\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9906 - accuracy: 0.2349 - val_loss: 2.9571 - val_accuracy: 0.2262\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9007 - accuracy: 0.2493 - val_loss: 2.8711 - val_accuracy: 0.2262\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8017 - accuracy: 0.2651 - val_loss: 2.7973 - val_accuracy: 0.2238\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7243 - accuracy: 0.2690 - val_loss: 2.7389 - val_accuracy: 0.2452\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6558 - accuracy: 0.2520 - val_loss: 2.6885 - val_accuracy: 0.2405\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6047 - accuracy: 0.2664 - val_loss: 2.6229 - val_accuracy: 0.2429\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5492 - accuracy: 0.2827 - val_loss: 2.5781 - val_accuracy: 0.2524\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5009 - accuracy: 0.2768 - val_loss: 2.5228 - val_accuracy: 0.2500\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4511 - accuracy: 0.2880 - val_loss: 2.4757 - val_accuracy: 0.2690\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4230 - accuracy: 0.2899 - val_loss: 2.4471 - val_accuracy: 0.2667\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3820 - accuracy: 0.2808 - val_loss: 2.4059 - val_accuracy: 0.2667\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3409 - accuracy: 0.2997 - val_loss: 2.3610 - val_accuracy: 0.2833\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3110 - accuracy: 0.3043 - val_loss: 2.3372 - val_accuracy: 0.2690\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2750 - accuracy: 0.2906 - val_loss: 2.3073 - val_accuracy: 0.2762\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.2372 - accuracy: 0.3037 - val_loss: 2.2815 - val_accuracy: 0.2714\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2228 - accuracy: 0.2997 - val_loss: 2.2630 - val_accuracy: 0.2786\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1892 - accuracy: 0.3089 - val_loss: 2.2331 - val_accuracy: 0.2714\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1689 - accuracy: 0.3109 - val_loss: 2.2023 - val_accuracy: 0.2881\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1447 - accuracy: 0.3135 - val_loss: 2.1903 - val_accuracy: 0.2929\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1281 - accuracy: 0.2958 - val_loss: 2.1611 - val_accuracy: 0.2738\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0922 - accuracy: 0.3226 - val_loss: 2.1480 - val_accuracy: 0.2952\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0760 - accuracy: 0.3253 - val_loss: 2.1165 - val_accuracy: 0.2857\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.1165 - accuracy: 0.2857\n",
      "Fold 3 - Validation Loss: 2.1165, Validation Accuracy: 0.2857\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 3.2784 - accuracy: 0.1710 - val_loss: 3.2132 - val_accuracy: 0.2043\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1765 - accuracy: 0.2004 - val_loss: 3.1196 - val_accuracy: 0.2452\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0849 - accuracy: 0.2330 - val_loss: 3.0296 - val_accuracy: 0.2404\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9907 - accuracy: 0.2389 - val_loss: 2.9337 - val_accuracy: 0.2620\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8899 - accuracy: 0.2637 - val_loss: 2.8461 - val_accuracy: 0.2572\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8144 - accuracy: 0.2572 - val_loss: 2.7655 - val_accuracy: 0.2500\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7325 - accuracy: 0.2859 - val_loss: 2.7052 - val_accuracy: 0.2500\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6745 - accuracy: 0.2650 - val_loss: 2.6465 - val_accuracy: 0.2476\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6033 - accuracy: 0.2885 - val_loss: 2.6081 - val_accuracy: 0.2380\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5477 - accuracy: 0.2794 - val_loss: 2.5573 - val_accuracy: 0.2668\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5032 - accuracy: 0.2931 - val_loss: 2.5009 - val_accuracy: 0.2692\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4544 - accuracy: 0.2911 - val_loss: 2.4617 - val_accuracy: 0.2812\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4070 - accuracy: 0.2977 - val_loss: 2.4264 - val_accuracy: 0.2812\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3705 - accuracy: 0.2990 - val_loss: 2.3804 - val_accuracy: 0.2764\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3329 - accuracy: 0.3068 - val_loss: 2.3597 - val_accuracy: 0.2885\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2991 - accuracy: 0.3140 - val_loss: 2.3221 - val_accuracy: 0.2861\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2632 - accuracy: 0.3114 - val_loss: 2.3063 - val_accuracy: 0.2668\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.2304 - accuracy: 0.3140 - val_loss: 2.2663 - val_accuracy: 0.2861\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2033 - accuracy: 0.3257 - val_loss: 2.2649 - val_accuracy: 0.2788\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1708 - accuracy: 0.3192 - val_loss: 2.2426 - val_accuracy: 0.2716\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1605 - accuracy: 0.3225 - val_loss: 2.1734 - val_accuracy: 0.2957\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1246 - accuracy: 0.3198 - val_loss: 2.1690 - val_accuracy: 0.2788\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0997 - accuracy: 0.3433 - val_loss: 2.1397 - val_accuracy: 0.2885\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0785 - accuracy: 0.3460 - val_loss: 2.1270 - val_accuracy: 0.2837\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0590 - accuracy: 0.3329 - val_loss: 2.1091 - val_accuracy: 0.2909\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1091 - accuracy: 0.2909\n",
      "Fold 4 - Validation Loss: 2.1091, Validation Accuracy: 0.2909\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 28ms/step - loss: 3.3000 - accuracy: 0.1710 - val_loss: 3.2372 - val_accuracy: 0.2404\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1812 - accuracy: 0.2115 - val_loss: 3.1388 - val_accuracy: 0.2139\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0944 - accuracy: 0.2219 - val_loss: 3.0496 - val_accuracy: 0.2404\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9932 - accuracy: 0.2441 - val_loss: 2.9691 - val_accuracy: 0.2308\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9076 - accuracy: 0.2428 - val_loss: 2.8987 - val_accuracy: 0.2260\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8318 - accuracy: 0.2565 - val_loss: 2.8285 - val_accuracy: 0.2332\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7558 - accuracy: 0.2559 - val_loss: 2.7683 - val_accuracy: 0.2380\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6887 - accuracy: 0.2826 - val_loss: 2.7295 - val_accuracy: 0.2356\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6355 - accuracy: 0.2670 - val_loss: 2.6660 - val_accuracy: 0.2596\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.5772 - accuracy: 0.2813 - val_loss: 2.6225 - val_accuracy: 0.2500\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5231 - accuracy: 0.2833 - val_loss: 2.6026 - val_accuracy: 0.2548\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4866 - accuracy: 0.2872 - val_loss: 2.5472 - val_accuracy: 0.2428\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4293 - accuracy: 0.2957 - val_loss: 2.5186 - val_accuracy: 0.2596\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3956 - accuracy: 0.3029 - val_loss: 2.4625 - val_accuracy: 0.2644\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3597 - accuracy: 0.2977 - val_loss: 2.4406 - val_accuracy: 0.2500\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3132 - accuracy: 0.3238 - val_loss: 2.4285 - val_accuracy: 0.2572\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2900 - accuracy: 0.3231 - val_loss: 2.3608 - val_accuracy: 0.2740\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2614 - accuracy: 0.3061 - val_loss: 2.3930 - val_accuracy: 0.2452\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2166 - accuracy: 0.3101 - val_loss: 2.3117 - val_accuracy: 0.2764\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1982 - accuracy: 0.3081 - val_loss: 2.2864 - val_accuracy: 0.2620\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1751 - accuracy: 0.3264 - val_loss: 2.3191 - val_accuracy: 0.2500\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1507 - accuracy: 0.3179 - val_loss: 2.2843 - val_accuracy: 0.2572\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1256 - accuracy: 0.3309 - val_loss: 2.3072 - val_accuracy: 0.2380\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0882 - accuracy: 0.3316 - val_loss: 2.2824 - val_accuracy: 0.2548\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0759 - accuracy: 0.3375 - val_loss: 2.2283 - val_accuracy: 0.2572\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2283 - accuracy: 0.2572\n",
      "Fold 5 - Validation Loss: 2.2283, Validation Accuracy: 0.2572\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 4s 27ms/step - loss: 3.3037 - accuracy: 0.1471 - val_loss: 3.2488 - val_accuracy: 0.1772\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 3.2171 - accuracy: 0.1662 - val_loss: 3.1670 - val_accuracy: 0.2011\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 3.1337 - accuracy: 0.1955 - val_loss: 3.0933 - val_accuracy: 0.2275\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 3.0671 - accuracy: 0.2000 - val_loss: 3.0224 - val_accuracy: 0.2513\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.9961 - accuracy: 0.2223 - val_loss: 2.9560 - val_accuracy: 0.2381\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.9313 - accuracy: 0.2236 - val_loss: 2.8875 - val_accuracy: 0.2593\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.8729 - accuracy: 0.2185 - val_loss: 2.8244 - val_accuracy: 0.2487\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.8084 - accuracy: 0.2382 - val_loss: 2.7669 - val_accuracy: 0.2540\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.7441 - accuracy: 0.2490 - val_loss: 2.7063 - val_accuracy: 0.2593\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.6878 - accuracy: 0.2669 - val_loss: 2.6509 - val_accuracy: 0.2407\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.6380 - accuracy: 0.2599 - val_loss: 2.5908 - val_accuracy: 0.2884\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.5838 - accuracy: 0.2611 - val_loss: 2.5446 - val_accuracy: 0.2434\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.5382 - accuracy: 0.2631 - val_loss: 2.5010 - val_accuracy: 0.2434\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.5040 - accuracy: 0.2847 - val_loss: 2.4616 - val_accuracy: 0.2566\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.4566 - accuracy: 0.2764 - val_loss: 2.4366 - val_accuracy: 0.2381\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.4194 - accuracy: 0.2790 - val_loss: 2.3957 - val_accuracy: 0.2646\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.3857 - accuracy: 0.2892 - val_loss: 2.3611 - val_accuracy: 0.2778\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.3583 - accuracy: 0.2758 - val_loss: 2.3317 - val_accuracy: 0.2804\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.3270 - accuracy: 0.2873 - val_loss: 2.3096 - val_accuracy: 0.2884\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.3004 - accuracy: 0.2962 - val_loss: 2.2825 - val_accuracy: 0.2751\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.2750 - accuracy: 0.2943 - val_loss: 2.2577 - val_accuracy: 0.2804\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.2450 - accuracy: 0.2854 - val_loss: 2.2199 - val_accuracy: 0.3095\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.2319 - accuracy: 0.2994 - val_loss: 2.2179 - val_accuracy: 0.2884\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.2081 - accuracy: 0.3045 - val_loss: 2.1769 - val_accuracy: 0.2963\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.1716 - accuracy: 0.3064 - val_loss: 2.1607 - val_accuracy: 0.3254\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1607 - accuracy: 0.3254\n",
      "Fold 1 - Validation Loss: 2.1607, Validation Accuracy: 0.3254\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 4s 28ms/step - loss: 3.3124 - accuracy: 0.1393 - val_loss: 3.2371 - val_accuracy: 0.2044\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 3.1985 - accuracy: 0.1712 - val_loss: 3.1299 - val_accuracy: 0.3050\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 3.1091 - accuracy: 0.1902 - val_loss: 3.0395 - val_accuracy: 0.3145\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.0194 - accuracy: 0.2184 - val_loss: 2.9506 - val_accuracy: 0.2925\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.9438 - accuracy: 0.2239 - val_loss: 2.8630 - val_accuracy: 0.3113\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.8597 - accuracy: 0.2356 - val_loss: 2.7823 - val_accuracy: 0.2956\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.7809 - accuracy: 0.2393 - val_loss: 2.7002 - val_accuracy: 0.2956\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.7186 - accuracy: 0.2607 - val_loss: 2.6264 - val_accuracy: 0.3270\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.6549 - accuracy: 0.2540 - val_loss: 2.5645 - val_accuracy: 0.3050\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.6036 - accuracy: 0.2613 - val_loss: 2.5198 - val_accuracy: 0.3145\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.5499 - accuracy: 0.2681 - val_loss: 2.4608 - val_accuracy: 0.3113\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.4930 - accuracy: 0.2607 - val_loss: 2.4099 - val_accuracy: 0.3113\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.4555 - accuracy: 0.2822 - val_loss: 2.3702 - val_accuracy: 0.3239\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.4252 - accuracy: 0.2613 - val_loss: 2.3248 - val_accuracy: 0.3459\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3756 - accuracy: 0.2718 - val_loss: 2.2872 - val_accuracy: 0.3239\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3447 - accuracy: 0.2902 - val_loss: 2.2694 - val_accuracy: 0.3208\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3245 - accuracy: 0.2693 - val_loss: 2.2204 - val_accuracy: 0.3459\n",
      "Epoch 18/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.2908 - accuracy: 0.2939 - val_loss: 2.2064 - val_accuracy: 0.3082\n",
      "Epoch 19/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.2578 - accuracy: 0.2828 - val_loss: 2.1701 - val_accuracy: 0.3333\n",
      "Epoch 20/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.2360 - accuracy: 0.2816 - val_loss: 2.1513 - val_accuracy: 0.2987\n",
      "Epoch 21/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.2147 - accuracy: 0.2712 - val_loss: 2.1208 - val_accuracy: 0.3333\n",
      "Epoch 22/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1870 - accuracy: 0.2926 - val_loss: 2.1105 - val_accuracy: 0.3019\n",
      "Epoch 23/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1590 - accuracy: 0.2902 - val_loss: 2.0936 - val_accuracy: 0.3208\n",
      "Epoch 24/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1302 - accuracy: 0.2969 - val_loss: 2.0823 - val_accuracy: 0.3082\n",
      "Epoch 25/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1056 - accuracy: 0.2963 - val_loss: 2.0726 - val_accuracy: 0.2956\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.0726 - accuracy: 0.2956\n",
      "Fold 2 - Validation Loss: 2.0726, Validation Accuracy: 0.2956\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 30ms/step - loss: 3.3063 - accuracy: 0.1545 - val_loss: 3.2477 - val_accuracy: 0.1643\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.2086 - accuracy: 0.1898 - val_loss: 3.1698 - val_accuracy: 0.1738\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1367 - accuracy: 0.1924 - val_loss: 3.0999 - val_accuracy: 0.1857\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0570 - accuracy: 0.2147 - val_loss: 3.0292 - val_accuracy: 0.2214\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9874 - accuracy: 0.2343 - val_loss: 2.9602 - val_accuracy: 0.2405\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9107 - accuracy: 0.2336 - val_loss: 2.8956 - val_accuracy: 0.2357\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.8385 - accuracy: 0.2330 - val_loss: 2.8309 - val_accuracy: 0.2167\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.7693 - accuracy: 0.2369 - val_loss: 2.7721 - val_accuracy: 0.2286\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7205 - accuracy: 0.2376 - val_loss: 2.7211 - val_accuracy: 0.2071\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6627 - accuracy: 0.2572 - val_loss: 2.6704 - val_accuracy: 0.2310\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6144 - accuracy: 0.2611 - val_loss: 2.6249 - val_accuracy: 0.2286\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5668 - accuracy: 0.2709 - val_loss: 2.5913 - val_accuracy: 0.2286\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5336 - accuracy: 0.2657 - val_loss: 2.5378 - val_accuracy: 0.2357\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4924 - accuracy: 0.2677 - val_loss: 2.4988 - val_accuracy: 0.2429\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4608 - accuracy: 0.2585 - val_loss: 2.4631 - val_accuracy: 0.2548\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.4258 - accuracy: 0.2651 - val_loss: 2.4287 - val_accuracy: 0.2619\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3874 - accuracy: 0.2736 - val_loss: 2.4039 - val_accuracy: 0.2738\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3488 - accuracy: 0.2729 - val_loss: 2.3773 - val_accuracy: 0.2738\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.3227 - accuracy: 0.2795 - val_loss: 2.3418 - val_accuracy: 0.2690\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 2.2959 - accuracy: 0.2893 - val_loss: 2.3298 - val_accuracy: 0.2810\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 2.2776 - accuracy: 0.2880 - val_loss: 2.2950 - val_accuracy: 0.2714\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 2.2523 - accuracy: 0.2873 - val_loss: 2.2601 - val_accuracy: 0.2881\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.2198 - accuracy: 0.2932 - val_loss: 2.2420 - val_accuracy: 0.2929\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1991 - accuracy: 0.2801 - val_loss: 2.2225 - val_accuracy: 0.3000\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1811 - accuracy: 0.2938 - val_loss: 2.2016 - val_accuracy: 0.2857\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.2016 - accuracy: 0.2857\n",
      "Fold 3 - Validation Loss: 2.2016, Validation Accuracy: 0.2857\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 3.3108 - accuracy: 0.1580 - val_loss: 3.2368 - val_accuracy: 0.2091\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 3.2064 - accuracy: 0.1756 - val_loss: 3.1498 - val_accuracy: 0.2668\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1250 - accuracy: 0.2082 - val_loss: 3.0651 - val_accuracy: 0.2716\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0365 - accuracy: 0.2219 - val_loss: 2.9811 - val_accuracy: 0.2837\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9670 - accuracy: 0.2343 - val_loss: 2.8977 - val_accuracy: 0.2692\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8775 - accuracy: 0.2585 - val_loss: 2.8156 - val_accuracy: 0.2740\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.8125 - accuracy: 0.2448 - val_loss: 2.7538 - val_accuracy: 0.2788\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7401 - accuracy: 0.2611 - val_loss: 2.6922 - val_accuracy: 0.2764\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6801 - accuracy: 0.2657 - val_loss: 2.6344 - val_accuracy: 0.2716\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6308 - accuracy: 0.2728 - val_loss: 2.5917 - val_accuracy: 0.2909\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5674 - accuracy: 0.2879 - val_loss: 2.5465 - val_accuracy: 0.2933\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.5346 - accuracy: 0.2683 - val_loss: 2.4987 - val_accuracy: 0.2909\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4951 - accuracy: 0.2839 - val_loss: 2.4685 - val_accuracy: 0.2885\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.4494 - accuracy: 0.2885 - val_loss: 2.4349 - val_accuracy: 0.2861\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.4230 - accuracy: 0.2644 - val_loss: 2.4003 - val_accuracy: 0.2837\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3853 - accuracy: 0.2937 - val_loss: 2.3761 - val_accuracy: 0.2885\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3436 - accuracy: 0.3029 - val_loss: 2.3475 - val_accuracy: 0.3053\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.3000 - accuracy: 0.2911 - val_loss: 2.3037 - val_accuracy: 0.3149\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.2844 - accuracy: 0.2950 - val_loss: 2.2852 - val_accuracy: 0.3077\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2498 - accuracy: 0.3101 - val_loss: 2.2795 - val_accuracy: 0.2909\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.2363 - accuracy: 0.2905 - val_loss: 2.2441 - val_accuracy: 0.2957\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.2118 - accuracy: 0.3003 - val_loss: 2.2278 - val_accuracy: 0.3005\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1843 - accuracy: 0.3087 - val_loss: 2.2055 - val_accuracy: 0.3005\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1649 - accuracy: 0.3009 - val_loss: 2.1745 - val_accuracy: 0.2957\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1448 - accuracy: 0.3192 - val_loss: 2.1553 - val_accuracy: 0.3173\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1553 - accuracy: 0.3173\n",
      "Fold 4 - Validation Loss: 2.1553, Validation Accuracy: 0.3173\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 3.3192 - accuracy: 0.1501 - val_loss: 3.2549 - val_accuracy: 0.1635\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 3.2092 - accuracy: 0.1867 - val_loss: 3.1702 - val_accuracy: 0.1803\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1402 - accuracy: 0.1775 - val_loss: 3.0947 - val_accuracy: 0.1899\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 3.0619 - accuracy: 0.1952 - val_loss: 3.0239 - val_accuracy: 0.1971\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.9810 - accuracy: 0.2121 - val_loss: 2.9571 - val_accuracy: 0.1851\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.9116 - accuracy: 0.2448 - val_loss: 2.8898 - val_accuracy: 0.1947\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.8301 - accuracy: 0.2493 - val_loss: 2.8266 - val_accuracy: 0.2188\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7553 - accuracy: 0.2480 - val_loss: 2.7684 - val_accuracy: 0.2284\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7013 - accuracy: 0.2539 - val_loss: 2.7119 - val_accuracy: 0.2380\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.6424 - accuracy: 0.2689 - val_loss: 2.6735 - val_accuracy: 0.2260\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5933 - accuracy: 0.2572 - val_loss: 2.6365 - val_accuracy: 0.2284\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.5327 - accuracy: 0.2748 - val_loss: 2.5905 - val_accuracy: 0.2308\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4876 - accuracy: 0.2715 - val_loss: 2.5645 - val_accuracy: 0.2404\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4439 - accuracy: 0.2937 - val_loss: 2.5255 - val_accuracy: 0.2452\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4201 - accuracy: 0.2657 - val_loss: 2.4886 - val_accuracy: 0.2428\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3758 - accuracy: 0.2820 - val_loss: 2.4826 - val_accuracy: 0.2452\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3579 - accuracy: 0.2709 - val_loss: 2.4131 - val_accuracy: 0.2452\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.3122 - accuracy: 0.2911 - val_loss: 2.4069 - val_accuracy: 0.2380\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2844 - accuracy: 0.2977 - val_loss: 2.3675 - val_accuracy: 0.2452\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2559 - accuracy: 0.2944 - val_loss: 2.3478 - val_accuracy: 0.2404\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2285 - accuracy: 0.2885 - val_loss: 2.3249 - val_accuracy: 0.2308\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.2096 - accuracy: 0.2990 - val_loss: 2.3336 - val_accuracy: 0.2308\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.1901 - accuracy: 0.2931 - val_loss: 2.3409 - val_accuracy: 0.2308\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1670 - accuracy: 0.2970 - val_loss: 2.3089 - val_accuracy: 0.2356\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1200 - accuracy: 0.3094 - val_loss: 2.2634 - val_accuracy: 0.2452\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.2634 - accuracy: 0.2452\n",
      "Fold 5 - Validation Loss: 2.2634, Validation Accuracy: 0.2452\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 4s 28ms/step - loss: 3.3488 - accuracy: 0.1490 - val_loss: 3.2715 - val_accuracy: 0.1772\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 3.2580 - accuracy: 0.1790 - val_loss: 3.1947 - val_accuracy: 0.2487\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 3.1878 - accuracy: 0.1662 - val_loss: 3.1274 - val_accuracy: 0.2540\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 3.1197 - accuracy: 0.1879 - val_loss: 3.0637 - val_accuracy: 0.2407\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 3.0574 - accuracy: 0.2000 - val_loss: 3.0007 - val_accuracy: 0.2354\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 3.0025 - accuracy: 0.2166 - val_loss: 2.9429 - val_accuracy: 0.2328\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.9380 - accuracy: 0.2121 - val_loss: 2.8871 - val_accuracy: 0.2407\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.8889 - accuracy: 0.2242 - val_loss: 2.8370 - val_accuracy: 0.2302\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.8423 - accuracy: 0.2236 - val_loss: 2.7870 - val_accuracy: 0.2328\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.7901 - accuracy: 0.2382 - val_loss: 2.7286 - val_accuracy: 0.2196\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.7435 - accuracy: 0.2312 - val_loss: 2.6784 - val_accuracy: 0.2407\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.6891 - accuracy: 0.2618 - val_loss: 2.6368 - val_accuracy: 0.2275\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.6463 - accuracy: 0.2631 - val_loss: 2.5961 - val_accuracy: 0.2275\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.6213 - accuracy: 0.2465 - val_loss: 2.5552 - val_accuracy: 0.2381\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.5752 - accuracy: 0.2529 - val_loss: 2.5207 - val_accuracy: 0.2381\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.5554 - accuracy: 0.2637 - val_loss: 2.5031 - val_accuracy: 0.2302\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.5002 - accuracy: 0.2790 - val_loss: 2.4673 - val_accuracy: 0.2222\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.4849 - accuracy: 0.2656 - val_loss: 2.4310 - val_accuracy: 0.2434\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.4629 - accuracy: 0.2561 - val_loss: 2.4052 - val_accuracy: 0.2540\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.4121 - accuracy: 0.2777 - val_loss: 2.3744 - val_accuracy: 0.2540\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.3945 - accuracy: 0.2662 - val_loss: 2.3486 - val_accuracy: 0.2619\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.3622 - accuracy: 0.2605 - val_loss: 2.3214 - val_accuracy: 0.2593\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.3602 - accuracy: 0.2522 - val_loss: 2.3282 - val_accuracy: 0.2328\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.3265 - accuracy: 0.2624 - val_loss: 2.2754 - val_accuracy: 0.2751\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.3116 - accuracy: 0.2713 - val_loss: 2.2504 - val_accuracy: 0.2937\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2504 - accuracy: 0.2937\n",
      "Fold 1 - Validation Loss: 2.2504, Validation Accuracy: 0.2937\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 4s 28ms/step - loss: 3.3518 - accuracy: 0.1344 - val_loss: 3.2691 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.2796 - accuracy: 0.1393 - val_loss: 3.1885 - val_accuracy: 0.2579\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.1873 - accuracy: 0.1736 - val_loss: 3.1185 - val_accuracy: 0.2579\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.1224 - accuracy: 0.1742 - val_loss: 3.0603 - val_accuracy: 0.2358\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.0682 - accuracy: 0.1761 - val_loss: 2.9932 - val_accuracy: 0.2610\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 3.0017 - accuracy: 0.2184 - val_loss: 2.9351 - val_accuracy: 0.2642\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.9625 - accuracy: 0.1994 - val_loss: 2.8838 - val_accuracy: 0.2642\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.9063 - accuracy: 0.2061 - val_loss: 2.8275 - val_accuracy: 0.3050\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.8554 - accuracy: 0.2123 - val_loss: 2.7636 - val_accuracy: 0.2893\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.8062 - accuracy: 0.2227 - val_loss: 2.7224 - val_accuracy: 0.2956\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.7616 - accuracy: 0.2215 - val_loss: 2.6810 - val_accuracy: 0.2736\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.7081 - accuracy: 0.2466 - val_loss: 2.6386 - val_accuracy: 0.2893\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.6731 - accuracy: 0.2411 - val_loss: 2.5844 - val_accuracy: 0.2925\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.6446 - accuracy: 0.2282 - val_loss: 2.5503 - val_accuracy: 0.2862\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.5977 - accuracy: 0.2350 - val_loss: 2.4966 - val_accuracy: 0.3050\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.5708 - accuracy: 0.2479 - val_loss: 2.4769 - val_accuracy: 0.2830\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.5311 - accuracy: 0.2571 - val_loss: 2.4408 - val_accuracy: 0.2956\n",
      "Epoch 18/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.4930 - accuracy: 0.2442 - val_loss: 2.4019 - val_accuracy: 0.3145\n",
      "Epoch 19/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.4644 - accuracy: 0.2429 - val_loss: 2.3732 - val_accuracy: 0.2987\n",
      "Epoch 20/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.4447 - accuracy: 0.2460 - val_loss: 2.3501 - val_accuracy: 0.2925\n",
      "Epoch 21/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.4069 - accuracy: 0.2503 - val_loss: 2.3126 - val_accuracy: 0.3050\n",
      "Epoch 22/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.3918 - accuracy: 0.2601 - val_loss: 2.2852 - val_accuracy: 0.3019\n",
      "Epoch 23/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.3622 - accuracy: 0.2411 - val_loss: 2.2624 - val_accuracy: 0.2987\n",
      "Epoch 24/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3501 - accuracy: 0.2454 - val_loss: 2.2466 - val_accuracy: 0.2925\n",
      "Epoch 25/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.3220 - accuracy: 0.2706 - val_loss: 2.2308 - val_accuracy: 0.2987\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.2308 - accuracy: 0.2987\n",
      "Fold 2 - Validation Loss: 2.2308, Validation Accuracy: 0.2987\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 3.3567 - accuracy: 0.1243 - val_loss: 3.2879 - val_accuracy: 0.1429\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.2917 - accuracy: 0.1270 - val_loss: 3.2194 - val_accuracy: 0.1643\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.2040 - accuracy: 0.1669 - val_loss: 3.1576 - val_accuracy: 0.1905\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1483 - accuracy: 0.1787 - val_loss: 3.1023 - val_accuracy: 0.2143\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 3.0996 - accuracy: 0.1688 - val_loss: 3.0498 - val_accuracy: 0.2048\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0513 - accuracy: 0.1688 - val_loss: 2.9998 - val_accuracy: 0.2190\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9952 - accuracy: 0.1806 - val_loss: 2.9520 - val_accuracy: 0.2119\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9344 - accuracy: 0.1904 - val_loss: 2.9028 - val_accuracy: 0.2095\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8840 - accuracy: 0.1944 - val_loss: 2.8554 - val_accuracy: 0.2119\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.8454 - accuracy: 0.2035 - val_loss: 2.8104 - val_accuracy: 0.2000\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7979 - accuracy: 0.2160 - val_loss: 2.7668 - val_accuracy: 0.2071\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7522 - accuracy: 0.2205 - val_loss: 2.7269 - val_accuracy: 0.1976\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.7168 - accuracy: 0.2179 - val_loss: 2.6884 - val_accuracy: 0.2000\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6657 - accuracy: 0.2389 - val_loss: 2.6556 - val_accuracy: 0.2095\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6264 - accuracy: 0.2395 - val_loss: 2.6199 - val_accuracy: 0.1857\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5922 - accuracy: 0.2408 - val_loss: 2.5927 - val_accuracy: 0.2000\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5537 - accuracy: 0.2376 - val_loss: 2.5652 - val_accuracy: 0.2000\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5262 - accuracy: 0.2376 - val_loss: 2.5330 - val_accuracy: 0.2119\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4989 - accuracy: 0.2304 - val_loss: 2.4983 - val_accuracy: 0.2190\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4616 - accuracy: 0.2474 - val_loss: 2.4747 - val_accuracy: 0.2190\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4325 - accuracy: 0.2487 - val_loss: 2.4576 - val_accuracy: 0.2143\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4109 - accuracy: 0.2441 - val_loss: 2.4328 - val_accuracy: 0.2119\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3943 - accuracy: 0.2441 - val_loss: 2.4109 - val_accuracy: 0.1952\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3575 - accuracy: 0.2467 - val_loss: 2.3835 - val_accuracy: 0.2048\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3295 - accuracy: 0.2683 - val_loss: 2.3599 - val_accuracy: 0.2143\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.3599 - accuracy: 0.2143\n",
      "Fold 3 - Validation Loss: 2.3599, Validation Accuracy: 0.2143\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 28ms/step - loss: 3.3644 - accuracy: 0.1129 - val_loss: 3.2781 - val_accuracy: 0.1755\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.2674 - accuracy: 0.1430 - val_loss: 3.2039 - val_accuracy: 0.1827\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.2064 - accuracy: 0.1580 - val_loss: 3.1382 - val_accuracy: 0.2188\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 3.1323 - accuracy: 0.1645 - val_loss: 3.0763 - val_accuracy: 0.2524\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0719 - accuracy: 0.1691 - val_loss: 3.0205 - val_accuracy: 0.2404\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0164 - accuracy: 0.1697 - val_loss: 2.9629 - val_accuracy: 0.2716\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9674 - accuracy: 0.1971 - val_loss: 2.9091 - val_accuracy: 0.2837\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9133 - accuracy: 0.1847 - val_loss: 2.8563 - val_accuracy: 0.2716\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8560 - accuracy: 0.1952 - val_loss: 2.8063 - val_accuracy: 0.2764\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8075 - accuracy: 0.2050 - val_loss: 2.7574 - val_accuracy: 0.2837\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7514 - accuracy: 0.2278 - val_loss: 2.7035 - val_accuracy: 0.2837\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.7114 - accuracy: 0.2134 - val_loss: 2.6587 - val_accuracy: 0.2837\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6626 - accuracy: 0.2285 - val_loss: 2.6119 - val_accuracy: 0.2572\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.6297 - accuracy: 0.2154 - val_loss: 2.5629 - val_accuracy: 0.2596\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5920 - accuracy: 0.2363 - val_loss: 2.5250 - val_accuracy: 0.2740\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.5324 - accuracy: 0.2448 - val_loss: 2.4894 - val_accuracy: 0.2716\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5025 - accuracy: 0.2441 - val_loss: 2.4451 - val_accuracy: 0.2692\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4587 - accuracy: 0.2539 - val_loss: 2.4090 - val_accuracy: 0.2644\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4404 - accuracy: 0.2415 - val_loss: 2.3791 - val_accuracy: 0.2788\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4107 - accuracy: 0.2487 - val_loss: 2.3561 - val_accuracy: 0.2740\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3721 - accuracy: 0.2598 - val_loss: 2.3267 - val_accuracy: 0.2740\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3472 - accuracy: 0.2585 - val_loss: 2.2999 - val_accuracy: 0.2909\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3371 - accuracy: 0.2513 - val_loss: 2.2856 - val_accuracy: 0.2981\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3056 - accuracy: 0.2768 - val_loss: 2.2657 - val_accuracy: 0.2909\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2703 - accuracy: 0.2663 - val_loss: 2.2369 - val_accuracy: 0.2957\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2369 - accuracy: 0.2957\n",
      "Fold 4 - Validation Loss: 2.2369, Validation Accuracy: 0.2957\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 28ms/step - loss: 3.3310 - accuracy: 0.1508 - val_loss: 3.2679 - val_accuracy: 0.1490\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.2602 - accuracy: 0.1573 - val_loss: 3.1999 - val_accuracy: 0.1827\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1992 - accuracy: 0.1599 - val_loss: 3.1397 - val_accuracy: 0.2284\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.1308 - accuracy: 0.1828 - val_loss: 3.0834 - val_accuracy: 0.2260\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0796 - accuracy: 0.1769 - val_loss: 3.0306 - val_accuracy: 0.2139\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 3.0188 - accuracy: 0.1913 - val_loss: 2.9761 - val_accuracy: 0.2236\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.9755 - accuracy: 0.1736 - val_loss: 2.9270 - val_accuracy: 0.2163\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.9187 - accuracy: 0.1906 - val_loss: 2.8813 - val_accuracy: 0.2212\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8752 - accuracy: 0.2148 - val_loss: 2.8288 - val_accuracy: 0.2380\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8222 - accuracy: 0.2141 - val_loss: 2.7855 - val_accuracy: 0.2356\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.7729 - accuracy: 0.2311 - val_loss: 2.7391 - val_accuracy: 0.2284\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.7218 - accuracy: 0.2226 - val_loss: 2.6995 - val_accuracy: 0.2356\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6766 - accuracy: 0.2383 - val_loss: 2.6529 - val_accuracy: 0.2476\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6429 - accuracy: 0.2376 - val_loss: 2.6179 - val_accuracy: 0.2404\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.6053 - accuracy: 0.2363 - val_loss: 2.5782 - val_accuracy: 0.2452\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.5617 - accuracy: 0.2428 - val_loss: 2.5506 - val_accuracy: 0.2452\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5290 - accuracy: 0.2461 - val_loss: 2.5139 - val_accuracy: 0.2524\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4891 - accuracy: 0.2422 - val_loss: 2.4900 - val_accuracy: 0.2428\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4593 - accuracy: 0.2676 - val_loss: 2.4472 - val_accuracy: 0.2500\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4245 - accuracy: 0.2624 - val_loss: 2.4286 - val_accuracy: 0.2332\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4066 - accuracy: 0.2644 - val_loss: 2.3945 - val_accuracy: 0.2476\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3656 - accuracy: 0.2722 - val_loss: 2.3765 - val_accuracy: 0.2500\n",
      "Epoch 23/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3434 - accuracy: 0.2846 - val_loss: 2.3790 - val_accuracy: 0.2308\n",
      "Epoch 24/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.3316 - accuracy: 0.2715 - val_loss: 2.3440 - val_accuracy: 0.2308\n",
      "Epoch 25/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3054 - accuracy: 0.2794 - val_loss: 2.3201 - val_accuracy: 0.2476\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3201 - accuracy: 0.2476\n",
      "Fold 5 - Validation Loss: 2.3201, Validation Accuracy: 0.2476\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 4s 28ms/step - loss: 2.9635 - accuracy: 0.1981 - val_loss: 2.6308 - val_accuracy: 0.2354\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.4449 - accuracy: 0.2268 - val_loss: 2.2417 - val_accuracy: 0.2407\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.1866 - accuracy: 0.2427 - val_loss: 2.1071 - val_accuracy: 0.2460\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.0521 - accuracy: 0.2599 - val_loss: 1.9425 - val_accuracy: 0.3069\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9935 - accuracy: 0.2656 - val_loss: 1.9093 - val_accuracy: 0.2778\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.9459 - accuracy: 0.2777 - val_loss: 1.8784 - val_accuracy: 0.2778\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.9019 - accuracy: 0.2815 - val_loss: 1.8516 - val_accuracy: 0.2910\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.8882 - accuracy: 0.2834 - val_loss: 1.8613 - val_accuracy: 0.2804\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.8896 - accuracy: 0.2752 - val_loss: 1.8384 - val_accuracy: 0.2910\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.8711 - accuracy: 0.2885 - val_loss: 1.8675 - val_accuracy: 0.2540\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8747 - accuracy: 0.2885 - val_loss: 1.9357 - val_accuracy: 0.1931\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8626 - accuracy: 0.2949 - val_loss: 1.8622 - val_accuracy: 0.3122\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8384 - accuracy: 0.2910\n",
      "Fold 1 - Validation Loss: 1.8384, Validation Accuracy: 0.2910\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 4s 28ms/step - loss: 2.9578 - accuracy: 0.2000 - val_loss: 2.5493 - val_accuracy: 0.2893\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.4039 - accuracy: 0.2337 - val_loss: 2.1845 - val_accuracy: 0.3113\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.1721 - accuracy: 0.2515 - val_loss: 1.9925 - val_accuracy: 0.3176\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.0654 - accuracy: 0.2448 - val_loss: 1.9321 - val_accuracy: 0.3082\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0051 - accuracy: 0.2595 - val_loss: 1.8739 - val_accuracy: 0.3145\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.9577 - accuracy: 0.2558 - val_loss: 1.8273 - val_accuracy: 0.3176\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.9327 - accuracy: 0.2620 - val_loss: 1.8077 - val_accuracy: 0.3082\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9529 - accuracy: 0.2521 - val_loss: 1.8578 - val_accuracy: 0.2673\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.9290 - accuracy: 0.2552 - val_loss: 1.8199 - val_accuracy: 0.3365\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.9008 - accuracy: 0.2742 - val_loss: 1.7824 - val_accuracy: 0.3239\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8999 - accuracy: 0.2663 - val_loss: 1.8083 - val_accuracy: 0.3239\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8801 - accuracy: 0.2712 - val_loss: 1.7804 - val_accuracy: 0.3145\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8558 - accuracy: 0.2798 - val_loss: 1.8162 - val_accuracy: 0.2704\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8794 - accuracy: 0.2761 - val_loss: 1.7469 - val_accuracy: 0.3145\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8501 - accuracy: 0.2994 - val_loss: 1.7496 - val_accuracy: 0.3365\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8435 - accuracy: 0.2877 - val_loss: 1.7552 - val_accuracy: 0.3145\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8513 - accuracy: 0.2822 - val_loss: 1.7356 - val_accuracy: 0.3239\n",
      "Epoch 18/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.8295 - accuracy: 0.2951 - val_loss: 1.7535 - val_accuracy: 0.3176\n",
      "Epoch 19/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8255 - accuracy: 0.3031 - val_loss: 1.7395 - val_accuracy: 0.3176\n",
      "Epoch 20/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 1.8207 - accuracy: 0.2969 - val_loss: 1.7439 - val_accuracy: 0.3113\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7356 - accuracy: 0.3239\n",
      "Fold 2 - Validation Loss: 1.7356, Validation Accuracy: 0.3239\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 28ms/step - loss: 2.9451 - accuracy: 0.2120 - val_loss: 2.6251 - val_accuracy: 0.2310\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4032 - accuracy: 0.2533 - val_loss: 2.3140 - val_accuracy: 0.1905\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1710 - accuracy: 0.2690 - val_loss: 2.1324 - val_accuracy: 0.2571\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0372 - accuracy: 0.2651 - val_loss: 2.0365 - val_accuracy: 0.2500\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9508 - accuracy: 0.2847 - val_loss: 1.9621 - val_accuracy: 0.2548\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9212 - accuracy: 0.2847 - val_loss: 1.9491 - val_accuracy: 0.2690\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9219 - accuracy: 0.2729 - val_loss: 1.9522 - val_accuracy: 0.2714\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8797 - accuracy: 0.2866 - val_loss: 1.8864 - val_accuracy: 0.2905\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.8787 - accuracy: 0.2821 - val_loss: 1.8877 - val_accuracy: 0.2857\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8552 - accuracy: 0.2906 - val_loss: 1.8843 - val_accuracy: 0.2833\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8210 - accuracy: 0.2912 - val_loss: 1.8718 - val_accuracy: 0.2762\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8317 - accuracy: 0.2938 - val_loss: 1.8563 - val_accuracy: 0.3190\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8244 - accuracy: 0.3037 - val_loss: 1.8608 - val_accuracy: 0.2976\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8191 - accuracy: 0.2880 - val_loss: 1.8341 - val_accuracy: 0.2762\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8092 - accuracy: 0.3030 - val_loss: 1.8425 - val_accuracy: 0.2738\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8167 - accuracy: 0.3063 - val_loss: 1.8508 - val_accuracy: 0.2952\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.7976 - accuracy: 0.2978 - val_loss: 1.8331 - val_accuracy: 0.3071\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.7912 - accuracy: 0.3024 - val_loss: 1.8688 - val_accuracy: 0.3024\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.7893 - accuracy: 0.2938 - val_loss: 1.7941 - val_accuracy: 0.3095\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.7932 - accuracy: 0.3050 - val_loss: 1.8078 - val_accuracy: 0.3071\n",
      "Epoch 21/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8139 - accuracy: 0.2925 - val_loss: 1.8719 - val_accuracy: 0.2905\n",
      "Epoch 22/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.7832 - accuracy: 0.3135 - val_loss: 1.8098 - val_accuracy: 0.3071\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.7941 - accuracy: 0.3095\n",
      "Fold 3 - Validation Loss: 1.7941, Validation Accuracy: 0.3095\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 2.9606 - accuracy: 0.2023 - val_loss: 2.6130 - val_accuracy: 0.2188\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4253 - accuracy: 0.2272 - val_loss: 2.2400 - val_accuracy: 0.2620\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.1652 - accuracy: 0.2598 - val_loss: 2.0835 - val_accuracy: 0.2644\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.0659 - accuracy: 0.2428 - val_loss: 1.9785 - val_accuracy: 0.3101\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.9747 - accuracy: 0.2715 - val_loss: 1.9408 - val_accuracy: 0.2957\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9152 - accuracy: 0.2742 - val_loss: 1.9075 - val_accuracy: 0.2981\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9024 - accuracy: 0.2807 - val_loss: 1.9530 - val_accuracy: 0.2716\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.9036 - accuracy: 0.2637 - val_loss: 1.8836 - val_accuracy: 0.2909\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8691 - accuracy: 0.2794 - val_loss: 1.8566 - val_accuracy: 0.3077\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8558 - accuracy: 0.2833 - val_loss: 1.9144 - val_accuracy: 0.2788\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8648 - accuracy: 0.2879 - val_loss: 1.8840 - val_accuracy: 0.2861\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8733 - accuracy: 0.2676 - val_loss: 1.8811 - val_accuracy: 0.2933\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8566 - accuracy: 0.3077\n",
      "Fold 4 - Validation Loss: 1.8566, Validation Accuracy: 0.3077\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 2.9798 - accuracy: 0.1939 - val_loss: 2.6503 - val_accuracy: 0.2476\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4332 - accuracy: 0.2546 - val_loss: 2.3481 - val_accuracy: 0.2260\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1904 - accuracy: 0.2702 - val_loss: 2.2160 - val_accuracy: 0.2308\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0662 - accuracy: 0.2611 - val_loss: 2.1421 - val_accuracy: 0.1971\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9871 - accuracy: 0.2676 - val_loss: 2.0340 - val_accuracy: 0.2043\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9431 - accuracy: 0.2807 - val_loss: 2.0354 - val_accuracy: 0.1923\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9288 - accuracy: 0.2702 - val_loss: 1.9433 - val_accuracy: 0.2452\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9082 - accuracy: 0.2742 - val_loss: 1.9212 - val_accuracy: 0.2284\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8579 - accuracy: 0.2957 - val_loss: 2.0047 - val_accuracy: 0.2188\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8502 - accuracy: 0.2898 - val_loss: 1.9452 - val_accuracy: 0.2308\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8400 - accuracy: 0.2898 - val_loss: 1.9522 - val_accuracy: 0.2284\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9212 - accuracy: 0.2284\n",
      "Fold 5 - Validation Loss: 1.9212, Validation Accuracy: 0.2284\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 5s 28ms/step - loss: 2.9735 - accuracy: 0.1885 - val_loss: 2.5827 - val_accuracy: 0.2646\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.4471 - accuracy: 0.2344 - val_loss: 2.2467 - val_accuracy: 0.2672\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.2021 - accuracy: 0.2541 - val_loss: 2.0973 - val_accuracy: 0.2566\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0878 - accuracy: 0.2554 - val_loss: 2.0160 - val_accuracy: 0.2725\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0213 - accuracy: 0.2688 - val_loss: 1.9726 - val_accuracy: 0.2328\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9679 - accuracy: 0.2618 - val_loss: 1.8976 - val_accuracy: 0.2804\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.9421 - accuracy: 0.2605 - val_loss: 1.8866 - val_accuracy: 0.2831\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.9165 - accuracy: 0.2611 - val_loss: 2.0026 - val_accuracy: 0.2037\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.9101 - accuracy: 0.2828 - val_loss: 1.9012 - val_accuracy: 0.2513\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.9129 - accuracy: 0.2675 - val_loss: 1.8545 - val_accuracy: 0.2778\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.8821 - accuracy: 0.2771 - val_loss: 1.8920 - val_accuracy: 0.2672\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8815 - accuracy: 0.2694 - val_loss: 1.8253 - val_accuracy: 0.2804\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8799 - accuracy: 0.2771 - val_loss: 1.8395 - val_accuracy: 0.2751\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8745 - accuracy: 0.2745 - val_loss: 1.8335 - val_accuracy: 0.2646\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 1.8642 - accuracy: 0.2847 - val_loss: 1.8089 - val_accuracy: 0.3042\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 1.8501 - accuracy: 0.2847 - val_loss: 1.8926 - val_accuracy: 0.2566\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 1.8850 - accuracy: 0.2828 - val_loss: 1.8160 - val_accuracy: 0.2646\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8343 - accuracy: 0.2860 - val_loss: 1.8071 - val_accuracy: 0.2884\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8552 - accuracy: 0.2904 - val_loss: 1.8058 - val_accuracy: 0.2963\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8550 - accuracy: 0.2943 - val_loss: 1.8183 - val_accuracy: 0.2910\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.8620 - accuracy: 0.2847 - val_loss: 1.8389 - val_accuracy: 0.2672\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 1.8302 - accuracy: 0.2943 - val_loss: 1.8186 - val_accuracy: 0.2804\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8058 - accuracy: 0.2963\n",
      "Fold 1 - Validation Loss: 1.8058, Validation Accuracy: 0.2963\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 8s 30ms/step - loss: 2.9844 - accuracy: 0.1939 - val_loss: 2.6048 - val_accuracy: 0.2673\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.4656 - accuracy: 0.2479 - val_loss: 2.2190 - val_accuracy: 0.2830\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.1884 - accuracy: 0.2521 - val_loss: 2.0313 - val_accuracy: 0.3459\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.0661 - accuracy: 0.2656 - val_loss: 1.9044 - val_accuracy: 0.3176\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.0090 - accuracy: 0.2613 - val_loss: 1.9013 - val_accuracy: 0.2893\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.9680 - accuracy: 0.2540 - val_loss: 1.8154 - val_accuracy: 0.3239\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.9434 - accuracy: 0.2632 - val_loss: 1.8235 - val_accuracy: 0.3176\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.9182 - accuracy: 0.2779 - val_loss: 1.8226 - val_accuracy: 0.3082\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9023 - accuracy: 0.2712 - val_loss: 1.8138 - val_accuracy: 0.3113\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 1.8757 - accuracy: 0.2730 - val_loss: 1.8047 - val_accuracy: 0.3176\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.8859 - accuracy: 0.2742 - val_loss: 1.7664 - val_accuracy: 0.2956\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.8793 - accuracy: 0.2736 - val_loss: 1.7610 - val_accuracy: 0.3208\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.8576 - accuracy: 0.2828 - val_loss: 1.8313 - val_accuracy: 0.2673\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.8499 - accuracy: 0.2828 - val_loss: 1.7404 - val_accuracy: 0.3113\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 1.8571 - accuracy: 0.2883 - val_loss: 1.7566 - val_accuracy: 0.3113\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 1s 17ms/step - loss: 1.8498 - accuracy: 0.2847 - val_loss: 1.7600 - val_accuracy: 0.3050\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 1.8446 - accuracy: 0.2798 - val_loss: 1.7498 - val_accuracy: 0.3239\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7404 - accuracy: 0.3113\n",
      "Fold 2 - Validation Loss: 1.7404, Validation Accuracy: 0.3113\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 5s 29ms/step - loss: 3.0125 - accuracy: 0.1747 - val_loss: 2.7325 - val_accuracy: 0.1571\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5494 - accuracy: 0.1872 - val_loss: 2.3690 - val_accuracy: 0.2190\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.2404 - accuracy: 0.2513 - val_loss: 2.1755 - val_accuracy: 0.2476\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.1104 - accuracy: 0.2539 - val_loss: 2.0872 - val_accuracy: 0.2500\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0222 - accuracy: 0.2709 - val_loss: 2.0722 - val_accuracy: 0.2429\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9692 - accuracy: 0.2520 - val_loss: 1.9705 - val_accuracy: 0.2405\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9293 - accuracy: 0.2618 - val_loss: 1.9575 - val_accuracy: 0.2762\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9043 - accuracy: 0.2736 - val_loss: 1.9315 - val_accuracy: 0.2595\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8871 - accuracy: 0.2886 - val_loss: 1.9422 - val_accuracy: 0.2762\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8875 - accuracy: 0.2781 - val_loss: 1.8960 - val_accuracy: 0.2738\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8530 - accuracy: 0.2873 - val_loss: 1.9080 - val_accuracy: 0.2810\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8707 - accuracy: 0.2775 - val_loss: 1.8894 - val_accuracy: 0.2595\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8589 - accuracy: 0.2795 - val_loss: 1.8758 - val_accuracy: 0.2952\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8497 - accuracy: 0.2847 - val_loss: 1.8573 - val_accuracy: 0.2905\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8235 - accuracy: 0.2938 - val_loss: 1.8491 - val_accuracy: 0.2762\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8302 - accuracy: 0.2965 - val_loss: 1.8661 - val_accuracy: 0.2619\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8337 - accuracy: 0.2932 - val_loss: 1.8651 - val_accuracy: 0.2595\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8270 - accuracy: 0.2938 - val_loss: 1.9094 - val_accuracy: 0.2738\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.8491 - accuracy: 0.2762\n",
      "Fold 3 - Validation Loss: 1.8491, Validation Accuracy: 0.2762\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 2.9997 - accuracy: 0.1599 - val_loss: 2.6885 - val_accuracy: 0.1611\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4833 - accuracy: 0.2219 - val_loss: 2.2487 - val_accuracy: 0.2933\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.2029 - accuracy: 0.2252 - val_loss: 2.0656 - val_accuracy: 0.2764\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0876 - accuracy: 0.2356 - val_loss: 2.0145 - val_accuracy: 0.2812\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0218 - accuracy: 0.2363 - val_loss: 1.9500 - val_accuracy: 0.2692\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9517 - accuracy: 0.2617 - val_loss: 1.9146 - val_accuracy: 0.2957\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9340 - accuracy: 0.2591 - val_loss: 1.9600 - val_accuracy: 0.2740\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9300 - accuracy: 0.2604 - val_loss: 1.8596 - val_accuracy: 0.2981\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8868 - accuracy: 0.2728 - val_loss: 1.8449 - val_accuracy: 0.2909\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8812 - accuracy: 0.2761 - val_loss: 1.8623 - val_accuracy: 0.2788\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8723 - accuracy: 0.2735 - val_loss: 1.8446 - val_accuracy: 0.3077\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8435 - accuracy: 0.2774 - val_loss: 1.8524 - val_accuracy: 0.2909\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8419 - accuracy: 0.2885 - val_loss: 1.8063 - val_accuracy: 0.2981\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8243 - accuracy: 0.3074 - val_loss: 1.8136 - val_accuracy: 0.3173\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8550 - accuracy: 0.2937 - val_loss: 1.8200 - val_accuracy: 0.2933\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8464 - accuracy: 0.2885 - val_loss: 1.7776 - val_accuracy: 0.3125\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8120 - accuracy: 0.3061 - val_loss: 1.7752 - val_accuracy: 0.3221\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8184 - accuracy: 0.2990 - val_loss: 1.7853 - val_accuracy: 0.3245\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 1.7986 - accuracy: 0.2990 - val_loss: 1.8202 - val_accuracy: 0.3173\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.7982 - accuracy: 0.3048 - val_loss: 1.8646 - val_accuracy: 0.3053\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7752 - accuracy: 0.3221\n",
      "Fold 4 - Validation Loss: 1.7752, Validation Accuracy: 0.3221\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 2.9746 - accuracy: 0.1854 - val_loss: 2.6321 - val_accuracy: 0.2332\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4377 - accuracy: 0.2441 - val_loss: 2.2758 - val_accuracy: 0.2476\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.1874 - accuracy: 0.2546 - val_loss: 2.1761 - val_accuracy: 0.2212\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0612 - accuracy: 0.2709 - val_loss: 2.1055 - val_accuracy: 0.2356\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9694 - accuracy: 0.2761 - val_loss: 2.0849 - val_accuracy: 0.2091\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9480 - accuracy: 0.2748 - val_loss: 2.0980 - val_accuracy: 0.1923\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9147 - accuracy: 0.2879 - val_loss: 1.9210 - val_accuracy: 0.2668\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8753 - accuracy: 0.2879 - val_loss: 1.9156 - val_accuracy: 0.2764\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8711 - accuracy: 0.2918 - val_loss: 1.9694 - val_accuracy: 0.2212\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8428 - accuracy: 0.2983 - val_loss: 1.9867 - val_accuracy: 0.2212\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8500 - accuracy: 0.3009 - val_loss: 1.9012 - val_accuracy: 0.2596\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8521 - accuracy: 0.2924 - val_loss: 1.9472 - val_accuracy: 0.2188\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8300 - accuracy: 0.2970 - val_loss: 1.9300 - val_accuracy: 0.2428\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8350 - accuracy: 0.2924 - val_loss: 1.8927 - val_accuracy: 0.2524\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8399 - accuracy: 0.2859 - val_loss: 1.8770 - val_accuracy: 0.2572\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8148 - accuracy: 0.3003 - val_loss: 1.9268 - val_accuracy: 0.2476\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 1.8120 - accuracy: 0.3055 - val_loss: 1.9156 - val_accuracy: 0.2428\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 1.8095 - accuracy: 0.3003 - val_loss: 1.9283 - val_accuracy: 0.2332\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8770 - accuracy: 0.2572\n",
      "Fold 5 - Validation Loss: 1.8770, Validation Accuracy: 0.2572\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 5s 28ms/step - loss: 3.0727 - accuracy: 0.1459 - val_loss: 2.7752 - val_accuracy: 0.1799\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.6176 - accuracy: 0.1643 - val_loss: 2.4305 - val_accuracy: 0.2434\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.3763 - accuracy: 0.2096 - val_loss: 2.1951 - val_accuracy: 0.2804\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.2013 - accuracy: 0.2318 - val_loss: 2.0664 - val_accuracy: 0.2698\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.1230 - accuracy: 0.2395 - val_loss: 2.0371 - val_accuracy: 0.2725\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0789 - accuracy: 0.2293 - val_loss: 2.0017 - val_accuracy: 0.2646\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0549 - accuracy: 0.2306 - val_loss: 1.9598 - val_accuracy: 0.2540\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0197 - accuracy: 0.2408 - val_loss: 1.9414 - val_accuracy: 0.2354\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9730 - accuracy: 0.2592 - val_loss: 1.8944 - val_accuracy: 0.2831\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9577 - accuracy: 0.2484 - val_loss: 1.8609 - val_accuracy: 0.3016\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9406 - accuracy: 0.2497 - val_loss: 1.9192 - val_accuracy: 0.2672\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9327 - accuracy: 0.2554 - val_loss: 1.8861 - val_accuracy: 0.2804\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 1.9130 - accuracy: 0.2682 - val_loss: 1.8411 - val_accuracy: 0.3148\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9298 - accuracy: 0.2726 - val_loss: 1.8843 - val_accuracy: 0.3016\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9220 - accuracy: 0.2618 - val_loss: 1.8329 - val_accuracy: 0.2884\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9184 - accuracy: 0.2745 - val_loss: 1.8483 - val_accuracy: 0.2910\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9232 - accuracy: 0.2643 - val_loss: 1.8463 - val_accuracy: 0.2884\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 1.9085 - accuracy: 0.2713 - val_loss: 1.8470 - val_accuracy: 0.2937\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8329 - accuracy: 0.2884\n",
      "Fold 1 - Validation Loss: 1.8329, Validation Accuracy: 0.2884\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 4s 28ms/step - loss: 3.0806 - accuracy: 0.1626 - val_loss: 2.7510 - val_accuracy: 0.2296\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.6249 - accuracy: 0.2025 - val_loss: 2.3868 - val_accuracy: 0.2956\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3357 - accuracy: 0.2202 - val_loss: 2.1283 - val_accuracy: 0.3208\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1853 - accuracy: 0.2258 - val_loss: 2.0117 - val_accuracy: 0.3270\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0856 - accuracy: 0.2374 - val_loss: 1.9615 - val_accuracy: 0.3459\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0396 - accuracy: 0.2405 - val_loss: 1.9111 - val_accuracy: 0.3050\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9970 - accuracy: 0.2485 - val_loss: 1.8589 - val_accuracy: 0.3019\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9859 - accuracy: 0.2387 - val_loss: 1.8634 - val_accuracy: 0.2830\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9413 - accuracy: 0.2742 - val_loss: 1.7991 - val_accuracy: 0.3208\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9569 - accuracy: 0.2442 - val_loss: 1.8099 - val_accuracy: 0.3113\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9317 - accuracy: 0.2638 - val_loss: 1.7940 - val_accuracy: 0.3113\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9156 - accuracy: 0.2613 - val_loss: 1.8026 - val_accuracy: 0.3082\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.8990 - accuracy: 0.2675 - val_loss: 1.8351 - val_accuracy: 0.2893\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9064 - accuracy: 0.2767 - val_loss: 1.7694 - val_accuracy: 0.3365\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 1.9089 - accuracy: 0.2638 - val_loss: 1.7795 - val_accuracy: 0.3239\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.9261 - accuracy: 0.2497 - val_loss: 1.8123 - val_accuracy: 0.3019\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.9112 - accuracy: 0.2644 - val_loss: 1.7808 - val_accuracy: 0.3082\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7694 - accuracy: 0.3365\n",
      "Fold 2 - Validation Loss: 1.7694, Validation Accuracy: 0.3365\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 5s 29ms/step - loss: 3.0839 - accuracy: 0.1649 - val_loss: 2.8161 - val_accuracy: 0.2262\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.6356 - accuracy: 0.2107 - val_loss: 2.4580 - val_accuracy: 0.2381\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3508 - accuracy: 0.2323 - val_loss: 2.2626 - val_accuracy: 0.2548\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1945 - accuracy: 0.2467 - val_loss: 2.1713 - val_accuracy: 0.2167\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.1485 - accuracy: 0.2134 - val_loss: 2.0922 - val_accuracy: 0.2214\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0307 - accuracy: 0.2585 - val_loss: 2.0664 - val_accuracy: 0.2452\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0116 - accuracy: 0.2448 - val_loss: 1.9988 - val_accuracy: 0.2381\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9578 - accuracy: 0.2664 - val_loss: 1.9836 - val_accuracy: 0.2452\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9292 - accuracy: 0.2651 - val_loss: 1.9859 - val_accuracy: 0.2429\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9445 - accuracy: 0.2520 - val_loss: 1.9484 - val_accuracy: 0.2333\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9112 - accuracy: 0.2611 - val_loss: 2.0063 - val_accuracy: 0.2595\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9003 - accuracy: 0.2716 - val_loss: 1.9525 - val_accuracy: 0.2357\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8985 - accuracy: 0.2801 - val_loss: 1.9114 - val_accuracy: 0.2548\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9092 - accuracy: 0.2703 - val_loss: 1.9198 - val_accuracy: 0.2762\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8827 - accuracy: 0.2729 - val_loss: 1.9011 - val_accuracy: 0.2452\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8984 - accuracy: 0.2723 - val_loss: 1.8908 - val_accuracy: 0.2690\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8730 - accuracy: 0.2749 - val_loss: 1.9198 - val_accuracy: 0.2452\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8708 - accuracy: 0.2788 - val_loss: 1.9136 - val_accuracy: 0.2810\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8636 - accuracy: 0.2814 - val_loss: 1.8929 - val_accuracy: 0.3024\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.8908 - accuracy: 0.2690\n",
      "Fold 3 - Validation Loss: 1.8908, Validation Accuracy: 0.2690\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 3.1184 - accuracy: 0.1521 - val_loss: 2.8364 - val_accuracy: 0.2163\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.6697 - accuracy: 0.1860 - val_loss: 2.4673 - val_accuracy: 0.2500\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3895 - accuracy: 0.2148 - val_loss: 2.2379 - val_accuracy: 0.2692\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2262 - accuracy: 0.2317 - val_loss: 2.1209 - val_accuracy: 0.2740\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1288 - accuracy: 0.2461 - val_loss: 2.0928 - val_accuracy: 0.2524\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.0689 - accuracy: 0.2369 - val_loss: 1.9842 - val_accuracy: 0.2957\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0075 - accuracy: 0.2428 - val_loss: 1.9674 - val_accuracy: 0.2740\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9822 - accuracy: 0.2415 - val_loss: 1.9091 - val_accuracy: 0.2957\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9474 - accuracy: 0.2565 - val_loss: 1.9106 - val_accuracy: 0.2716\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9454 - accuracy: 0.2676 - val_loss: 1.8799 - val_accuracy: 0.3053\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9330 - accuracy: 0.2546 - val_loss: 1.8759 - val_accuracy: 0.2933\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9079 - accuracy: 0.2604 - val_loss: 1.8553 - val_accuracy: 0.2764\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9232 - accuracy: 0.2448 - val_loss: 1.8618 - val_accuracy: 0.2837\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9126 - accuracy: 0.2722 - val_loss: 1.8700 - val_accuracy: 0.2837\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9046 - accuracy: 0.2637 - val_loss: 1.8505 - val_accuracy: 0.3077\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9036 - accuracy: 0.2807 - val_loss: 1.8592 - val_accuracy: 0.2957\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8965 - accuracy: 0.2670 - val_loss: 1.8723 - val_accuracy: 0.2812\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8866 - accuracy: 0.2755 - val_loss: 1.8782 - val_accuracy: 0.2885\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8505 - accuracy: 0.3077\n",
      "Fold 4 - Validation Loss: 1.8505, Validation Accuracy: 0.3077\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 3.0723 - accuracy: 0.1567 - val_loss: 2.7733 - val_accuracy: 0.2356\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5979 - accuracy: 0.1997 - val_loss: 2.4277 - val_accuracy: 0.2188\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.3336 - accuracy: 0.2239 - val_loss: 2.2234 - val_accuracy: 0.2236\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1957 - accuracy: 0.2141 - val_loss: 2.1041 - val_accuracy: 0.2308\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0895 - accuracy: 0.2376 - val_loss: 2.0512 - val_accuracy: 0.2404\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0319 - accuracy: 0.2409 - val_loss: 1.9886 - val_accuracy: 0.2452\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.9976 - accuracy: 0.2617 - val_loss: 1.9972 - val_accuracy: 0.2308\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9762 - accuracy: 0.2552 - val_loss: 1.9691 - val_accuracy: 0.2452\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9487 - accuracy: 0.2598 - val_loss: 2.0037 - val_accuracy: 0.2043\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9319 - accuracy: 0.2657 - val_loss: 1.9845 - val_accuracy: 0.2236\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.9200 - accuracy: 0.2787 - val_loss: 1.9352 - val_accuracy: 0.2452\n",
      "Epoch 12/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8838 - accuracy: 0.2768 - val_loss: 1.9108 - val_accuracy: 0.2572\n",
      "Epoch 13/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8831 - accuracy: 0.2774 - val_loss: 1.9215 - val_accuracy: 0.2452\n",
      "Epoch 14/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8603 - accuracy: 0.2859 - val_loss: 1.8949 - val_accuracy: 0.2524\n",
      "Epoch 15/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8958 - accuracy: 0.2644 - val_loss: 1.9093 - val_accuracy: 0.2452\n",
      "Epoch 16/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8657 - accuracy: 0.2787 - val_loss: 1.9362 - val_accuracy: 0.2332\n",
      "Epoch 17/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8816 - accuracy: 0.2768 - val_loss: 1.8792 - val_accuracy: 0.2596\n",
      "Epoch 18/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8499 - accuracy: 0.2761 - val_loss: 1.9100 - val_accuracy: 0.2332\n",
      "Epoch 19/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 1.8617 - accuracy: 0.2963 - val_loss: 1.8883 - val_accuracy: 0.2572\n",
      "Epoch 20/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 1.8712 - accuracy: 0.2872 - val_loss: 1.8811 - val_accuracy: 0.2668\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.8792 - accuracy: 0.2596\n",
      "Fold 5 - Validation Loss: 1.8792, Validation Accuracy: 0.2596\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 4s 29ms/step - loss: 5.4458 - accuracy: 0.1631 - val_loss: 2.9606 - val_accuracy: 0.1640\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.6467 - accuracy: 0.1478 - val_loss: 2.2115 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.1096 - accuracy: 0.1452 - val_loss: 2.0674 - val_accuracy: 0.1481\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0509 - accuracy: 0.1465 - val_loss: 2.0486 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0439 - accuracy: 0.1510 - val_loss: 2.0428 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0438 - accuracy: 0.1510 - val_loss: 2.0430 - val_accuracy: 0.1481\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0431 - accuracy: 0.1567 - val_loss: 2.0507 - val_accuracy: 0.1481\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0451 - accuracy: 0.1484 - val_loss: 2.0426 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0445 - accuracy: 0.1369 - val_loss: 2.0465 - val_accuracy: 0.1481\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0420 - accuracy: 0.1478 - val_loss: 2.0529 - val_accuracy: 0.1481\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0423 - accuracy: 0.1611 - val_loss: 2.0527 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0426 - accuracy: 0.1481\n",
      "Fold 1 - Validation Loss: 2.0426, Validation Accuracy: 0.1481\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 5s 31ms/step - loss: 4.9528 - accuracy: 0.1485 - val_loss: 2.5999 - val_accuracy: 0.1667\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.3196 - accuracy: 0.1442 - val_loss: 2.1544 - val_accuracy: 0.1698\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0908 - accuracy: 0.1362 - val_loss: 2.0351 - val_accuracy: 0.1509\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0536 - accuracy: 0.1466 - val_loss: 2.0327 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.0423 - accuracy: 0.1491 - val_loss: 2.0331 - val_accuracy: 0.1509\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0497 - accuracy: 0.1423 - val_loss: 2.0418 - val_accuracy: 0.1509\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0467 - accuracy: 0.1331 - val_loss: 2.0327 - val_accuracy: 0.1509\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0423 - accuracy: 0.1595 - val_loss: 2.0494 - val_accuracy: 0.1509\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0491 - accuracy: 0.1479 - val_loss: 2.0359 - val_accuracy: 0.1509\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0457 - accuracy: 0.1411 - val_loss: 2.0383 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.0327 - accuracy: 0.1509\n",
      "Fold 2 - Validation Loss: 2.0327, Validation Accuracy: 0.1509\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 5.3918 - accuracy: 0.1505 - val_loss: 2.5411 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1711 - accuracy: 0.1479 - val_loss: 2.0537 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0479 - accuracy: 0.1446 - val_loss: 2.0456 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0476 - accuracy: 0.1401 - val_loss: 2.0450 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0429 - accuracy: 0.1440 - val_loss: 2.0457 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0382 - accuracy: 0.1531 - val_loss: 2.0550 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0497 - accuracy: 0.1453 - val_loss: 2.0461 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.0450 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0450, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 5s 31ms/step - loss: 5.5432 - accuracy: 0.1593 - val_loss: 2.7582 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5698 - accuracy: 0.1527 - val_loss: 2.2735 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2133 - accuracy: 0.1384 - val_loss: 2.0883 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0540 - accuracy: 0.1423 - val_loss: 2.0411 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0473 - accuracy: 0.1514 - val_loss: 2.0429 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0455 - accuracy: 0.1534 - val_loss: 2.0380 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0461 - accuracy: 0.1527 - val_loss: 2.0397 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0499 - accuracy: 0.1384 - val_loss: 2.0384 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0456 - accuracy: 0.1430 - val_loss: 2.0414 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0380 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0380, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 5s 31ms/step - loss: 6.0712 - accuracy: 0.1612 - val_loss: 2.9243 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.4507 - accuracy: 0.1403 - val_loss: 2.2235 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1916 - accuracy: 0.1508 - val_loss: 2.1338 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0795 - accuracy: 0.1358 - val_loss: 2.0636 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0593 - accuracy: 0.1325 - val_loss: 2.0437 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0552 - accuracy: 0.1547 - val_loss: 2.0447 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0459 - accuracy: 0.1456 - val_loss: 2.0390 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 2.0498 - accuracy: 0.1423 - val_loss: 2.0367 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 2.0433 - accuracy: 0.1462 - val_loss: 2.0378 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 2.0439 - accuracy: 0.1593 - val_loss: 2.0387 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 2.0430 - accuracy: 0.1501 - val_loss: 2.0460 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0367 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0367, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 6s 33ms/step - loss: 5.2495 - accuracy: 0.1490 - val_loss: 2.8937 - val_accuracy: 0.1481\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.4640 - accuracy: 0.1478 - val_loss: 2.1695 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 2.0805 - accuracy: 0.1427 - val_loss: 2.0499 - val_accuracy: 0.1481\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.0492 - accuracy: 0.1465 - val_loss: 2.0479 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0444 - accuracy: 0.1490 - val_loss: 2.0428 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.0440 - accuracy: 0.1503 - val_loss: 2.0433 - val_accuracy: 0.1481\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 2.0434 - accuracy: 0.1535 - val_loss: 2.0511 - val_accuracy: 0.1481\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.0454 - accuracy: 0.1484 - val_loss: 2.0426 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.0447 - accuracy: 0.1376 - val_loss: 2.0466 - val_accuracy: 0.1481\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.0421 - accuracy: 0.1478 - val_loss: 2.0529 - val_accuracy: 0.1481\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.0424 - accuracy: 0.1624 - val_loss: 2.0534 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0426 - accuracy: 0.1481\n",
      "Fold 1 - Validation Loss: 2.0426, Validation Accuracy: 0.1481\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 5s 31ms/step - loss: 5.3013 - accuracy: 0.1350 - val_loss: 3.0699 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 16ms/step - loss: 2.8409 - accuracy: 0.1429 - val_loss: 2.3587 - val_accuracy: 0.1698\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.1421 - accuracy: 0.1479 - val_loss: 2.0374 - val_accuracy: 0.1509\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.0532 - accuracy: 0.1485 - val_loss: 2.0334 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0437 - accuracy: 0.1491 - val_loss: 2.0330 - val_accuracy: 0.1509\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0494 - accuracy: 0.1411 - val_loss: 2.0425 - val_accuracy: 0.1509\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0468 - accuracy: 0.1276 - val_loss: 2.0322 - val_accuracy: 0.1509\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0427 - accuracy: 0.1577 - val_loss: 2.0492 - val_accuracy: 0.1509\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 2.0490 - accuracy: 0.1423 - val_loss: 2.0357 - val_accuracy: 0.1509\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0457 - accuracy: 0.1411 - val_loss: 2.0384 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.0322 - accuracy: 0.1509\n",
      "Fold 2 - Validation Loss: 2.0322, Validation Accuracy: 0.1509\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 30ms/step - loss: 5.3500 - accuracy: 0.1374 - val_loss: 3.2739 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.8811 - accuracy: 0.1538 - val_loss: 2.2620 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1716 - accuracy: 0.1361 - val_loss: 2.0713 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0544 - accuracy: 0.1486 - val_loss: 2.0446 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0433 - accuracy: 0.1479 - val_loss: 2.0454 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0384 - accuracy: 0.1571 - val_loss: 2.0533 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0492 - accuracy: 0.1466 - val_loss: 2.0463 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.0446 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0446, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 30ms/step - loss: 4.9579 - accuracy: 0.1580 - val_loss: 2.7390 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3949 - accuracy: 0.1482 - val_loss: 2.1097 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0613 - accuracy: 0.1384 - val_loss: 2.0365 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0463 - accuracy: 0.1449 - val_loss: 2.0426 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0491 - accuracy: 0.1508 - val_loss: 2.0445 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0462 - accuracy: 0.1527 - val_loss: 2.0396 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0365 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0365, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 5.2003 - accuracy: 0.1508 - val_loss: 2.6931 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.3247 - accuracy: 0.1423 - val_loss: 2.0769 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0605 - accuracy: 0.1371 - val_loss: 2.0375 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0473 - accuracy: 0.1469 - val_loss: 2.0434 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0469 - accuracy: 0.1364 - val_loss: 2.0425 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0458 - accuracy: 0.1514 - val_loss: 2.0411 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0375 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0375, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "50/50 [==============================] - 5s 31ms/step - loss: 5.8539 - accuracy: 0.1561 - val_loss: 3.3600 - val_accuracy: 0.1640\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.7536 - accuracy: 0.1459 - val_loss: 2.2050 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.1043 - accuracy: 0.1376 - val_loss: 2.0958 - val_accuracy: 0.1481\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 2.0637 - accuracy: 0.1465 - val_loss: 2.0493 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0446 - accuracy: 0.1510 - val_loss: 2.0427 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0441 - accuracy: 0.1484 - val_loss: 2.0433 - val_accuracy: 0.1481\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0435 - accuracy: 0.1535 - val_loss: 2.0517 - val_accuracy: 0.1481\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0456 - accuracy: 0.1484 - val_loss: 2.0423 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.0447 - accuracy: 0.1369 - val_loss: 2.0467 - val_accuracy: 0.1481\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0422 - accuracy: 0.1478 - val_loss: 2.0529 - val_accuracy: 0.1481\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 2.0425 - accuracy: 0.1650 - val_loss: 2.0532 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0423 - accuracy: 0.1481\n",
      "Fold 1 - Validation Loss: 2.0423, Validation Accuracy: 0.1481\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "51/51 [==============================] - 4s 28ms/step - loss: 5.4810 - accuracy: 0.1429 - val_loss: 2.8850 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.5273 - accuracy: 0.1571 - val_loss: 2.2685 - val_accuracy: 0.1509\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.1335 - accuracy: 0.1509 - val_loss: 2.0533 - val_accuracy: 0.1509\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0488 - accuracy: 0.1466 - val_loss: 2.0410 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.0445 - accuracy: 0.1491 - val_loss: 2.0332 - val_accuracy: 0.1509\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.0502 - accuracy: 0.1423 - val_loss: 2.0421 - val_accuracy: 0.1509\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0470 - accuracy: 0.1307 - val_loss: 2.0328 - val_accuracy: 0.1509\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 1s 14ms/step - loss: 2.0426 - accuracy: 0.1595 - val_loss: 2.0499 - val_accuracy: 0.1509\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.0493 - accuracy: 0.1479 - val_loss: 2.0361 - val_accuracy: 0.1509\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 2.0458 - accuracy: 0.1411 - val_loss: 2.0384 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.0328 - accuracy: 0.1509\n",
      "Fold 2 - Validation Loss: 2.0328, Validation Accuracy: 0.1509\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 5s 30ms/step - loss: 5.0165 - accuracy: 0.1551 - val_loss: 2.9346 - val_accuracy: 0.1571\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.5390 - accuracy: 0.1564 - val_loss: 2.2118 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0909 - accuracy: 0.1414 - val_loss: 2.0492 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0499 - accuracy: 0.1440 - val_loss: 2.0449 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0440 - accuracy: 0.1459 - val_loss: 2.0460 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 17ms/step - loss: 2.0387 - accuracy: 0.1577 - val_loss: 2.0557 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0506 - accuracy: 0.1401 - val_loss: 2.0476 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.0449 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0449, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 4s 29ms/step - loss: 4.9886 - accuracy: 0.1619 - val_loss: 2.7412 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.4420 - accuracy: 0.1599 - val_loss: 2.1113 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 2.0709 - accuracy: 0.1325 - val_loss: 2.0373 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0469 - accuracy: 0.1397 - val_loss: 2.0441 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.0493 - accuracy: 0.1586 - val_loss: 2.0444 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0464 - accuracy: 0.1573 - val_loss: 2.0387 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0373 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0373, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "48/48 [==============================] - 5s 31ms/step - loss: 5.9378 - accuracy: 0.1573 - val_loss: 3.0585 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.7065 - accuracy: 0.1403 - val_loss: 2.3799 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.2804 - accuracy: 0.1338 - val_loss: 2.0884 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.1080 - accuracy: 0.1384 - val_loss: 2.0898 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 2.0542 - accuracy: 0.1436 - val_loss: 2.0428 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0461 - accuracy: 0.1514 - val_loss: 2.0423 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0464 - accuracy: 0.1475 - val_loss: 2.0394 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0504 - accuracy: 0.1430 - val_loss: 2.0369 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0436 - accuracy: 0.1462 - val_loss: 2.0380 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0443 - accuracy: 0.1554 - val_loss: 2.0391 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 2.0433 - accuracy: 0.1501 - val_loss: 2.0459 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0369 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0369, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 51ms/step - loss: 3.3254 - accuracy: 0.1522 - val_loss: 3.2665 - val_accuracy: 0.1905\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 3.2479 - accuracy: 0.1968 - val_loss: 3.1966 - val_accuracy: 0.2460\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.1716 - accuracy: 0.2178 - val_loss: 3.1359 - val_accuracy: 0.2487\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 3.1152 - accuracy: 0.2274 - val_loss: 3.0805 - val_accuracy: 0.2434\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.0543 - accuracy: 0.2306 - val_loss: 3.0203 - val_accuracy: 0.2434\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 3.0050 - accuracy: 0.2414 - val_loss: 2.9707 - val_accuracy: 0.2354\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.9406 - accuracy: 0.2682 - val_loss: 2.9239 - val_accuracy: 0.2328\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 2.8921 - accuracy: 0.2624 - val_loss: 2.8768 - val_accuracy: 0.2222\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.8365 - accuracy: 0.2694 - val_loss: 2.8256 - val_accuracy: 0.2460\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.7992 - accuracy: 0.2739 - val_loss: 2.7927 - val_accuracy: 0.2381\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.7618 - accuracy: 0.2796 - val_loss: 2.7509 - val_accuracy: 0.2434\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.7137 - accuracy: 0.2822 - val_loss: 2.7226 - val_accuracy: 0.2275\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.6794 - accuracy: 0.2879 - val_loss: 2.6854 - val_accuracy: 0.2407\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.6525 - accuracy: 0.2981 - val_loss: 2.6452 - val_accuracy: 0.2328\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 2.6006 - accuracy: 0.3070 - val_loss: 2.6020 - val_accuracy: 0.2566\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.5737 - accuracy: 0.3006 - val_loss: 2.5813 - val_accuracy: 0.2566\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.5422 - accuracy: 0.2962 - val_loss: 2.5498 - val_accuracy: 0.2540\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.5173 - accuracy: 0.3070 - val_loss: 2.5100 - val_accuracy: 0.2672\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.4875 - accuracy: 0.3096 - val_loss: 2.4793 - val_accuracy: 0.2778\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.4451 - accuracy: 0.3236 - val_loss: 2.4494 - val_accuracy: 0.2831\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.4187 - accuracy: 0.3134 - val_loss: 2.4215 - val_accuracy: 0.3042\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.4000 - accuracy: 0.3102 - val_loss: 2.3956 - val_accuracy: 0.2937\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.3786 - accuracy: 0.3057 - val_loss: 2.4069 - val_accuracy: 0.2619\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.3588 - accuracy: 0.3268 - val_loss: 2.3595 - val_accuracy: 0.2698\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.3189 - accuracy: 0.3146 - val_loss: 2.3416 - val_accuracy: 0.3148\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3416 - accuracy: 0.3148\n",
      "Fold 1 - Validation Loss: 2.3416, Validation Accuracy: 0.3148\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 4s 49ms/step - loss: 3.3215 - accuracy: 0.1675 - val_loss: 3.2640 - val_accuracy: 0.2044\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.2398 - accuracy: 0.2117 - val_loss: 3.1878 - val_accuracy: 0.2516\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.1740 - accuracy: 0.2110 - val_loss: 3.1225 - val_accuracy: 0.2862\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.1092 - accuracy: 0.2423 - val_loss: 3.0564 - val_accuracy: 0.2767\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.0545 - accuracy: 0.2374 - val_loss: 2.9946 - val_accuracy: 0.2862\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.9915 - accuracy: 0.2521 - val_loss: 2.9366 - val_accuracy: 0.2956\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.9315 - accuracy: 0.2589 - val_loss: 2.8820 - val_accuracy: 0.2893\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.8877 - accuracy: 0.2693 - val_loss: 2.8303 - val_accuracy: 0.2862\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.8336 - accuracy: 0.2564 - val_loss: 2.7760 - val_accuracy: 0.2987\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.7968 - accuracy: 0.2485 - val_loss: 2.7309 - val_accuracy: 0.3019\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.7527 - accuracy: 0.2613 - val_loss: 2.6853 - val_accuracy: 0.2925\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.7022 - accuracy: 0.2693 - val_loss: 2.6450 - val_accuracy: 0.2893\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.6665 - accuracy: 0.2613 - val_loss: 2.6140 - val_accuracy: 0.2862\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.6303 - accuracy: 0.2669 - val_loss: 2.5743 - val_accuracy: 0.2736\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.6009 - accuracy: 0.2859 - val_loss: 2.5482 - val_accuracy: 0.2673\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.5697 - accuracy: 0.2761 - val_loss: 2.5242 - val_accuracy: 0.2925\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.5372 - accuracy: 0.2791 - val_loss: 2.4859 - val_accuracy: 0.2893\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.5043 - accuracy: 0.2951 - val_loss: 2.4559 - val_accuracy: 0.2862\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.4672 - accuracy: 0.2920 - val_loss: 2.4408 - val_accuracy: 0.2799\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.4544 - accuracy: 0.2798 - val_loss: 2.4237 - val_accuracy: 0.2862\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.4156 - accuracy: 0.2890 - val_loss: 2.3851 - val_accuracy: 0.2767\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.3893 - accuracy: 0.3012 - val_loss: 2.3702 - val_accuracy: 0.2830\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.3749 - accuracy: 0.2859 - val_loss: 2.3495 - val_accuracy: 0.2956\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.3348 - accuracy: 0.3135 - val_loss: 2.3375 - val_accuracy: 0.2862\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.3160 - accuracy: 0.3080 - val_loss: 2.3116 - val_accuracy: 0.2799\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.3116 - accuracy: 0.2799\n",
      "Fold 2 - Validation Loss: 2.3116, Validation Accuracy: 0.2799\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 52ms/step - loss: 3.3336 - accuracy: 0.1545 - val_loss: 3.2869 - val_accuracy: 0.1786\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.2571 - accuracy: 0.1872 - val_loss: 3.2205 - val_accuracy: 0.1905\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.1961 - accuracy: 0.2003 - val_loss: 3.1623 - val_accuracy: 0.2048\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 3.1390 - accuracy: 0.2075 - val_loss: 3.1072 - val_accuracy: 0.2286\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 3.0837 - accuracy: 0.2186 - val_loss: 3.0555 - val_accuracy: 0.2405\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.0218 - accuracy: 0.2415 - val_loss: 3.0037 - val_accuracy: 0.2500\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.9666 - accuracy: 0.2559 - val_loss: 2.9515 - val_accuracy: 0.2429\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.9081 - accuracy: 0.2709 - val_loss: 2.9017 - val_accuracy: 0.2595\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.8696 - accuracy: 0.2585 - val_loss: 2.8591 - val_accuracy: 0.2333\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.8128 - accuracy: 0.2716 - val_loss: 2.8203 - val_accuracy: 0.2690\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.7593 - accuracy: 0.2592 - val_loss: 2.7847 - val_accuracy: 0.2524\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.7185 - accuracy: 0.2866 - val_loss: 2.7533 - val_accuracy: 0.2571\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.6886 - accuracy: 0.2709 - val_loss: 2.7229 - val_accuracy: 0.2524\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.6506 - accuracy: 0.2755 - val_loss: 2.6920 - val_accuracy: 0.2548\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.6178 - accuracy: 0.2873 - val_loss: 2.6600 - val_accuracy: 0.2786\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5873 - accuracy: 0.2906 - val_loss: 2.6342 - val_accuracy: 0.2667\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5480 - accuracy: 0.2886 - val_loss: 2.6023 - val_accuracy: 0.2857\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.5221 - accuracy: 0.2827 - val_loss: 2.5747 - val_accuracy: 0.2929\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.4908 - accuracy: 0.2847 - val_loss: 2.5538 - val_accuracy: 0.2857\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.4726 - accuracy: 0.2827 - val_loss: 2.5257 - val_accuracy: 0.2762\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.4393 - accuracy: 0.2808 - val_loss: 2.4995 - val_accuracy: 0.2786\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.4087 - accuracy: 0.2971 - val_loss: 2.4808 - val_accuracy: 0.2929\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.3934 - accuracy: 0.2958 - val_loss: 2.4558 - val_accuracy: 0.2905\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.3691 - accuracy: 0.2932 - val_loss: 2.4335 - val_accuracy: 0.2881\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.3433 - accuracy: 0.3037 - val_loss: 2.4159 - val_accuracy: 0.2833\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.4159 - accuracy: 0.2833\n",
      "Fold 3 - Validation Loss: 2.4159, Validation Accuracy: 0.2833\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 49ms/step - loss: 3.3626 - accuracy: 0.1155 - val_loss: 3.2991 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.2743 - accuracy: 0.1678 - val_loss: 3.2267 - val_accuracy: 0.1707\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.2087 - accuracy: 0.1899 - val_loss: 3.1679 - val_accuracy: 0.2957\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 3.1516 - accuracy: 0.1997 - val_loss: 3.1072 - val_accuracy: 0.2428\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.0935 - accuracy: 0.2213 - val_loss: 3.0487 - val_accuracy: 0.2764\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.0402 - accuracy: 0.2285 - val_loss: 2.9931 - val_accuracy: 0.2909\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.9924 - accuracy: 0.2428 - val_loss: 2.9406 - val_accuracy: 0.2861\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.9379 - accuracy: 0.2520 - val_loss: 2.8886 - val_accuracy: 0.2692\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.8850 - accuracy: 0.2474 - val_loss: 2.8417 - val_accuracy: 0.2837\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.8436 - accuracy: 0.2572 - val_loss: 2.8033 - val_accuracy: 0.2933\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.7970 - accuracy: 0.2715 - val_loss: 2.7669 - val_accuracy: 0.2885\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.7515 - accuracy: 0.2670 - val_loss: 2.7307 - val_accuracy: 0.3053\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.7307 - accuracy: 0.2611 - val_loss: 2.7012 - val_accuracy: 0.2933\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.6937 - accuracy: 0.2611 - val_loss: 2.6688 - val_accuracy: 0.3029\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.6554 - accuracy: 0.2755 - val_loss: 2.6407 - val_accuracy: 0.3005\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.6178 - accuracy: 0.2748 - val_loss: 2.6097 - val_accuracy: 0.3005\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.5935 - accuracy: 0.2650 - val_loss: 2.5920 - val_accuracy: 0.2909\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5479 - accuracy: 0.2846 - val_loss: 2.5570 - val_accuracy: 0.2909\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5305 - accuracy: 0.2885 - val_loss: 2.5300 - val_accuracy: 0.2933\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.5089 - accuracy: 0.2866 - val_loss: 2.5091 - val_accuracy: 0.2668\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.4747 - accuracy: 0.2950 - val_loss: 2.4871 - val_accuracy: 0.2861\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.4510 - accuracy: 0.2990 - val_loss: 2.4646 - val_accuracy: 0.2788\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.4315 - accuracy: 0.2866 - val_loss: 2.4425 - val_accuracy: 0.2933\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.3974 - accuracy: 0.2918 - val_loss: 2.4227 - val_accuracy: 0.3053\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.3719 - accuracy: 0.2977 - val_loss: 2.3966 - val_accuracy: 0.2885\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.3966 - accuracy: 0.2885\n",
      "Fold 4 - Validation Loss: 2.3966, Validation Accuracy: 0.2885\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 50ms/step - loss: 3.3299 - accuracy: 0.1586 - val_loss: 3.2855 - val_accuracy: 0.1947\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.2644 - accuracy: 0.1704 - val_loss: 3.2278 - val_accuracy: 0.1827\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.2031 - accuracy: 0.1841 - val_loss: 3.1760 - val_accuracy: 0.1947\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.1525 - accuracy: 0.1906 - val_loss: 3.1257 - val_accuracy: 0.2043\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.0995 - accuracy: 0.2115 - val_loss: 3.0764 - val_accuracy: 0.2115\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.0465 - accuracy: 0.2252 - val_loss: 3.0276 - val_accuracy: 0.2332\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.9968 - accuracy: 0.2467 - val_loss: 2.9802 - val_accuracy: 0.2452\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.9389 - accuracy: 0.2448 - val_loss: 2.9330 - val_accuracy: 0.2332\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.8908 - accuracy: 0.2604 - val_loss: 2.8863 - val_accuracy: 0.2572\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.8341 - accuracy: 0.2657 - val_loss: 2.8514 - val_accuracy: 0.2308\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.7879 - accuracy: 0.2820 - val_loss: 2.8026 - val_accuracy: 0.2428\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.7465 - accuracy: 0.2755 - val_loss: 2.7722 - val_accuracy: 0.2428\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.6913 - accuracy: 0.2833 - val_loss: 2.7316 - val_accuracy: 0.2476\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6685 - accuracy: 0.3009 - val_loss: 2.7168 - val_accuracy: 0.2476\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6219 - accuracy: 0.2846 - val_loss: 2.6958 - val_accuracy: 0.2308\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.5914 - accuracy: 0.2937 - val_loss: 2.6666 - val_accuracy: 0.2332\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.5439 - accuracy: 0.3016 - val_loss: 2.6203 - val_accuracy: 0.2452\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.5297 - accuracy: 0.2957 - val_loss: 2.6299 - val_accuracy: 0.2308\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.4998 - accuracy: 0.3016 - val_loss: 2.5876 - val_accuracy: 0.2308\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.4773 - accuracy: 0.2957 - val_loss: 2.5767 - val_accuracy: 0.2308\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.4420 - accuracy: 0.3016 - val_loss: 2.5444 - val_accuracy: 0.2404\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.4101 - accuracy: 0.3120 - val_loss: 2.5185 - val_accuracy: 0.2428\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.3896 - accuracy: 0.3140 - val_loss: 2.5336 - val_accuracy: 0.2188\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.3655 - accuracy: 0.3101 - val_loss: 2.4915 - val_accuracy: 0.2308\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.3492 - accuracy: 0.3055 - val_loss: 2.4665 - val_accuracy: 0.2332\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4665 - accuracy: 0.2332\n",
      "Fold 5 - Validation Loss: 2.4665, Validation Accuracy: 0.2332\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 52ms/step - loss: 3.3605 - accuracy: 0.1318 - val_loss: 3.3028 - val_accuracy: 0.1958\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.2844 - accuracy: 0.1586 - val_loss: 3.2367 - val_accuracy: 0.1878\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 3.2288 - accuracy: 0.1752 - val_loss: 3.1802 - val_accuracy: 0.1852\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.1733 - accuracy: 0.1943 - val_loss: 3.1276 - val_accuracy: 0.2169\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.1133 - accuracy: 0.2045 - val_loss: 3.0753 - val_accuracy: 0.2090\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 3.0710 - accuracy: 0.2102 - val_loss: 3.0295 - val_accuracy: 0.2169\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 3.0268 - accuracy: 0.2197 - val_loss: 2.9777 - val_accuracy: 0.2460\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.9735 - accuracy: 0.2433 - val_loss: 2.9304 - val_accuracy: 0.2487\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.9268 - accuracy: 0.2439 - val_loss: 2.8844 - val_accuracy: 0.2566\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.8823 - accuracy: 0.2522 - val_loss: 2.8427 - val_accuracy: 0.2487\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.8480 - accuracy: 0.2497 - val_loss: 2.7900 - val_accuracy: 0.2566\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.8005 - accuracy: 0.2516 - val_loss: 2.7709 - val_accuracy: 0.2593\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.7553 - accuracy: 0.2732 - val_loss: 2.7326 - val_accuracy: 0.2381\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 2.7266 - accuracy: 0.2720 - val_loss: 2.6928 - val_accuracy: 0.2646\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.6985 - accuracy: 0.2669 - val_loss: 2.6468 - val_accuracy: 0.2646\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.6589 - accuracy: 0.2618 - val_loss: 2.6192 - val_accuracy: 0.2487\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 2.6173 - accuracy: 0.2675 - val_loss: 2.5878 - val_accuracy: 0.2487\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.5905 - accuracy: 0.2828 - val_loss: 2.5614 - val_accuracy: 0.2487\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.5763 - accuracy: 0.2752 - val_loss: 2.5342 - val_accuracy: 0.2566\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.5411 - accuracy: 0.2720 - val_loss: 2.4976 - val_accuracy: 0.2513\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.5198 - accuracy: 0.2726 - val_loss: 2.4634 - val_accuracy: 0.2698\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.4916 - accuracy: 0.2815 - val_loss: 2.4532 - val_accuracy: 0.2540\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 2.4574 - accuracy: 0.2796 - val_loss: 2.4355 - val_accuracy: 0.2354\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.4327 - accuracy: 0.2828 - val_loss: 2.3918 - val_accuracy: 0.2725\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.4212 - accuracy: 0.2866 - val_loss: 2.3747 - val_accuracy: 0.2619\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3747 - accuracy: 0.2619\n",
      "Fold 1 - Validation Loss: 2.3747, Validation Accuracy: 0.2619\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 4s 47ms/step - loss: 3.3047 - accuracy: 0.1613 - val_loss: 3.2485 - val_accuracy: 0.2201\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.2374 - accuracy: 0.1865 - val_loss: 3.1767 - val_accuracy: 0.2956\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.1758 - accuracy: 0.1982 - val_loss: 3.1087 - val_accuracy: 0.3145\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.1065 - accuracy: 0.2166 - val_loss: 3.0390 - val_accuracy: 0.3113\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.0542 - accuracy: 0.2209 - val_loss: 2.9755 - val_accuracy: 0.3302\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.9965 - accuracy: 0.2429 - val_loss: 2.9111 - val_accuracy: 0.3208\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 2.9427 - accuracy: 0.2589 - val_loss: 2.8560 - val_accuracy: 0.3176\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.9047 - accuracy: 0.2429 - val_loss: 2.8132 - val_accuracy: 0.3145\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.8444 - accuracy: 0.2534 - val_loss: 2.7610 - val_accuracy: 0.3239\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.8126 - accuracy: 0.2552 - val_loss: 2.7202 - val_accuracy: 0.3082\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 2.7586 - accuracy: 0.2681 - val_loss: 2.6755 - val_accuracy: 0.3145\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.7165 - accuracy: 0.2644 - val_loss: 2.6262 - val_accuracy: 0.3302\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 2.6836 - accuracy: 0.2736 - val_loss: 2.5952 - val_accuracy: 0.3208\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.6648 - accuracy: 0.2607 - val_loss: 2.5645 - val_accuracy: 0.3239\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.6087 - accuracy: 0.2736 - val_loss: 2.5299 - val_accuracy: 0.3302\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.5991 - accuracy: 0.2656 - val_loss: 2.5001 - val_accuracy: 0.3365\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.5630 - accuracy: 0.2607 - val_loss: 2.4734 - val_accuracy: 0.3396\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 2.5329 - accuracy: 0.2859 - val_loss: 2.4438 - val_accuracy: 0.3365\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.5029 - accuracy: 0.2761 - val_loss: 2.4205 - val_accuracy: 0.3302\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.4743 - accuracy: 0.2761 - val_loss: 2.3937 - val_accuracy: 0.3333\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 2.4409 - accuracy: 0.2871 - val_loss: 2.3658 - val_accuracy: 0.3270\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.4149 - accuracy: 0.3092 - val_loss: 2.3470 - val_accuracy: 0.3365\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.4024 - accuracy: 0.2963 - val_loss: 2.3308 - val_accuracy: 0.3333\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.3625 - accuracy: 0.3000 - val_loss: 2.3216 - val_accuracy: 0.3239\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 2.3447 - accuracy: 0.3012 - val_loss: 2.2894 - val_accuracy: 0.3270\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.2894 - accuracy: 0.3270\n",
      "Fold 2 - Validation Loss: 2.2894, Validation Accuracy: 0.3270\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 51ms/step - loss: 3.3489 - accuracy: 0.1289 - val_loss: 3.2970 - val_accuracy: 0.1643\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.2770 - accuracy: 0.1453 - val_loss: 3.2394 - val_accuracy: 0.2000\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.2188 - accuracy: 0.1774 - val_loss: 3.1891 - val_accuracy: 0.2357\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.1648 - accuracy: 0.2140 - val_loss: 3.1407 - val_accuracy: 0.2476\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.1182 - accuracy: 0.2016 - val_loss: 3.0942 - val_accuracy: 0.2571\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.0674 - accuracy: 0.2264 - val_loss: 3.0488 - val_accuracy: 0.2381\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.0165 - accuracy: 0.2219 - val_loss: 3.0056 - val_accuracy: 0.2214\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.9734 - accuracy: 0.2284 - val_loss: 2.9652 - val_accuracy: 0.2071\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.9181 - accuracy: 0.2507 - val_loss: 2.9230 - val_accuracy: 0.2024\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.8859 - accuracy: 0.2487 - val_loss: 2.8841 - val_accuracy: 0.2190\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.8349 - accuracy: 0.2454 - val_loss: 2.8491 - val_accuracy: 0.2119\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.7999 - accuracy: 0.2513 - val_loss: 2.8176 - val_accuracy: 0.2238\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.7641 - accuracy: 0.2579 - val_loss: 2.7831 - val_accuracy: 0.2357\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.7293 - accuracy: 0.2493 - val_loss: 2.7471 - val_accuracy: 0.2357\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.6954 - accuracy: 0.2487 - val_loss: 2.7155 - val_accuracy: 0.2548\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.6512 - accuracy: 0.2775 - val_loss: 2.6845 - val_accuracy: 0.2452\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6154 - accuracy: 0.2723 - val_loss: 2.6636 - val_accuracy: 0.2595\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.5824 - accuracy: 0.2834 - val_loss: 2.6299 - val_accuracy: 0.2429\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.5601 - accuracy: 0.2664 - val_loss: 2.5994 - val_accuracy: 0.2667\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.5451 - accuracy: 0.2775 - val_loss: 2.5757 - val_accuracy: 0.2643\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5067 - accuracy: 0.2795 - val_loss: 2.5581 - val_accuracy: 0.2548\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.4770 - accuracy: 0.2775 - val_loss: 2.5353 - val_accuracy: 0.2667\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.4671 - accuracy: 0.2696 - val_loss: 2.5061 - val_accuracy: 0.2571\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.4165 - accuracy: 0.2965 - val_loss: 2.4938 - val_accuracy: 0.2595\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.4063 - accuracy: 0.2880 - val_loss: 2.4724 - val_accuracy: 0.2619\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.4724 - accuracy: 0.2619\n",
      "Fold 3 - Validation Loss: 2.4724, Validation Accuracy: 0.2619\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 50ms/step - loss: 3.3366 - accuracy: 0.1181 - val_loss: 3.2871 - val_accuracy: 0.1322\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.2735 - accuracy: 0.1508 - val_loss: 3.2271 - val_accuracy: 0.1394\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.2187 - accuracy: 0.1651 - val_loss: 3.1753 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.1639 - accuracy: 0.1730 - val_loss: 3.1252 - val_accuracy: 0.1611\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.1121 - accuracy: 0.2043 - val_loss: 3.0776 - val_accuracy: 0.2091\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.0581 - accuracy: 0.2095 - val_loss: 3.0252 - val_accuracy: 0.2981\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.0205 - accuracy: 0.2252 - val_loss: 2.9761 - val_accuracy: 0.2812\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.9705 - accuracy: 0.2369 - val_loss: 2.9293 - val_accuracy: 0.2668\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.9226 - accuracy: 0.2409 - val_loss: 2.8796 - val_accuracy: 0.2812\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.8790 - accuracy: 0.2265 - val_loss: 2.8323 - val_accuracy: 0.2788\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.8354 - accuracy: 0.2474 - val_loss: 2.7884 - val_accuracy: 0.2716\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.7878 - accuracy: 0.2624 - val_loss: 2.7447 - val_accuracy: 0.2812\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.7470 - accuracy: 0.2644 - val_loss: 2.7047 - val_accuracy: 0.2837\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.7093 - accuracy: 0.2657 - val_loss: 2.6794 - val_accuracy: 0.2692\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6692 - accuracy: 0.2755 - val_loss: 2.6470 - val_accuracy: 0.2764\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6316 - accuracy: 0.2794 - val_loss: 2.6154 - val_accuracy: 0.2812\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6025 - accuracy: 0.2683 - val_loss: 2.5894 - val_accuracy: 0.2837\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5728 - accuracy: 0.2787 - val_loss: 2.5636 - val_accuracy: 0.2788\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.5513 - accuracy: 0.2722 - val_loss: 2.5361 - val_accuracy: 0.2909\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.5100 - accuracy: 0.2702 - val_loss: 2.5127 - val_accuracy: 0.2885\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.4919 - accuracy: 0.2774 - val_loss: 2.4814 - val_accuracy: 0.2981\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.4621 - accuracy: 0.2807 - val_loss: 2.4563 - val_accuracy: 0.3077\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.4243 - accuracy: 0.3003 - val_loss: 2.4428 - val_accuracy: 0.2933\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.4226 - accuracy: 0.2963 - val_loss: 2.4163 - val_accuracy: 0.3053\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.3916 - accuracy: 0.2950 - val_loss: 2.4034 - val_accuracy: 0.2957\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4034 - accuracy: 0.2957\n",
      "Fold 4 - Validation Loss: 2.4034, Validation Accuracy: 0.2957\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 51ms/step - loss: 3.3644 - accuracy: 0.1221 - val_loss: 3.3170 - val_accuracy: 0.1827\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.2985 - accuracy: 0.1534 - val_loss: 3.2496 - val_accuracy: 0.2548\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.2367 - accuracy: 0.1906 - val_loss: 3.1932 - val_accuracy: 0.2404\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.1786 - accuracy: 0.2076 - val_loss: 3.1349 - val_accuracy: 0.2692\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.1279 - accuracy: 0.2193 - val_loss: 3.0853 - val_accuracy: 0.2284\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.0679 - accuracy: 0.2507 - val_loss: 3.0421 - val_accuracy: 0.2212\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.0255 - accuracy: 0.2422 - val_loss: 2.9927 - val_accuracy: 0.2115\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.9622 - accuracy: 0.2487 - val_loss: 2.9460 - val_accuracy: 0.2284\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.9264 - accuracy: 0.2637 - val_loss: 2.9065 - val_accuracy: 0.2500\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.8775 - accuracy: 0.2644 - val_loss: 2.8743 - val_accuracy: 0.2356\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.8281 - accuracy: 0.2631 - val_loss: 2.8357 - val_accuracy: 0.2476\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.7893 - accuracy: 0.2676 - val_loss: 2.7956 - val_accuracy: 0.2524\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.7475 - accuracy: 0.2722 - val_loss: 2.7662 - val_accuracy: 0.2524\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.7117 - accuracy: 0.2683 - val_loss: 2.7488 - val_accuracy: 0.2644\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6739 - accuracy: 0.2774 - val_loss: 2.7247 - val_accuracy: 0.2572\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.6482 - accuracy: 0.2983 - val_loss: 2.6812 - val_accuracy: 0.2548\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.6227 - accuracy: 0.2781 - val_loss: 2.6427 - val_accuracy: 0.2692\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.5830 - accuracy: 0.2813 - val_loss: 2.6498 - val_accuracy: 0.2476\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.5573 - accuracy: 0.2937 - val_loss: 2.6017 - val_accuracy: 0.2548\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.5339 - accuracy: 0.2898 - val_loss: 2.5932 - val_accuracy: 0.2452\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5069 - accuracy: 0.2872 - val_loss: 2.5488 - val_accuracy: 0.2644\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.4764 - accuracy: 0.2885 - val_loss: 2.5338 - val_accuracy: 0.2644\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.4575 - accuracy: 0.2983 - val_loss: 2.5429 - val_accuracy: 0.2428\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.4231 - accuracy: 0.3087 - val_loss: 2.4902 - val_accuracy: 0.2644\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.4093 - accuracy: 0.3081 - val_loss: 2.4828 - val_accuracy: 0.2500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4828 - accuracy: 0.2500\n",
      "Fold 5 - Validation Loss: 2.4828, Validation Accuracy: 0.2500\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 51ms/step - loss: 3.3826 - accuracy: 0.1268 - val_loss: 3.3204 - val_accuracy: 0.1534\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 3.3190 - accuracy: 0.1446 - val_loss: 3.2741 - val_accuracy: 0.1349\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 3.2776 - accuracy: 0.1503 - val_loss: 3.2317 - val_accuracy: 0.1058\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.2222 - accuracy: 0.1631 - val_loss: 3.1919 - val_accuracy: 0.1270\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.1925 - accuracy: 0.1586 - val_loss: 3.1543 - val_accuracy: 0.1799\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 3.1405 - accuracy: 0.1803 - val_loss: 3.1164 - val_accuracy: 0.2116\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.1049 - accuracy: 0.1669 - val_loss: 3.0807 - val_accuracy: 0.2196\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.0717 - accuracy: 0.1771 - val_loss: 3.0456 - val_accuracy: 0.2566\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.0419 - accuracy: 0.1707 - val_loss: 3.0119 - val_accuracy: 0.2275\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 3.0146 - accuracy: 0.1586 - val_loss: 2.9797 - val_accuracy: 0.2513\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.9731 - accuracy: 0.1860 - val_loss: 2.9490 - val_accuracy: 0.2540\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 2.9481 - accuracy: 0.1752 - val_loss: 2.9172 - val_accuracy: 0.2354\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 2.9097 - accuracy: 0.1904 - val_loss: 2.8864 - val_accuracy: 0.2460\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.8817 - accuracy: 0.1809 - val_loss: 2.8556 - val_accuracy: 0.2196\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.8506 - accuracy: 0.1955 - val_loss: 2.8264 - val_accuracy: 0.2381\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.8107 - accuracy: 0.1987 - val_loss: 2.7966 - val_accuracy: 0.2302\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.7891 - accuracy: 0.2013 - val_loss: 2.7683 - val_accuracy: 0.2302\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.7660 - accuracy: 0.2115 - val_loss: 2.7420 - val_accuracy: 0.2196\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.7429 - accuracy: 0.1975 - val_loss: 2.7147 - val_accuracy: 0.2169\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.7156 - accuracy: 0.2013 - val_loss: 2.6857 - val_accuracy: 0.2275\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.6914 - accuracy: 0.2121 - val_loss: 2.6569 - val_accuracy: 0.2381\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.6523 - accuracy: 0.2166 - val_loss: 2.6326 - val_accuracy: 0.2275\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.6339 - accuracy: 0.2236 - val_loss: 2.6049 - val_accuracy: 0.2302\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 2.6080 - accuracy: 0.2255 - val_loss: 2.5849 - val_accuracy: 0.2249\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.5811 - accuracy: 0.2331 - val_loss: 2.5598 - val_accuracy: 0.2302\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5598 - accuracy: 0.2302\n",
      "Fold 1 - Validation Loss: 2.5598, Validation Accuracy: 0.2302\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 5s 51ms/step - loss: 3.3741 - accuracy: 0.1252 - val_loss: 3.3067 - val_accuracy: 0.1730\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.3209 - accuracy: 0.1319 - val_loss: 3.2528 - val_accuracy: 0.2296\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.2629 - accuracy: 0.1534 - val_loss: 3.2072 - val_accuracy: 0.1918\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.2215 - accuracy: 0.1595 - val_loss: 3.1648 - val_accuracy: 0.2201\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.1847 - accuracy: 0.1589 - val_loss: 3.1256 - val_accuracy: 0.2044\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.1494 - accuracy: 0.1546 - val_loss: 3.0887 - val_accuracy: 0.2013\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.0992 - accuracy: 0.1798 - val_loss: 3.0536 - val_accuracy: 0.2044\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.0734 - accuracy: 0.1755 - val_loss: 3.0196 - val_accuracy: 0.2013\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.0433 - accuracy: 0.1798 - val_loss: 2.9860 - val_accuracy: 0.1981\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.0044 - accuracy: 0.1785 - val_loss: 2.9531 - val_accuracy: 0.2138\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.9707 - accuracy: 0.1853 - val_loss: 2.9208 - val_accuracy: 0.2233\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 2.9432 - accuracy: 0.1840 - val_loss: 2.8889 - val_accuracy: 0.2296\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.9085 - accuracy: 0.1804 - val_loss: 2.8563 - val_accuracy: 0.2390\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.8811 - accuracy: 0.1804 - val_loss: 2.8252 - val_accuracy: 0.2579\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.8561 - accuracy: 0.1816 - val_loss: 2.7963 - val_accuracy: 0.2799\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.8231 - accuracy: 0.1957 - val_loss: 2.7649 - val_accuracy: 0.2862\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.7873 - accuracy: 0.1963 - val_loss: 2.7316 - val_accuracy: 0.2799\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.7544 - accuracy: 0.2184 - val_loss: 2.6974 - val_accuracy: 0.2956\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.7360 - accuracy: 0.2025 - val_loss: 2.6656 - val_accuracy: 0.3050\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.7062 - accuracy: 0.2233 - val_loss: 2.6335 - val_accuracy: 0.3050\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.6832 - accuracy: 0.2117 - val_loss: 2.6055 - val_accuracy: 0.2799\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 2.6532 - accuracy: 0.2245 - val_loss: 2.5725 - val_accuracy: 0.3113\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.6148 - accuracy: 0.2294 - val_loss: 2.5416 - val_accuracy: 0.2925\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.5966 - accuracy: 0.2325 - val_loss: 2.5151 - val_accuracy: 0.3019\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.5796 - accuracy: 0.2294 - val_loss: 2.4874 - val_accuracy: 0.3113\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.4874 - accuracy: 0.3113\n",
      "Fold 2 - Validation Loss: 2.4874, Validation Accuracy: 0.3113\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 56ms/step - loss: 3.3910 - accuracy: 0.1296 - val_loss: 3.3212 - val_accuracy: 0.1405\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.3386 - accuracy: 0.1361 - val_loss: 3.2733 - val_accuracy: 0.1405\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.2751 - accuracy: 0.1597 - val_loss: 3.2306 - val_accuracy: 0.1476\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.2443 - accuracy: 0.1492 - val_loss: 3.1908 - val_accuracy: 0.1738\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 3.1993 - accuracy: 0.1479 - val_loss: 3.1548 - val_accuracy: 0.1643\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.1553 - accuracy: 0.1636 - val_loss: 3.1195 - val_accuracy: 0.1690\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.1187 - accuracy: 0.1832 - val_loss: 3.0851 - val_accuracy: 0.1738\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 3.0861 - accuracy: 0.1767 - val_loss: 3.0523 - val_accuracy: 0.1833\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.0526 - accuracy: 0.1682 - val_loss: 3.0198 - val_accuracy: 0.1857\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.0173 - accuracy: 0.1610 - val_loss: 2.9873 - val_accuracy: 0.2119\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.9930 - accuracy: 0.1616 - val_loss: 2.9564 - val_accuracy: 0.2190\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.9545 - accuracy: 0.1911 - val_loss: 2.9271 - val_accuracy: 0.2333\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.9236 - accuracy: 0.1754 - val_loss: 2.8977 - val_accuracy: 0.2048\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.8908 - accuracy: 0.1970 - val_loss: 2.8672 - val_accuracy: 0.2405\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.8567 - accuracy: 0.2068 - val_loss: 2.8378 - val_accuracy: 0.2310\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.8299 - accuracy: 0.1957 - val_loss: 2.8107 - val_accuracy: 0.2333\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.7997 - accuracy: 0.2029 - val_loss: 2.7842 - val_accuracy: 0.2286\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.7740 - accuracy: 0.1963 - val_loss: 2.7560 - val_accuracy: 0.2238\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.7438 - accuracy: 0.1976 - val_loss: 2.7315 - val_accuracy: 0.2143\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.7206 - accuracy: 0.1970 - val_loss: 2.7039 - val_accuracy: 0.2167\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.6767 - accuracy: 0.2284 - val_loss: 2.6794 - val_accuracy: 0.2119\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.6562 - accuracy: 0.2114 - val_loss: 2.6539 - val_accuracy: 0.2119\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.6334 - accuracy: 0.2081 - val_loss: 2.6313 - val_accuracy: 0.2310\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.5988 - accuracy: 0.2258 - val_loss: 2.6110 - val_accuracy: 0.2238\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.5885 - accuracy: 0.2225 - val_loss: 2.5900 - val_accuracy: 0.2143\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.5900 - accuracy: 0.2143\n",
      "Fold 3 - Validation Loss: 2.5900, Validation Accuracy: 0.2143\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 8s 57ms/step - loss: 3.3665 - accuracy: 0.1416 - val_loss: 3.3038 - val_accuracy: 0.1514\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 3.3076 - accuracy: 0.1475 - val_loss: 3.2569 - val_accuracy: 0.1322\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.2678 - accuracy: 0.1456 - val_loss: 3.2194 - val_accuracy: 0.1466\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.2324 - accuracy: 0.1671 - val_loss: 3.1832 - val_accuracy: 0.1587\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.1945 - accuracy: 0.1547 - val_loss: 3.1484 - val_accuracy: 0.1779\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.1566 - accuracy: 0.1717 - val_loss: 3.1128 - val_accuracy: 0.2019\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.1162 - accuracy: 0.1684 - val_loss: 3.0788 - val_accuracy: 0.2260\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.0826 - accuracy: 0.1789 - val_loss: 3.0460 - val_accuracy: 0.2356\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.0423 - accuracy: 0.1899 - val_loss: 3.0141 - val_accuracy: 0.2524\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.0147 - accuracy: 0.1867 - val_loss: 2.9844 - val_accuracy: 0.2404\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.9826 - accuracy: 0.1867 - val_loss: 2.9534 - val_accuracy: 0.2380\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.9562 - accuracy: 0.1762 - val_loss: 2.9203 - val_accuracy: 0.2332\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.9309 - accuracy: 0.1841 - val_loss: 2.8885 - val_accuracy: 0.2500\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.8987 - accuracy: 0.1932 - val_loss: 2.8584 - val_accuracy: 0.2692\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.8594 - accuracy: 0.1932 - val_loss: 2.8288 - val_accuracy: 0.2716\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.8282 - accuracy: 0.2128 - val_loss: 2.8020 - val_accuracy: 0.2620\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.8052 - accuracy: 0.2089 - val_loss: 2.7711 - val_accuracy: 0.2692\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.7693 - accuracy: 0.2010 - val_loss: 2.7437 - val_accuracy: 0.2596\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.7446 - accuracy: 0.2161 - val_loss: 2.7163 - val_accuracy: 0.2596\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.7144 - accuracy: 0.2285 - val_loss: 2.6906 - val_accuracy: 0.2644\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.6911 - accuracy: 0.2213 - val_loss: 2.6664 - val_accuracy: 0.2572\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.6633 - accuracy: 0.2219 - val_loss: 2.6405 - val_accuracy: 0.2524\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.6316 - accuracy: 0.2272 - val_loss: 2.6189 - val_accuracy: 0.2356\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.6115 - accuracy: 0.2219 - val_loss: 2.5914 - val_accuracy: 0.2572\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.5793 - accuracy: 0.2565 - val_loss: 2.5646 - val_accuracy: 0.2668\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5646 - accuracy: 0.2668\n",
      "Fold 4 - Validation Loss: 2.5646, Validation Accuracy: 0.2668\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 63ms/step - loss: 3.3641 - accuracy: 0.1299 - val_loss: 3.3084 - val_accuracy: 0.1418\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 3.3111 - accuracy: 0.1430 - val_loss: 3.2596 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.2696 - accuracy: 0.1430 - val_loss: 3.2183 - val_accuracy: 0.1611\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.2158 - accuracy: 0.1625 - val_loss: 3.1786 - val_accuracy: 0.2115\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.1785 - accuracy: 0.1651 - val_loss: 3.1391 - val_accuracy: 0.2404\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.1379 - accuracy: 0.1664 - val_loss: 3.1027 - val_accuracy: 0.2524\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 3.1119 - accuracy: 0.1749 - val_loss: 3.0675 - val_accuracy: 0.2620\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.0653 - accuracy: 0.1860 - val_loss: 3.0337 - val_accuracy: 0.2668\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.0255 - accuracy: 0.1926 - val_loss: 3.0005 - val_accuracy: 0.2572\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 3.0050 - accuracy: 0.1926 - val_loss: 2.9678 - val_accuracy: 0.2452\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.9718 - accuracy: 0.1971 - val_loss: 2.9360 - val_accuracy: 0.2380\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.9346 - accuracy: 0.1899 - val_loss: 2.9034 - val_accuracy: 0.2476\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.9061 - accuracy: 0.2017 - val_loss: 2.8733 - val_accuracy: 0.2668\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.8744 - accuracy: 0.2206 - val_loss: 2.8414 - val_accuracy: 0.2476\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.8380 - accuracy: 0.2291 - val_loss: 2.8117 - val_accuracy: 0.2428\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.8104 - accuracy: 0.2206 - val_loss: 2.7806 - val_accuracy: 0.2476\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.7679 - accuracy: 0.2272 - val_loss: 2.7523 - val_accuracy: 0.2404\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.7319 - accuracy: 0.2356 - val_loss: 2.7202 - val_accuracy: 0.2404\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 2.7123 - accuracy: 0.2474 - val_loss: 2.6983 - val_accuracy: 0.2404\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.6811 - accuracy: 0.2513 - val_loss: 2.6661 - val_accuracy: 0.2428\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.6618 - accuracy: 0.2389 - val_loss: 2.6517 - val_accuracy: 0.2380\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.6406 - accuracy: 0.2396 - val_loss: 2.6257 - val_accuracy: 0.2428\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.5974 - accuracy: 0.2709 - val_loss: 2.5979 - val_accuracy: 0.2452\n",
      "Epoch 24/25\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 2.5769 - accuracy: 0.2480 - val_loss: 2.5763 - val_accuracy: 0.2380\n",
      "Epoch 25/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.5477 - accuracy: 0.2467 - val_loss: 2.5613 - val_accuracy: 0.2404\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.5613 - accuracy: 0.2404\n",
      "Fold 5 - Validation Loss: 2.5613, Validation Accuracy: 0.2404\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 57ms/step - loss: 3.0921 - accuracy: 0.1962 - val_loss: 2.8195 - val_accuracy: 0.2143\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 2.6586 - accuracy: 0.2497 - val_loss: 2.5375 - val_accuracy: 0.2011\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 2.4155 - accuracy: 0.2618 - val_loss: 2.3658 - val_accuracy: 0.2275\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 2.2507 - accuracy: 0.2567 - val_loss: 2.1687 - val_accuracy: 0.2646\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 2.1299 - accuracy: 0.2822 - val_loss: 2.0956 - val_accuracy: 0.2460\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 2.0346 - accuracy: 0.2803 - val_loss: 1.9825 - val_accuracy: 0.2857\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.9761 - accuracy: 0.2777 - val_loss: 1.9752 - val_accuracy: 0.2646\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.9266 - accuracy: 0.2904 - val_loss: 1.9763 - val_accuracy: 0.2407\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.8997 - accuracy: 0.3096 - val_loss: 1.8952 - val_accuracy: 0.2831\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.8682 - accuracy: 0.3032 - val_loss: 1.8745 - val_accuracy: 0.2804\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.8650 - accuracy: 0.2994 - val_loss: 1.8888 - val_accuracy: 0.2751\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.8454 - accuracy: 0.3032 - val_loss: 1.8285 - val_accuracy: 0.2831\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.8241 - accuracy: 0.3083 - val_loss: 1.8296 - val_accuracy: 0.3069\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.8169 - accuracy: 0.3038 - val_loss: 1.8167 - val_accuracy: 0.3095\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.8088 - accuracy: 0.3070 - val_loss: 1.8077 - val_accuracy: 0.2937\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.8087 - accuracy: 0.3197 - val_loss: 1.7956 - val_accuracy: 0.3042\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.7879 - accuracy: 0.3127 - val_loss: 1.8010 - val_accuracy: 0.3148\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.8011 - accuracy: 0.3051 - val_loss: 1.8297 - val_accuracy: 0.3016\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 1.7950 - accuracy: 0.3064 - val_loss: 1.7978 - val_accuracy: 0.2857\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7956 - accuracy: 0.3042\n",
      "Fold 1 - Validation Loss: 1.7956, Validation Accuracy: 0.3042\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 4s 53ms/step - loss: 3.1030 - accuracy: 0.1663 - val_loss: 2.8085 - val_accuracy: 0.2893\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 2.6720 - accuracy: 0.2245 - val_loss: 2.4264 - val_accuracy: 0.2893\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 2.3870 - accuracy: 0.2387 - val_loss: 2.1891 - val_accuracy: 0.2987\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 2.2345 - accuracy: 0.2454 - val_loss: 2.0943 - val_accuracy: 0.3082\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 2.1023 - accuracy: 0.2632 - val_loss: 1.9594 - val_accuracy: 0.2925\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 2.0324 - accuracy: 0.2675 - val_loss: 1.9002 - val_accuracy: 0.3302\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.9542 - accuracy: 0.2810 - val_loss: 1.8556 - val_accuracy: 0.3270\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.9310 - accuracy: 0.2853 - val_loss: 1.8576 - val_accuracy: 0.3082\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8962 - accuracy: 0.2890 - val_loss: 1.7929 - val_accuracy: 0.3270\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8719 - accuracy: 0.2963 - val_loss: 1.8128 - val_accuracy: 0.3113\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8834 - accuracy: 0.2963 - val_loss: 1.7901 - val_accuracy: 0.3239\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8557 - accuracy: 0.2834 - val_loss: 1.7658 - val_accuracy: 0.3176\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8317 - accuracy: 0.2920 - val_loss: 1.9115 - val_accuracy: 0.2296\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8332 - accuracy: 0.2847 - val_loss: 1.8202 - val_accuracy: 0.2925\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 1.8004 - accuracy: 0.3049 - val_loss: 1.8044 - val_accuracy: 0.2956\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7658 - accuracy: 0.3176\n",
      "Fold 2 - Validation Loss: 1.7658, Validation Accuracy: 0.3176\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 58ms/step - loss: 3.1119 - accuracy: 0.1878 - val_loss: 2.8664 - val_accuracy: 0.2143\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.6677 - accuracy: 0.2657 - val_loss: 2.5531 - val_accuracy: 0.2286\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.3867 - accuracy: 0.2709 - val_loss: 2.3342 - val_accuracy: 0.2571\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.2130 - accuracy: 0.2781 - val_loss: 2.1697 - val_accuracy: 0.2976\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.1194 - accuracy: 0.2644 - val_loss: 2.1137 - val_accuracy: 0.2452\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.0271 - accuracy: 0.2866 - val_loss: 2.0507 - val_accuracy: 0.2762\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.9639 - accuracy: 0.2781 - val_loss: 1.9686 - val_accuracy: 0.3048\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.9235 - accuracy: 0.2952 - val_loss: 1.9245 - val_accuracy: 0.3119\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.8997 - accuracy: 0.2938 - val_loss: 1.9542 - val_accuracy: 0.2810\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.8857 - accuracy: 0.2880 - val_loss: 1.9080 - val_accuracy: 0.2881\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.8535 - accuracy: 0.3010 - val_loss: 1.8764 - val_accuracy: 0.2952\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.8435 - accuracy: 0.2958 - val_loss: 1.8850 - val_accuracy: 0.2976\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.8655 - accuracy: 0.2925 - val_loss: 1.8920 - val_accuracy: 0.3071\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.8629 - accuracy: 0.2834 - val_loss: 1.8919 - val_accuracy: 0.2452\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.8764 - accuracy: 0.2952\n",
      "Fold 3 - Validation Loss: 1.8764, Validation Accuracy: 0.2952\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 54ms/step - loss: 3.1255 - accuracy: 0.1886 - val_loss: 2.8797 - val_accuracy: 0.2067\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.7011 - accuracy: 0.2493 - val_loss: 2.5252 - val_accuracy: 0.2596\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.4330 - accuracy: 0.2702 - val_loss: 2.3048 - val_accuracy: 0.2692\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.2560 - accuracy: 0.2715 - val_loss: 2.2129 - val_accuracy: 0.2596\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.1436 - accuracy: 0.2800 - val_loss: 2.0909 - val_accuracy: 0.2620\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0432 - accuracy: 0.2670 - val_loss: 2.0080 - val_accuracy: 0.2957\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9932 - accuracy: 0.2774 - val_loss: 1.9657 - val_accuracy: 0.3053\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9386 - accuracy: 0.2866 - val_loss: 1.9521 - val_accuracy: 0.2957\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9040 - accuracy: 0.3029 - val_loss: 1.8904 - val_accuracy: 0.3077\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8838 - accuracy: 0.2892 - val_loss: 1.8926 - val_accuracy: 0.2909\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.8746 - accuracy: 0.2937 - val_loss: 1.8342 - val_accuracy: 0.3197\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8298 - accuracy: 0.3133 - val_loss: 1.8227 - val_accuracy: 0.2933\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.8079 - accuracy: 0.3244 - val_loss: 1.8038 - val_accuracy: 0.3005\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.7990 - accuracy: 0.3042 - val_loss: 1.8175 - val_accuracy: 0.2788\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.7930 - accuracy: 0.3114 - val_loss: 1.8239 - val_accuracy: 0.3077\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8087 - accuracy: 0.3140 - val_loss: 1.7892 - val_accuracy: 0.3582\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.7513 - accuracy: 0.3192 - val_loss: 1.7590 - val_accuracy: 0.3269\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.7777 - accuracy: 0.3107 - val_loss: 1.8288 - val_accuracy: 0.2861\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.7276 - accuracy: 0.3420 - val_loss: 1.7500 - val_accuracy: 0.3317\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 1.7350 - accuracy: 0.3427 - val_loss: 1.7811 - val_accuracy: 0.3149\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.7539 - accuracy: 0.3296 - val_loss: 1.7747 - val_accuracy: 0.3438\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.7372 - accuracy: 0.3322 - val_loss: 1.7677 - val_accuracy: 0.3269\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7500 - accuracy: 0.3317\n",
      "Fold 4 - Validation Loss: 1.7500, Validation Accuracy: 0.3317\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 52ms/step - loss: 3.1271 - accuracy: 0.1756 - val_loss: 2.8871 - val_accuracy: 0.2524\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.7010 - accuracy: 0.2396 - val_loss: 2.5541 - val_accuracy: 0.2067\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.3975 - accuracy: 0.2670 - val_loss: 2.4131 - val_accuracy: 0.2212\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.2400 - accuracy: 0.2644 - val_loss: 2.1943 - val_accuracy: 0.2404\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0957 - accuracy: 0.2735 - val_loss: 2.0997 - val_accuracy: 0.2284\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0060 - accuracy: 0.2963 - val_loss: 2.0709 - val_accuracy: 0.2188\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9385 - accuracy: 0.2963 - val_loss: 2.0075 - val_accuracy: 0.2236\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9036 - accuracy: 0.3061 - val_loss: 1.9901 - val_accuracy: 0.2163\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8579 - accuracy: 0.3159 - val_loss: 2.0440 - val_accuracy: 0.2332\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8708 - accuracy: 0.3081 - val_loss: 1.9334 - val_accuracy: 0.2476\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8388 - accuracy: 0.3114 - val_loss: 2.0253 - val_accuracy: 0.2163\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8134 - accuracy: 0.3107 - val_loss: 1.9469 - val_accuracy: 0.2476\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8207 - accuracy: 0.3114 - val_loss: 1.9168 - val_accuracy: 0.2548\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8074 - accuracy: 0.3179 - val_loss: 1.8886 - val_accuracy: 0.2596\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7888 - accuracy: 0.3257 - val_loss: 1.9291 - val_accuracy: 0.2428\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7724 - accuracy: 0.3264 - val_loss: 1.9763 - val_accuracy: 0.2380\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7694 - accuracy: 0.3120 - val_loss: 1.8359 - val_accuracy: 0.2788\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.7568 - accuracy: 0.3211 - val_loss: 1.9008 - val_accuracy: 0.2620\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7579 - accuracy: 0.3140 - val_loss: 1.8553 - val_accuracy: 0.2572\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7557 - accuracy: 0.3225 - val_loss: 1.8490 - val_accuracy: 0.2909\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8359 - accuracy: 0.2788\n",
      "Fold 5 - Validation Loss: 1.8359, Validation Accuracy: 0.2788\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 52ms/step - loss: 3.1171 - accuracy: 0.1809 - val_loss: 2.8702 - val_accuracy: 0.2434\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.7149 - accuracy: 0.2357 - val_loss: 2.5209 - val_accuracy: 0.2487\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.4421 - accuracy: 0.2478 - val_loss: 2.3133 - val_accuracy: 0.2646\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.2762 - accuracy: 0.2586 - val_loss: 2.1806 - val_accuracy: 0.2487\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.1546 - accuracy: 0.2561 - val_loss: 2.0640 - val_accuracy: 0.2937\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0581 - accuracy: 0.2694 - val_loss: 1.9936 - val_accuracy: 0.2619\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.0082 - accuracy: 0.2682 - val_loss: 1.9806 - val_accuracy: 0.2460\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.9801 - accuracy: 0.2669 - val_loss: 1.9371 - val_accuracy: 0.2566\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.9205 - accuracy: 0.2904 - val_loss: 1.8595 - val_accuracy: 0.3175\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8893 - accuracy: 0.2866 - val_loss: 1.8568 - val_accuracy: 0.3069\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.8809 - accuracy: 0.2834 - val_loss: 1.8637 - val_accuracy: 0.2751\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1.8671 - accuracy: 0.2924 - val_loss: 1.8350 - val_accuracy: 0.2910\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8364 - accuracy: 0.2911 - val_loss: 1.8289 - val_accuracy: 0.3016\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8259 - accuracy: 0.3127 - val_loss: 1.7922 - val_accuracy: 0.3042\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8158 - accuracy: 0.2994 - val_loss: 1.8660 - val_accuracy: 0.2857\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8226 - accuracy: 0.3140 - val_loss: 1.8043 - val_accuracy: 0.3016\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8437 - accuracy: 0.2943 - val_loss: 1.8078 - val_accuracy: 0.3095\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7922 - accuracy: 0.3042\n",
      "Fold 1 - Validation Loss: 1.7922, Validation Accuracy: 0.3042\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 4s 49ms/step - loss: 3.1368 - accuracy: 0.1644 - val_loss: 2.8704 - val_accuracy: 0.2453\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.7383 - accuracy: 0.2123 - val_loss: 2.4901 - val_accuracy: 0.2956\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.4329 - accuracy: 0.2589 - val_loss: 2.2421 - val_accuracy: 0.3113\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.2795 - accuracy: 0.2423 - val_loss: 2.1950 - val_accuracy: 0.2673\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.1548 - accuracy: 0.2571 - val_loss: 2.0140 - val_accuracy: 0.3050\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0675 - accuracy: 0.2589 - val_loss: 1.9531 - val_accuracy: 0.3050\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0151 - accuracy: 0.2626 - val_loss: 1.8826 - val_accuracy: 0.3365\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.9601 - accuracy: 0.2810 - val_loss: 1.8463 - val_accuracy: 0.2987\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.9534 - accuracy: 0.2736 - val_loss: 1.8287 - val_accuracy: 0.3082\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.9146 - accuracy: 0.2828 - val_loss: 1.8628 - val_accuracy: 0.2862\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.9026 - accuracy: 0.2669 - val_loss: 1.8060 - val_accuracy: 0.2893\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8729 - accuracy: 0.2828 - val_loss: 1.7816 - val_accuracy: 0.3082\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.8650 - accuracy: 0.2902 - val_loss: 1.8232 - val_accuracy: 0.2893\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8606 - accuracy: 0.2988 - val_loss: 1.7906 - val_accuracy: 0.3082\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8459 - accuracy: 0.3006 - val_loss: 1.8141 - val_accuracy: 0.2893\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7816 - accuracy: 0.3082\n",
      "Fold 2 - Validation Loss: 1.7816, Validation Accuracy: 0.3082\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 52ms/step - loss: 3.1072 - accuracy: 0.2022 - val_loss: 2.8802 - val_accuracy: 0.2214\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.6925 - accuracy: 0.2592 - val_loss: 2.5816 - val_accuracy: 0.2476\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.4411 - accuracy: 0.2651 - val_loss: 2.4302 - val_accuracy: 0.2476\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.2857 - accuracy: 0.2709 - val_loss: 2.2667 - val_accuracy: 0.2452\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.1532 - accuracy: 0.2631 - val_loss: 2.1389 - val_accuracy: 0.2429\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0573 - accuracy: 0.2762 - val_loss: 2.1207 - val_accuracy: 0.2452\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0227 - accuracy: 0.2729 - val_loss: 2.0117 - val_accuracy: 0.2952\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.9478 - accuracy: 0.2938 - val_loss: 1.9942 - val_accuracy: 0.2738\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9172 - accuracy: 0.2938 - val_loss: 2.0395 - val_accuracy: 0.2762\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.9155 - accuracy: 0.2853 - val_loss: 1.9485 - val_accuracy: 0.2929\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8820 - accuracy: 0.2912 - val_loss: 1.9243 - val_accuracy: 0.2762\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8849 - accuracy: 0.2866 - val_loss: 1.8896 - val_accuracy: 0.2619\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8708 - accuracy: 0.2814 - val_loss: 1.8935 - val_accuracy: 0.2619\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8356 - accuracy: 0.3056 - val_loss: 1.9148 - val_accuracy: 0.2786\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8400 - accuracy: 0.2886 - val_loss: 1.8959 - val_accuracy: 0.2667\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.8896 - accuracy: 0.2619\n",
      "Fold 3 - Validation Loss: 1.8896, Validation Accuracy: 0.2619\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 57ms/step - loss: 3.1138 - accuracy: 0.1854 - val_loss: 2.8900 - val_accuracy: 0.2043\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.7433 - accuracy: 0.2082 - val_loss: 2.5680 - val_accuracy: 0.2644\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.4654 - accuracy: 0.2559 - val_loss: 2.3113 - val_accuracy: 0.2885\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.2963 - accuracy: 0.2493 - val_loss: 2.2333 - val_accuracy: 0.2428\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1571 - accuracy: 0.2493 - val_loss: 2.1176 - val_accuracy: 0.2572\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0660 - accuracy: 0.2644 - val_loss: 1.9999 - val_accuracy: 0.2812\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.0137 - accuracy: 0.2735 - val_loss: 2.0002 - val_accuracy: 0.2837\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.9682 - accuracy: 0.2761 - val_loss: 1.9746 - val_accuracy: 0.2740\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9373 - accuracy: 0.2872 - val_loss: 1.9218 - val_accuracy: 0.2909\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8985 - accuracy: 0.2813 - val_loss: 1.9026 - val_accuracy: 0.2788\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9086 - accuracy: 0.2787 - val_loss: 1.8764 - val_accuracy: 0.2933\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.8794 - accuracy: 0.2970 - val_loss: 1.8768 - val_accuracy: 0.2957\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8698 - accuracy: 0.2879 - val_loss: 1.8563 - val_accuracy: 0.2981\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8759 - accuracy: 0.2794 - val_loss: 1.8402 - val_accuracy: 0.2933\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8575 - accuracy: 0.2898 - val_loss: 1.8243 - val_accuracy: 0.3101\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8585 - accuracy: 0.2852 - val_loss: 1.8355 - val_accuracy: 0.3077\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8477 - accuracy: 0.2931 - val_loss: 1.8643 - val_accuracy: 0.3245\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8428 - accuracy: 0.2977 - val_loss: 1.8448 - val_accuracy: 0.3221\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8243 - accuracy: 0.3101\n",
      "Fold 4 - Validation Loss: 1.8243, Validation Accuracy: 0.3101\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 51ms/step - loss: 3.1419 - accuracy: 0.1762 - val_loss: 2.9075 - val_accuracy: 0.2332\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.7368 - accuracy: 0.2337 - val_loss: 2.6158 - val_accuracy: 0.2212\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.4749 - accuracy: 0.2696 - val_loss: 2.4831 - val_accuracy: 0.2067\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.3130 - accuracy: 0.2507 - val_loss: 2.2408 - val_accuracy: 0.2356\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.1595 - accuracy: 0.2748 - val_loss: 2.1324 - val_accuracy: 0.2524\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0850 - accuracy: 0.2663 - val_loss: 2.1210 - val_accuracy: 0.2019\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0356 - accuracy: 0.2657 - val_loss: 2.0448 - val_accuracy: 0.2404\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.9683 - accuracy: 0.2885 - val_loss: 2.0578 - val_accuracy: 0.2212\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9130 - accuracy: 0.3003 - val_loss: 2.0313 - val_accuracy: 0.2308\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8800 - accuracy: 0.3003 - val_loss: 1.9940 - val_accuracy: 0.2404\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8656 - accuracy: 0.2918 - val_loss: 2.0523 - val_accuracy: 0.2236\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8535 - accuracy: 0.2990 - val_loss: 1.9594 - val_accuracy: 0.2284\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8437 - accuracy: 0.3061 - val_loss: 1.9159 - val_accuracy: 0.2620\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8258 - accuracy: 0.3087 - val_loss: 1.9088 - val_accuracy: 0.2380\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8241 - accuracy: 0.3042 - val_loss: 1.9690 - val_accuracy: 0.2115\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8201 - accuracy: 0.3120 - val_loss: 1.9137 - val_accuracy: 0.2260\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8093 - accuracy: 0.3153 - val_loss: 1.8577 - val_accuracy: 0.2668\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7824 - accuracy: 0.3198 - val_loss: 1.8897 - val_accuracy: 0.2500\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.7940 - accuracy: 0.3127 - val_loss: 1.8662 - val_accuracy: 0.2500\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.7875 - accuracy: 0.3114 - val_loss: 1.8550 - val_accuracy: 0.2740\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.7786 - accuracy: 0.3185 - val_loss: 1.8893 - val_accuracy: 0.2692\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.7627 - accuracy: 0.3205 - val_loss: 1.9540 - val_accuracy: 0.2452\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.7962 - accuracy: 0.3074 - val_loss: 1.9873 - val_accuracy: 0.2188\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8550 - accuracy: 0.2740\n",
      "Fold 5 - Validation Loss: 1.8550, Validation Accuracy: 0.2740\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 50ms/step - loss: 3.1877 - accuracy: 0.1408 - val_loss: 2.9658 - val_accuracy: 0.2116\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 2.8408 - accuracy: 0.1803 - val_loss: 2.6820 - val_accuracy: 0.2646\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.5861 - accuracy: 0.2121 - val_loss: 2.4376 - val_accuracy: 0.2619\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.3982 - accuracy: 0.2325 - val_loss: 2.2479 - val_accuracy: 0.2672\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.2561 - accuracy: 0.2433 - val_loss: 2.1842 - val_accuracy: 0.2222\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.1612 - accuracy: 0.2446 - val_loss: 2.0591 - val_accuracy: 0.2698\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0900 - accuracy: 0.2599 - val_loss: 2.0266 - val_accuracy: 0.2434\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0240 - accuracy: 0.2643 - val_loss: 1.9444 - val_accuracy: 0.2910\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.9990 - accuracy: 0.2669 - val_loss: 1.9241 - val_accuracy: 0.2778\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.9780 - accuracy: 0.2669 - val_loss: 1.9008 - val_accuracy: 0.2857\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.9423 - accuracy: 0.2682 - val_loss: 1.8626 - val_accuracy: 0.2884\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.9425 - accuracy: 0.2713 - val_loss: 1.8648 - val_accuracy: 0.2937\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.9129 - accuracy: 0.2643 - val_loss: 1.8595 - val_accuracy: 0.2989\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.9158 - accuracy: 0.2675 - val_loss: 1.8425 - val_accuracy: 0.3148\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.9085 - accuracy: 0.2688 - val_loss: 1.8393 - val_accuracy: 0.2937\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.8915 - accuracy: 0.2790 - val_loss: 1.8473 - val_accuracy: 0.2884\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8568 - accuracy: 0.2841 - val_loss: 1.7984 - val_accuracy: 0.2937\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 1.8630 - accuracy: 0.2783 - val_loss: 1.8103 - val_accuracy: 0.3016\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 1.8320 - accuracy: 0.3025 - val_loss: 1.8007 - val_accuracy: 0.2937\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 1.8967 - accuracy: 0.2694 - val_loss: 1.8325 - val_accuracy: 0.3122\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7984 - accuracy: 0.2937\n",
      "Fold 1 - Validation Loss: 1.7984, Validation Accuracy: 0.2937\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 5s 53ms/step - loss: 3.1708 - accuracy: 0.1540 - val_loss: 2.9371 - val_accuracy: 0.1887\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.8306 - accuracy: 0.1558 - val_loss: 2.6586 - val_accuracy: 0.2170\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.5832 - accuracy: 0.1699 - val_loss: 2.4518 - val_accuracy: 0.2673\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.3969 - accuracy: 0.1877 - val_loss: 2.2829 - val_accuracy: 0.2390\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.2585 - accuracy: 0.2196 - val_loss: 2.1176 - val_accuracy: 0.2925\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.1525 - accuracy: 0.2301 - val_loss: 2.0390 - val_accuracy: 0.2830\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0929 - accuracy: 0.2350 - val_loss: 1.9498 - val_accuracy: 0.3019\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.0512 - accuracy: 0.2466 - val_loss: 1.9364 - val_accuracy: 0.2987\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.0004 - accuracy: 0.2571 - val_loss: 1.8851 - val_accuracy: 0.2862\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 1.9743 - accuracy: 0.2448 - val_loss: 1.8407 - val_accuracy: 0.3208\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.9493 - accuracy: 0.2681 - val_loss: 1.8126 - val_accuracy: 0.3270\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.9451 - accuracy: 0.2589 - val_loss: 1.8045 - val_accuracy: 0.3176\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.9179 - accuracy: 0.2687 - val_loss: 1.8043 - val_accuracy: 0.3145\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.9061 - accuracy: 0.2595 - val_loss: 1.7894 - val_accuracy: 0.3050\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.9076 - accuracy: 0.2607 - val_loss: 1.7889 - val_accuracy: 0.3396\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8996 - accuracy: 0.2607 - val_loss: 1.7818 - val_accuracy: 0.3050\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.9032 - accuracy: 0.2724 - val_loss: 1.7842 - val_accuracy: 0.3302\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8779 - accuracy: 0.2656 - val_loss: 1.7759 - val_accuracy: 0.3208\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8694 - accuracy: 0.2896 - val_loss: 1.7663 - val_accuracy: 0.3302\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8786 - accuracy: 0.2675 - val_loss: 1.7637 - val_accuracy: 0.2830\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8600 - accuracy: 0.2828 - val_loss: 1.7725 - val_accuracy: 0.3365\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8583 - accuracy: 0.2871 - val_loss: 1.7995 - val_accuracy: 0.2987\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 1.8460 - accuracy: 0.2890 - val_loss: 1.7515 - val_accuracy: 0.3270\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.8694 - accuracy: 0.2969 - val_loss: 1.7653 - val_accuracy: 0.3239\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.8671 - accuracy: 0.2785 - val_loss: 1.7423 - val_accuracy: 0.3145\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.7423 - accuracy: 0.3145\n",
      "Fold 2 - Validation Loss: 1.7423, Validation Accuracy: 0.3145\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 53ms/step - loss: 3.1966 - accuracy: 0.1486 - val_loss: 2.9797 - val_accuracy: 0.2000\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.8408 - accuracy: 0.2107 - val_loss: 2.6966 - val_accuracy: 0.2214\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.5999 - accuracy: 0.2349 - val_loss: 2.4748 - val_accuracy: 0.2333\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.4066 - accuracy: 0.2369 - val_loss: 2.3250 - val_accuracy: 0.2333\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.2682 - accuracy: 0.2421 - val_loss: 2.2252 - val_accuracy: 0.2381\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.1636 - accuracy: 0.2480 - val_loss: 2.1633 - val_accuracy: 0.2476\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.1012 - accuracy: 0.2618 - val_loss: 2.0961 - val_accuracy: 0.2262\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0665 - accuracy: 0.2349 - val_loss: 2.0454 - val_accuracy: 0.2476\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0174 - accuracy: 0.2336 - val_loss: 2.0453 - val_accuracy: 0.2548\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9814 - accuracy: 0.2690 - val_loss: 2.0221 - val_accuracy: 0.2524\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9457 - accuracy: 0.2716 - val_loss: 1.9833 - val_accuracy: 0.2738\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9356 - accuracy: 0.2605 - val_loss: 1.9497 - val_accuracy: 0.2595\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9202 - accuracy: 0.2808 - val_loss: 1.9246 - val_accuracy: 0.2786\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9129 - accuracy: 0.2618 - val_loss: 1.9618 - val_accuracy: 0.2619\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9128 - accuracy: 0.2801 - val_loss: 1.9275 - val_accuracy: 0.2500\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8879 - accuracy: 0.2749 - val_loss: 1.9367 - val_accuracy: 0.2738\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.9246 - accuracy: 0.2786\n",
      "Fold 3 - Validation Loss: 1.9246, Validation Accuracy: 0.2786\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 52ms/step - loss: 3.2115 - accuracy: 0.1482 - val_loss: 3.0103 - val_accuracy: 0.2043\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.8973 - accuracy: 0.1625 - val_loss: 2.7397 - val_accuracy: 0.2380\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.6453 - accuracy: 0.1919 - val_loss: 2.5056 - val_accuracy: 0.2644\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.4414 - accuracy: 0.2298 - val_loss: 2.3048 - val_accuracy: 0.2764\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.2863 - accuracy: 0.2474 - val_loss: 2.1991 - val_accuracy: 0.2788\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.1924 - accuracy: 0.2454 - val_loss: 2.1062 - val_accuracy: 0.2837\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1299 - accuracy: 0.2480 - val_loss: 2.0569 - val_accuracy: 0.2620\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0804 - accuracy: 0.2454 - val_loss: 1.9956 - val_accuracy: 0.2861\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0164 - accuracy: 0.2742 - val_loss: 1.9601 - val_accuracy: 0.2812\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9662 - accuracy: 0.2755 - val_loss: 1.9406 - val_accuracy: 0.2764\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9622 - accuracy: 0.2591 - val_loss: 1.9179 - val_accuracy: 0.2861\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9467 - accuracy: 0.2650 - val_loss: 1.9005 - val_accuracy: 0.3149\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9083 - accuracy: 0.2774 - val_loss: 1.8824 - val_accuracy: 0.2957\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9055 - accuracy: 0.2813 - val_loss: 1.8601 - val_accuracy: 0.3029\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9095 - accuracy: 0.2604 - val_loss: 1.8435 - val_accuracy: 0.3101\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9076 - accuracy: 0.2755 - val_loss: 1.8542 - val_accuracy: 0.2957\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8873 - accuracy: 0.2748 - val_loss: 1.9099 - val_accuracy: 0.2861\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.8719 - accuracy: 0.2781 - val_loss: 1.8521 - val_accuracy: 0.2957\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8435 - accuracy: 0.3101\n",
      "Fold 4 - Validation Loss: 1.8435, Validation Accuracy: 0.3101\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 53ms/step - loss: 3.2010 - accuracy: 0.1345 - val_loss: 2.9880 - val_accuracy: 0.1827\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.8721 - accuracy: 0.1586 - val_loss: 2.7179 - val_accuracy: 0.2212\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.6239 - accuracy: 0.2069 - val_loss: 2.4974 - val_accuracy: 0.2308\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.4230 - accuracy: 0.2356 - val_loss: 2.3306 - val_accuracy: 0.2139\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.2709 - accuracy: 0.2448 - val_loss: 2.2187 - val_accuracy: 0.2212\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1937 - accuracy: 0.2474 - val_loss: 2.1569 - val_accuracy: 0.2308\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0974 - accuracy: 0.2552 - val_loss: 2.1119 - val_accuracy: 0.2332\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0552 - accuracy: 0.2637 - val_loss: 2.0966 - val_accuracy: 0.2236\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0140 - accuracy: 0.2611 - val_loss: 2.0084 - val_accuracy: 0.2596\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9656 - accuracy: 0.2670 - val_loss: 2.0506 - val_accuracy: 0.2212\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.9379 - accuracy: 0.2879 - val_loss: 2.0106 - val_accuracy: 0.2188\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9279 - accuracy: 0.2787 - val_loss: 1.9915 - val_accuracy: 0.2284\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9150 - accuracy: 0.2839 - val_loss: 1.9660 - val_accuracy: 0.2380\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9135 - accuracy: 0.2820 - val_loss: 1.9234 - val_accuracy: 0.2620\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8957 - accuracy: 0.2742 - val_loss: 1.9417 - val_accuracy: 0.2572\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 1.8730 - accuracy: 0.2892 - val_loss: 1.9773 - val_accuracy: 0.2188\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8893 - accuracy: 0.2898 - val_loss: 1.9555 - val_accuracy: 0.2837\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.9234 - accuracy: 0.2620\n",
      "Fold 5 - Validation Loss: 1.9234, Validation Accuracy: 0.2620\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 51ms/step - loss: 6.8481 - accuracy: 0.1554 - val_loss: 4.9809 - val_accuracy: 0.1481\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 3.4922 - accuracy: 0.1420 - val_loss: 3.2267 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.7728 - accuracy: 0.1605 - val_loss: 2.4676 - val_accuracy: 0.1640\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.2455 - accuracy: 0.1446 - val_loss: 2.1780 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.1253 - accuracy: 0.1580 - val_loss: 2.0961 - val_accuracy: 0.1640\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0551 - accuracy: 0.1420 - val_loss: 2.0430 - val_accuracy: 0.1481\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0381 - accuracy: 0.1420 - val_loss: 2.0417 - val_accuracy: 0.1640\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0378 - accuracy: 0.1408 - val_loss: 2.0409 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0375 - accuracy: 0.1535 - val_loss: 2.0418 - val_accuracy: 0.1481\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0389 - accuracy: 0.1312 - val_loss: 2.0421 - val_accuracy: 0.1481\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0396 - accuracy: 0.1401 - val_loss: 2.0477 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0409 - accuracy: 0.1481\n",
      "Fold 1 - Validation Loss: 2.0409, Validation Accuracy: 0.1481\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 4s 51ms/step - loss: 6.4179 - accuracy: 0.1528 - val_loss: 4.3311 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.0786 - accuracy: 0.1509 - val_loss: 2.3902 - val_accuracy: 0.1604\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.2152 - accuracy: 0.1644 - val_loss: 2.1432 - val_accuracy: 0.1509\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0920 - accuracy: 0.1626 - val_loss: 2.0628 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.0521 - accuracy: 0.1534 - val_loss: 2.0304 - val_accuracy: 0.1572\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 2.0449 - accuracy: 0.1356 - val_loss: 2.0328 - val_accuracy: 0.1509\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 2.0416 - accuracy: 0.1448 - val_loss: 2.0309 - val_accuracy: 0.1509\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 2.0424 - accuracy: 0.1521 - val_loss: 2.0352 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.0304 - accuracy: 0.1572\n",
      "Fold 2 - Validation Loss: 2.0304, Validation Accuracy: 0.1572\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 53ms/step - loss: 5.8909 - accuracy: 0.1545 - val_loss: 4.1852 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.9396 - accuracy: 0.1590 - val_loss: 2.2679 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.1583 - accuracy: 0.1564 - val_loss: 2.0806 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0565 - accuracy: 0.1322 - val_loss: 2.0421 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0412 - accuracy: 0.1453 - val_loss: 2.0382 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0416 - accuracy: 0.1499 - val_loss: 2.0389 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0411 - accuracy: 0.1407 - val_loss: 2.0373 - val_accuracy: 0.1524\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.0400 - accuracy: 0.1545 - val_loss: 2.0389 - val_accuracy: 0.1524\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 2.0409 - accuracy: 0.1518 - val_loss: 2.0403 - val_accuracy: 0.1524\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.0442 - accuracy: 0.1505 - val_loss: 2.0426 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.0373 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0373, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 53ms/step - loss: 5.6341 - accuracy: 0.1482 - val_loss: 3.8411 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.9405 - accuracy: 0.1521 - val_loss: 2.4516 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.3221 - accuracy: 0.1625 - val_loss: 2.1553 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1141 - accuracy: 0.1423 - val_loss: 2.0647 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0498 - accuracy: 0.1488 - val_loss: 2.0346 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0416 - accuracy: 0.1534 - val_loss: 2.0342 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0423 - accuracy: 0.1430 - val_loss: 2.0340 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.0408 - accuracy: 0.1253 - val_loss: 2.0335 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0436 - accuracy: 0.1495 - val_loss: 2.0370 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0411 - accuracy: 0.1469 - val_loss: 2.0341 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0388 - accuracy: 0.1488 - val_loss: 2.0340 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0335 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0335, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 5s 58ms/step - loss: 5.8075 - accuracy: 0.1638 - val_loss: 3.9457 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 3.4924 - accuracy: 0.1521 - val_loss: 3.2111 - val_accuracy: 0.1611\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.0582 - accuracy: 0.1638 - val_loss: 2.6823 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.3505 - accuracy: 0.1449 - val_loss: 2.1279 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.0854 - accuracy: 0.1462 - val_loss: 2.0429 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0445 - accuracy: 0.1462 - val_loss: 2.0338 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.0416 - accuracy: 0.1443 - val_loss: 2.0331 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0400 - accuracy: 0.1416 - val_loss: 2.0335 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0405 - accuracy: 0.1456 - val_loss: 2.0349 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0395 - accuracy: 0.1436 - val_loss: 2.0335 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 2.0331 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0331, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 54ms/step - loss: 8.2144 - accuracy: 0.1561 - val_loss: 5.7155 - val_accuracy: 0.1640\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 3.5705 - accuracy: 0.1420 - val_loss: 2.8117 - val_accuracy: 0.1640\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.9170 - accuracy: 0.1363 - val_loss: 2.5730 - val_accuracy: 0.1481\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.3928 - accuracy: 0.1471 - val_loss: 2.1962 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.1080 - accuracy: 0.1414 - val_loss: 2.0631 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0655 - accuracy: 0.1516 - val_loss: 2.0724 - val_accuracy: 0.1640\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0774 - accuracy: 0.1497 - val_loss: 2.0592 - val_accuracy: 0.1640\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0440 - accuracy: 0.1439 - val_loss: 2.0510 - val_accuracy: 0.1640\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0468 - accuracy: 0.1465 - val_loss: 2.0426 - val_accuracy: 0.1481\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0391 - accuracy: 0.1338 - val_loss: 2.0420 - val_accuracy: 0.1481\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0394 - accuracy: 0.1478 - val_loss: 2.0470 - val_accuracy: 0.1481\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0403 - accuracy: 0.1503 - val_loss: 2.0451 - val_accuracy: 0.1481\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0433 - accuracy: 0.1446 - val_loss: 2.0397 - val_accuracy: 0.1640\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0371 - accuracy: 0.1516 - val_loss: 2.0417 - val_accuracy: 0.1481\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0384 - accuracy: 0.1459 - val_loss: 2.0418 - val_accuracy: 0.1481\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0388 - accuracy: 0.1631 - val_loss: 2.0428 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0397 - accuracy: 0.1640\n",
      "Fold 1 - Validation Loss: 2.0397, Validation Accuracy: 0.1640\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 4s 49ms/step - loss: 6.5603 - accuracy: 0.1411 - val_loss: 4.2039 - val_accuracy: 0.1195\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.8551 - accuracy: 0.1454 - val_loss: 2.2897 - val_accuracy: 0.1509\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.2265 - accuracy: 0.1460 - val_loss: 2.1369 - val_accuracy: 0.1509\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.1028 - accuracy: 0.1479 - val_loss: 2.0593 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0480 - accuracy: 0.1479 - val_loss: 2.0306 - val_accuracy: 0.1509\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.0417 - accuracy: 0.1356 - val_loss: 2.0331 - val_accuracy: 0.1509\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0417 - accuracy: 0.1448 - val_loss: 2.0309 - val_accuracy: 0.1509\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0423 - accuracy: 0.1552 - val_loss: 2.0375 - val_accuracy: 0.1509\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.0306 - accuracy: 0.1509\n",
      "Fold 2 - Validation Loss: 2.0306, Validation Accuracy: 0.1509\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 57ms/step - loss: 6.8310 - accuracy: 0.1525 - val_loss: 4.7388 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 3.2258 - accuracy: 0.1525 - val_loss: 2.5128 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.3743 - accuracy: 0.1473 - val_loss: 2.1877 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.1632 - accuracy: 0.1381 - val_loss: 2.0992 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0633 - accuracy: 0.1329 - val_loss: 2.0418 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0411 - accuracy: 0.1538 - val_loss: 2.0413 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0409 - accuracy: 0.1473 - val_loss: 2.0378 - val_accuracy: 0.1524\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0407 - accuracy: 0.1486 - val_loss: 2.0388 - val_accuracy: 0.1524\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0418 - accuracy: 0.1466 - val_loss: 2.0398 - val_accuracy: 0.1524\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0448 - accuracy: 0.1577 - val_loss: 2.0425 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.0378 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0378, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 54ms/step - loss: 5.7536 - accuracy: 0.1593 - val_loss: 3.7867 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.0519 - accuracy: 0.1416 - val_loss: 2.7068 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.5388 - accuracy: 0.1554 - val_loss: 2.2830 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.2238 - accuracy: 0.1462 - val_loss: 2.1437 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0987 - accuracy: 0.1534 - val_loss: 2.0524 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0472 - accuracy: 0.1534 - val_loss: 2.0355 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0431 - accuracy: 0.1377 - val_loss: 2.0345 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0412 - accuracy: 0.1279 - val_loss: 2.0337 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0435 - accuracy: 0.1482 - val_loss: 2.0369 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0414 - accuracy: 0.1469 - val_loss: 2.0347 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0388 - accuracy: 0.1475 - val_loss: 2.0338 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0337 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0337, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 5s 57ms/step - loss: 6.9103 - accuracy: 0.1554 - val_loss: 5.1099 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 3.3892 - accuracy: 0.1456 - val_loss: 2.6373 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.3773 - accuracy: 0.1580 - val_loss: 2.2101 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.1592 - accuracy: 0.1423 - val_loss: 2.1288 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1172 - accuracy: 0.1449 - val_loss: 2.0606 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0543 - accuracy: 0.1456 - val_loss: 2.0376 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0436 - accuracy: 0.1430 - val_loss: 2.0339 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.0404 - accuracy: 0.1495 - val_loss: 2.0338 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.0410 - accuracy: 0.1443 - val_loss: 2.0359 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 2.0399 - accuracy: 0.1482 - val_loss: 2.0341 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 2.0397 - accuracy: 0.1482 - val_loss: 2.0355 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0338 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0338, Validation Accuracy: 0.1538\n",
      "(1948, 8)\n",
      "Training fold 1 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1570, 4, 88)\n",
      "(1570, 8)\n",
      "(378, 4, 88)\n",
      "(378, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "25/25 [==============================] - 4s 52ms/step - loss: 7.2760 - accuracy: 0.1376 - val_loss: 5.0514 - val_accuracy: 0.1481\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 3.6748 - accuracy: 0.1510 - val_loss: 2.9509 - val_accuracy: 0.1481\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.8596 - accuracy: 0.1510 - val_loss: 2.6273 - val_accuracy: 0.1455\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 2.5326 - accuracy: 0.1433 - val_loss: 2.3224 - val_accuracy: 0.1481\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.2654 - accuracy: 0.1427 - val_loss: 2.2029 - val_accuracy: 0.1481\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.1384 - accuracy: 0.1580 - val_loss: 2.0886 - val_accuracy: 0.1640\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0603 - accuracy: 0.1395 - val_loss: 2.0583 - val_accuracy: 0.1640\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0539 - accuracy: 0.1414 - val_loss: 2.0448 - val_accuracy: 0.1481\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0381 - accuracy: 0.1420 - val_loss: 2.0424 - val_accuracy: 0.1481\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0392 - accuracy: 0.1306 - val_loss: 2.0421 - val_accuracy: 0.1481\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0394 - accuracy: 0.1465 - val_loss: 2.0468 - val_accuracy: 0.1481\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0402 - accuracy: 0.1503 - val_loss: 2.0461 - val_accuracy: 0.1481\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0438 - accuracy: 0.1478 - val_loss: 2.0397 - val_accuracy: 0.1640\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0372 - accuracy: 0.1516 - val_loss: 2.0417 - val_accuracy: 0.1481\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0386 - accuracy: 0.1459 - val_loss: 2.0421 - val_accuracy: 0.1481\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0388 - accuracy: 0.1624 - val_loss: 2.0431 - val_accuracy: 0.1481\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.0397 - accuracy: 0.1640\n",
      "Fold 1 - Validation Loss: 2.0397, Validation Accuracy: 0.1640\n",
      "Training fold 2 ...\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1630, 4, 88)\n",
      "(1630, 8)\n",
      "(318, 4, 88)\n",
      "(318, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "26/26 [==============================] - 4s 49ms/step - loss: 6.9273 - accuracy: 0.1509 - val_loss: 3.9247 - val_accuracy: 0.1509\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 3.1916 - accuracy: 0.1644 - val_loss: 2.7974 - val_accuracy: 0.1509\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.5101 - accuracy: 0.1344 - val_loss: 2.2500 - val_accuracy: 0.1509\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 2.1685 - accuracy: 0.1589 - val_loss: 2.0901 - val_accuracy: 0.1509\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0780 - accuracy: 0.1528 - val_loss: 2.0369 - val_accuracy: 0.1509\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.0449 - accuracy: 0.1374 - val_loss: 2.0363 - val_accuracy: 0.1509\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0429 - accuracy: 0.1466 - val_loss: 2.0314 - val_accuracy: 0.1509\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 2.0426 - accuracy: 0.1521 - val_loss: 2.0356 - val_accuracy: 0.1509\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0455 - accuracy: 0.1491 - val_loss: 2.0288 - val_accuracy: 0.1698\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0422 - accuracy: 0.1509 - val_loss: 2.0347 - val_accuracy: 0.1509\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0402 - accuracy: 0.1528 - val_loss: 2.0308 - val_accuracy: 0.1509\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 2.0446 - accuracy: 0.1454 - val_loss: 2.0291 - val_accuracy: 0.1698\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.0288 - accuracy: 0.1698\n",
      "Fold 2 - Validation Loss: 2.0288, Validation Accuracy: 0.1698\n",
      "Training fold 3 ...\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "(1528, 4, 88)\n",
      "(1528, 8)\n",
      "(420, 4, 88)\n",
      "(420, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 56ms/step - loss: 6.2142 - accuracy: 0.1459 - val_loss: 4.0267 - val_accuracy: 0.1524\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.0861 - accuracy: 0.1558 - val_loss: 2.5968 - val_accuracy: 0.1524\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.3358 - accuracy: 0.1564 - val_loss: 2.1159 - val_accuracy: 0.1524\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0980 - accuracy: 0.1453 - val_loss: 2.1058 - val_accuracy: 0.1524\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0741 - accuracy: 0.1381 - val_loss: 2.0431 - val_accuracy: 0.1524\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0434 - accuracy: 0.1459 - val_loss: 2.0446 - val_accuracy: 0.1524\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0424 - accuracy: 0.1407 - val_loss: 2.0386 - val_accuracy: 0.1524\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0412 - accuracy: 0.1531 - val_loss: 2.0394 - val_accuracy: 0.1524\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0415 - accuracy: 0.1492 - val_loss: 2.0417 - val_accuracy: 0.1524\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0457 - accuracy: 0.1577 - val_loss: 2.0435 - val_accuracy: 0.1524\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.0386 - accuracy: 0.1524\n",
      "Fold 3 - Validation Loss: 2.0386, Validation Accuracy: 0.1524\n",
      "Training fold 4 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 4s 52ms/step - loss: 6.7399 - accuracy: 0.1547 - val_loss: 4.5535 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.4742 - accuracy: 0.1586 - val_loss: 2.8512 - val_accuracy: 0.1514\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.9534 - accuracy: 0.1534 - val_loss: 2.7499 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.6001 - accuracy: 0.1475 - val_loss: 2.2922 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.2685 - accuracy: 0.1560 - val_loss: 2.2087 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1489 - accuracy: 0.1540 - val_loss: 2.0563 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0703 - accuracy: 0.1416 - val_loss: 2.0752 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0610 - accuracy: 0.1292 - val_loss: 2.0364 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0448 - accuracy: 0.1527 - val_loss: 2.0372 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0413 - accuracy: 0.1475 - val_loss: 2.0344 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0388 - accuracy: 0.1475 - val_loss: 2.0342 - val_accuracy: 0.1538\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0421 - accuracy: 0.1508 - val_loss: 2.0373 - val_accuracy: 0.1538\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0407 - accuracy: 0.1527 - val_loss: 2.0359 - val_accuracy: 0.1538\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.0406 - accuracy: 0.1586 - val_loss: 2.0366 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0342 - accuracy: 0.1538\n",
      "Fold 4 - Validation Loss: 2.0342, Validation Accuracy: 0.1538\n",
      "Training fold 5 ...\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(1532, 4, 88)\n",
      "(1532, 8)\n",
      "(416, 4, 88)\n",
      "(416, 8)\n",
      "cambio\n",
      "Epoch 1/25\n",
      "24/24 [==============================] - 5s 54ms/step - loss: 5.6926 - accuracy: 0.1651 - val_loss: 3.8307 - val_accuracy: 0.1538\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 3.2634 - accuracy: 0.1547 - val_loss: 2.9665 - val_accuracy: 0.1538\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.9955 - accuracy: 0.1599 - val_loss: 2.7900 - val_accuracy: 0.1538\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.4808 - accuracy: 0.1345 - val_loss: 2.2438 - val_accuracy: 0.1538\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1890 - accuracy: 0.1279 - val_loss: 2.0993 - val_accuracy: 0.1538\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.0727 - accuracy: 0.1449 - val_loss: 2.0469 - val_accuracy: 0.1538\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0464 - accuracy: 0.1475 - val_loss: 2.0344 - val_accuracy: 0.1538\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.0412 - accuracy: 0.1495 - val_loss: 2.0337 - val_accuracy: 0.1538\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.0411 - accuracy: 0.1475 - val_loss: 2.0369 - val_accuracy: 0.1538\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.0402 - accuracy: 0.1488 - val_loss: 2.0339 - val_accuracy: 0.1538\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0399 - accuracy: 0.1501 - val_loss: 2.0357 - val_accuracy: 0.1538\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.0337 - accuracy: 0.1538\n",
      "Fold 5 - Validation Loss: 2.0337, Validation Accuracy: 0.1538\n"
     ]
    }
   ],
   "source": [
    "batches_size = [16, 32, 64]\n",
    "lrs = [0.0001, 0.001, 0.1]\n",
    "dropout = [0.2, 0.3, 0.5]\n",
    "\n",
    "hyperparams = list(itertools.product(batches_size, lrs, dropout))\n",
    "print(y_dev_ohe.shape)\n",
    "\n",
    "valid_loss = []\n",
    "for batch_s, lr, drop in hyperparams:\n",
    "    loss = cross_validate_rnn(X_dev, y_dev_ohe, actors_dev, batch_size=batch_s, learning_rate=lr, dropout=drop)\n",
    "    valid_loss.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt hyperparams:  (64, 0.001, 0.2)\n",
      "min val loss: 1.804750108718872\n"
     ]
    }
   ],
   "source": [
    "plt.plot(range(len(valid_loss)), valid_loss)\n",
    "plt.title(\"Loss para distintos hyperparams\")\n",
    "plt.show()\n",
    "\n",
    "print(\"opt hyperparams: \", hyperparams[np.argmin(valid_loss)])\n",
    "print(\"min val loss:\", np.min(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Epoch 1/500\n",
      "30/30 [==============================] - 4s 41ms/step - loss: 3.3581 - accuracy: 0.1360 - val_loss: 3.3425 - val_accuracy: 0.1803\n",
      "Epoch 2/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.3363 - accuracy: 0.1381 - val_loss: 3.3193 - val_accuracy: 0.1947\n",
      "Epoch 3/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 3.3123 - accuracy: 0.1744 - val_loss: 3.2962 - val_accuracy: 0.2284\n",
      "Epoch 4/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 3.2904 - accuracy: 0.1864 - val_loss: 3.2729 - val_accuracy: 0.2668\n",
      "Epoch 5/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 3.2655 - accuracy: 0.2164 - val_loss: 3.2489 - val_accuracy: 0.2981\n",
      "Epoch 6/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.2413 - accuracy: 0.2358 - val_loss: 3.2247 - val_accuracy: 0.3053\n",
      "Epoch 7/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.2171 - accuracy: 0.2579 - val_loss: 3.1996 - val_accuracy: 0.2933\n",
      "Epoch 8/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.1902 - accuracy: 0.2652 - val_loss: 3.1747 - val_accuracy: 0.3005\n",
      "Epoch 9/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.1673 - accuracy: 0.2721 - val_loss: 3.1492 - val_accuracy: 0.2981\n",
      "Epoch 10/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.1407 - accuracy: 0.2994 - val_loss: 3.1230 - val_accuracy: 0.3053\n",
      "Epoch 11/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.1147 - accuracy: 0.3188 - val_loss: 3.0974 - val_accuracy: 0.2957\n",
      "Epoch 12/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 3.0877 - accuracy: 0.3120 - val_loss: 3.0705 - val_accuracy: 0.2981\n",
      "Epoch 13/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.0634 - accuracy: 0.3088 - val_loss: 3.0438 - val_accuracy: 0.3005\n",
      "Epoch 14/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.0330 - accuracy: 0.3346 - val_loss: 3.0174 - val_accuracy: 0.3149\n",
      "Epoch 15/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.0096 - accuracy: 0.3235 - val_loss: 2.9908 - val_accuracy: 0.3125\n",
      "Epoch 16/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.9801 - accuracy: 0.3325 - val_loss: 2.9644 - val_accuracy: 0.3221\n",
      "Epoch 17/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.9539 - accuracy: 0.3319 - val_loss: 2.9379 - val_accuracy: 0.3149\n",
      "Epoch 18/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.9307 - accuracy: 0.3314 - val_loss: 2.9128 - val_accuracy: 0.3197\n",
      "Epoch 19/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 2.8984 - accuracy: 0.3388 - val_loss: 2.8871 - val_accuracy: 0.3365\n",
      "Epoch 20/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.8732 - accuracy: 0.3430 - val_loss: 2.8623 - val_accuracy: 0.3462\n",
      "Epoch 21/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.8488 - accuracy: 0.3566 - val_loss: 2.8380 - val_accuracy: 0.3438\n",
      "Epoch 22/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.8221 - accuracy: 0.3529 - val_loss: 2.8143 - val_accuracy: 0.3389\n",
      "Epoch 23/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.7954 - accuracy: 0.3624 - val_loss: 2.7911 - val_accuracy: 0.3341\n",
      "Epoch 24/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.7706 - accuracy: 0.3592 - val_loss: 2.7684 - val_accuracy: 0.3389\n",
      "Epoch 25/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.7468 - accuracy: 0.3761 - val_loss: 2.7465 - val_accuracy: 0.3486\n",
      "Epoch 26/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.7200 - accuracy: 0.3745 - val_loss: 2.7249 - val_accuracy: 0.3486\n",
      "Epoch 27/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 2.6955 - accuracy: 0.3603 - val_loss: 2.7043 - val_accuracy: 0.3558\n",
      "Epoch 28/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.6691 - accuracy: 0.3771 - val_loss: 2.6838 - val_accuracy: 0.3726\n",
      "Epoch 29/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.6480 - accuracy: 0.3813 - val_loss: 2.6641 - val_accuracy: 0.3678\n",
      "Epoch 30/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.6229 - accuracy: 0.3834 - val_loss: 2.6449 - val_accuracy: 0.3702\n",
      "Epoch 31/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.5938 - accuracy: 0.3944 - val_loss: 2.6262 - val_accuracy: 0.3774\n",
      "Epoch 32/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.5720 - accuracy: 0.3871 - val_loss: 2.6086 - val_accuracy: 0.3726\n",
      "Epoch 33/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.5545 - accuracy: 0.3839 - val_loss: 2.5903 - val_accuracy: 0.3870\n",
      "Epoch 34/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.5352 - accuracy: 0.3971 - val_loss: 2.5732 - val_accuracy: 0.3894\n",
      "Epoch 35/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.5113 - accuracy: 0.3955 - val_loss: 2.5573 - val_accuracy: 0.3822\n",
      "Epoch 36/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.4905 - accuracy: 0.3929 - val_loss: 2.5400 - val_accuracy: 0.3894\n",
      "Epoch 37/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.4695 - accuracy: 0.3939 - val_loss: 2.5236 - val_accuracy: 0.3918\n",
      "Epoch 38/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.4455 - accuracy: 0.4081 - val_loss: 2.5087 - val_accuracy: 0.3942\n",
      "Epoch 39/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.4325 - accuracy: 0.4049 - val_loss: 2.4925 - val_accuracy: 0.3966\n",
      "Epoch 40/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.4093 - accuracy: 0.4175 - val_loss: 2.4787 - val_accuracy: 0.3942\n",
      "Epoch 41/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.3924 - accuracy: 0.4133 - val_loss: 2.4644 - val_accuracy: 0.3822\n",
      "Epoch 42/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.3771 - accuracy: 0.4254 - val_loss: 2.4495 - val_accuracy: 0.3966\n",
      "Epoch 43/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.3547 - accuracy: 0.4170 - val_loss: 2.4356 - val_accuracy: 0.3870\n",
      "Epoch 44/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.3437 - accuracy: 0.4154 - val_loss: 2.4210 - val_accuracy: 0.3966\n",
      "Epoch 45/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.3198 - accuracy: 0.4202 - val_loss: 2.4053 - val_accuracy: 0.3966\n",
      "Epoch 46/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.3095 - accuracy: 0.4212 - val_loss: 2.3926 - val_accuracy: 0.3966\n",
      "Epoch 47/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.2972 - accuracy: 0.4191 - val_loss: 2.3793 - val_accuracy: 0.3918\n",
      "Epoch 48/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.2716 - accuracy: 0.4286 - val_loss: 2.3652 - val_accuracy: 0.3846\n",
      "Epoch 49/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.2614 - accuracy: 0.4286 - val_loss: 2.3533 - val_accuracy: 0.3846\n",
      "Epoch 50/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 2.2423 - accuracy: 0.4307 - val_loss: 2.3410 - val_accuracy: 0.3846\n",
      "Epoch 51/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 2.2247 - accuracy: 0.4407 - val_loss: 2.3283 - val_accuracy: 0.3894\n",
      "Epoch 52/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.2098 - accuracy: 0.4475 - val_loss: 2.3168 - val_accuracy: 0.3894\n",
      "Epoch 53/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.1959 - accuracy: 0.4433 - val_loss: 2.3042 - val_accuracy: 0.3942\n",
      "Epoch 54/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.1862 - accuracy: 0.4522 - val_loss: 2.2922 - val_accuracy: 0.3990\n",
      "Epoch 55/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.1700 - accuracy: 0.4475 - val_loss: 2.2804 - val_accuracy: 0.3966\n",
      "Epoch 56/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.1642 - accuracy: 0.4533 - val_loss: 2.2692 - val_accuracy: 0.3966\n",
      "Epoch 57/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.1435 - accuracy: 0.4575 - val_loss: 2.2573 - val_accuracy: 0.3966\n",
      "Epoch 58/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.1350 - accuracy: 0.4480 - val_loss: 2.2460 - val_accuracy: 0.3990\n",
      "Epoch 59/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.1189 - accuracy: 0.4512 - val_loss: 2.2349 - val_accuracy: 0.4014\n",
      "Epoch 60/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.1056 - accuracy: 0.4575 - val_loss: 2.2244 - val_accuracy: 0.4087\n",
      "Epoch 61/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 2.0959 - accuracy: 0.4480 - val_loss: 2.2141 - val_accuracy: 0.4087\n",
      "Epoch 62/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.0815 - accuracy: 0.4506 - val_loss: 2.2041 - val_accuracy: 0.4087\n",
      "Epoch 63/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.0711 - accuracy: 0.4580 - val_loss: 2.1923 - val_accuracy: 0.4062\n",
      "Epoch 64/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.0609 - accuracy: 0.4669 - val_loss: 2.1821 - val_accuracy: 0.4111\n",
      "Epoch 65/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 2.0442 - accuracy: 0.4695 - val_loss: 2.1697 - val_accuracy: 0.4207\n",
      "Epoch 66/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.0320 - accuracy: 0.4837 - val_loss: 2.1612 - val_accuracy: 0.4159\n",
      "Epoch 67/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.0204 - accuracy: 0.4580 - val_loss: 2.1507 - val_accuracy: 0.4159\n",
      "Epoch 68/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.0158 - accuracy: 0.4811 - val_loss: 2.1417 - val_accuracy: 0.4159\n",
      "Epoch 69/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.0011 - accuracy: 0.4648 - val_loss: 2.1308 - val_accuracy: 0.4183\n",
      "Epoch 70/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.9939 - accuracy: 0.4664 - val_loss: 2.1205 - val_accuracy: 0.4135\n",
      "Epoch 71/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.9750 - accuracy: 0.4806 - val_loss: 2.1112 - val_accuracy: 0.4183\n",
      "Epoch 72/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.9594 - accuracy: 0.4811 - val_loss: 2.1028 - val_accuracy: 0.4183\n",
      "Epoch 73/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.9633 - accuracy: 0.4837 - val_loss: 2.0942 - val_accuracy: 0.4159\n",
      "Epoch 74/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.9478 - accuracy: 0.4874 - val_loss: 2.0834 - val_accuracy: 0.4111\n",
      "Epoch 75/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.9401 - accuracy: 0.4911 - val_loss: 2.0761 - val_accuracy: 0.4111\n",
      "Epoch 76/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.9262 - accuracy: 0.4937 - val_loss: 2.0677 - val_accuracy: 0.4111\n",
      "Epoch 77/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.9269 - accuracy: 0.4895 - val_loss: 2.0579 - val_accuracy: 0.4087\n",
      "Epoch 78/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.9085 - accuracy: 0.5021 - val_loss: 2.0485 - val_accuracy: 0.4159\n",
      "Epoch 79/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8980 - accuracy: 0.5021 - val_loss: 2.0404 - val_accuracy: 0.4159\n",
      "Epoch 80/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8931 - accuracy: 0.4926 - val_loss: 2.0354 - val_accuracy: 0.4135\n",
      "Epoch 81/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8888 - accuracy: 0.4968 - val_loss: 2.0258 - val_accuracy: 0.4135\n",
      "Epoch 82/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8633 - accuracy: 0.5058 - val_loss: 2.0181 - val_accuracy: 0.4111\n",
      "Epoch 83/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8651 - accuracy: 0.5026 - val_loss: 2.0088 - val_accuracy: 0.4159\n",
      "Epoch 84/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8403 - accuracy: 0.5105 - val_loss: 1.9992 - val_accuracy: 0.4135\n",
      "Epoch 85/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.8326 - accuracy: 0.5032 - val_loss: 1.9904 - val_accuracy: 0.4159\n",
      "Epoch 86/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.8296 - accuracy: 0.5142 - val_loss: 1.9818 - val_accuracy: 0.4183\n",
      "Epoch 87/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.8212 - accuracy: 0.5121 - val_loss: 1.9763 - val_accuracy: 0.4183\n",
      "Epoch 88/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.8232 - accuracy: 0.5016 - val_loss: 1.9695 - val_accuracy: 0.4159\n",
      "Epoch 89/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8089 - accuracy: 0.5126 - val_loss: 1.9628 - val_accuracy: 0.4159\n",
      "Epoch 90/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8025 - accuracy: 0.5126 - val_loss: 1.9520 - val_accuracy: 0.4135\n",
      "Epoch 91/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.7867 - accuracy: 0.5194 - val_loss: 1.9479 - val_accuracy: 0.4135\n",
      "Epoch 92/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.7727 - accuracy: 0.5210 - val_loss: 1.9368 - val_accuracy: 0.4135\n",
      "Epoch 93/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.7778 - accuracy: 0.5163 - val_loss: 1.9315 - val_accuracy: 0.4135\n",
      "Epoch 94/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.7575 - accuracy: 0.5184 - val_loss: 1.9257 - val_accuracy: 0.4135\n",
      "Epoch 95/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.7496 - accuracy: 0.5163 - val_loss: 1.9171 - val_accuracy: 0.4159\n",
      "Epoch 96/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.7397 - accuracy: 0.5273 - val_loss: 1.9098 - val_accuracy: 0.4159\n",
      "Epoch 97/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.7317 - accuracy: 0.5252 - val_loss: 1.9042 - val_accuracy: 0.4183\n",
      "Epoch 98/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.7353 - accuracy: 0.5236 - val_loss: 1.8952 - val_accuracy: 0.4159\n",
      "Epoch 99/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.7277 - accuracy: 0.5373 - val_loss: 1.8882 - val_accuracy: 0.4279\n",
      "Epoch 100/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.7147 - accuracy: 0.5394 - val_loss: 1.8803 - val_accuracy: 0.4279\n",
      "Epoch 101/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.7142 - accuracy: 0.5336 - val_loss: 1.8742 - val_accuracy: 0.4231\n",
      "Epoch 102/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.7077 - accuracy: 0.5362 - val_loss: 1.8701 - val_accuracy: 0.4231\n",
      "Epoch 103/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.6919 - accuracy: 0.5404 - val_loss: 1.8608 - val_accuracy: 0.4255\n",
      "Epoch 104/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.6817 - accuracy: 0.5383 - val_loss: 1.8547 - val_accuracy: 0.4327\n",
      "Epoch 105/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.6748 - accuracy: 0.5347 - val_loss: 1.8483 - val_accuracy: 0.4351\n",
      "Epoch 106/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.6664 - accuracy: 0.5383 - val_loss: 1.8450 - val_accuracy: 0.4327\n",
      "Epoch 107/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.6572 - accuracy: 0.5431 - val_loss: 1.8358 - val_accuracy: 0.4375\n",
      "Epoch 108/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.6563 - accuracy: 0.5357 - val_loss: 1.8296 - val_accuracy: 0.4423\n",
      "Epoch 109/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.6450 - accuracy: 0.5431 - val_loss: 1.8218 - val_accuracy: 0.4447\n",
      "Epoch 110/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.6380 - accuracy: 0.5515 - val_loss: 1.8153 - val_accuracy: 0.4471\n",
      "Epoch 111/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.6282 - accuracy: 0.5557 - val_loss: 1.8092 - val_accuracy: 0.4471\n",
      "Epoch 112/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.6252 - accuracy: 0.5494 - val_loss: 1.8042 - val_accuracy: 0.4519\n",
      "Epoch 113/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.6220 - accuracy: 0.5446 - val_loss: 1.7980 - val_accuracy: 0.4471\n",
      "Epoch 114/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.6083 - accuracy: 0.5530 - val_loss: 1.7905 - val_accuracy: 0.4495\n",
      "Epoch 115/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.5994 - accuracy: 0.5593 - val_loss: 1.7885 - val_accuracy: 0.4447\n",
      "Epoch 116/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.5973 - accuracy: 0.5572 - val_loss: 1.7797 - val_accuracy: 0.4519\n",
      "Epoch 117/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.5833 - accuracy: 0.5625 - val_loss: 1.7754 - val_accuracy: 0.4543\n",
      "Epoch 118/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5796 - accuracy: 0.5562 - val_loss: 1.7682 - val_accuracy: 0.4543\n",
      "Epoch 119/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5746 - accuracy: 0.5625 - val_loss: 1.7607 - val_accuracy: 0.4495\n",
      "Epoch 120/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.5691 - accuracy: 0.5567 - val_loss: 1.7583 - val_accuracy: 0.4495\n",
      "Epoch 121/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5573 - accuracy: 0.5683 - val_loss: 1.7515 - val_accuracy: 0.4495\n",
      "Epoch 122/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5475 - accuracy: 0.5772 - val_loss: 1.7452 - val_accuracy: 0.4495\n",
      "Epoch 123/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5519 - accuracy: 0.5599 - val_loss: 1.7383 - val_accuracy: 0.4543\n",
      "Epoch 124/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5357 - accuracy: 0.5683 - val_loss: 1.7338 - val_accuracy: 0.4543\n",
      "Epoch 125/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.5353 - accuracy: 0.5725 - val_loss: 1.7326 - val_accuracy: 0.4495\n",
      "Epoch 126/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.5253 - accuracy: 0.5788 - val_loss: 1.7250 - val_accuracy: 0.4495\n",
      "Epoch 127/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.5169 - accuracy: 0.5730 - val_loss: 1.7192 - val_accuracy: 0.4543\n",
      "Epoch 128/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5162 - accuracy: 0.5751 - val_loss: 1.7158 - val_accuracy: 0.4543\n",
      "Epoch 129/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5048 - accuracy: 0.5651 - val_loss: 1.7106 - val_accuracy: 0.4543\n",
      "Epoch 130/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.5023 - accuracy: 0.5751 - val_loss: 1.7055 - val_accuracy: 0.4615\n",
      "Epoch 131/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.4881 - accuracy: 0.5798 - val_loss: 1.7009 - val_accuracy: 0.4543\n",
      "Epoch 132/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4820 - accuracy: 0.5767 - val_loss: 1.6961 - val_accuracy: 0.4615\n",
      "Epoch 133/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.4871 - accuracy: 0.5662 - val_loss: 1.6919 - val_accuracy: 0.4639\n",
      "Epoch 134/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4806 - accuracy: 0.5819 - val_loss: 1.6849 - val_accuracy: 0.4591\n",
      "Epoch 135/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.4688 - accuracy: 0.5777 - val_loss: 1.6810 - val_accuracy: 0.4639\n",
      "Epoch 136/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4619 - accuracy: 0.5924 - val_loss: 1.6780 - val_accuracy: 0.4663\n",
      "Epoch 137/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4620 - accuracy: 0.5783 - val_loss: 1.6748 - val_accuracy: 0.4663\n",
      "Epoch 138/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4562 - accuracy: 0.5819 - val_loss: 1.6691 - val_accuracy: 0.4615\n",
      "Epoch 139/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4457 - accuracy: 0.5909 - val_loss: 1.6630 - val_accuracy: 0.4639\n",
      "Epoch 140/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.4428 - accuracy: 0.5893 - val_loss: 1.6585 - val_accuracy: 0.4639\n",
      "Epoch 141/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4288 - accuracy: 0.5867 - val_loss: 1.6532 - val_accuracy: 0.4639\n",
      "Epoch 142/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4341 - accuracy: 0.5893 - val_loss: 1.6507 - val_accuracy: 0.4615\n",
      "Epoch 143/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4278 - accuracy: 0.5903 - val_loss: 1.6483 - val_accuracy: 0.4591\n",
      "Epoch 144/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.4132 - accuracy: 0.5867 - val_loss: 1.6473 - val_accuracy: 0.4495\n",
      "Epoch 145/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.4026 - accuracy: 0.5961 - val_loss: 1.6389 - val_accuracy: 0.4567\n",
      "Epoch 146/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.4074 - accuracy: 0.5882 - val_loss: 1.6326 - val_accuracy: 0.4639\n",
      "Epoch 147/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3952 - accuracy: 0.6003 - val_loss: 1.6331 - val_accuracy: 0.4567\n",
      "Epoch 148/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3956 - accuracy: 0.5872 - val_loss: 1.6280 - val_accuracy: 0.4567\n",
      "Epoch 149/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.3843 - accuracy: 0.5935 - val_loss: 1.6263 - val_accuracy: 0.4543\n",
      "Epoch 150/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.3931 - accuracy: 0.5840 - val_loss: 1.6203 - val_accuracy: 0.4639\n",
      "Epoch 151/500\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.3829 - accuracy: 0.5998 - val_loss: 1.6154 - val_accuracy: 0.4712\n",
      "Epoch 152/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.3631 - accuracy: 0.6019 - val_loss: 1.6151 - val_accuracy: 0.4615\n",
      "Epoch 153/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3678 - accuracy: 0.6050 - val_loss: 1.6070 - val_accuracy: 0.4688\n",
      "Epoch 154/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3575 - accuracy: 0.5956 - val_loss: 1.6061 - val_accuracy: 0.4688\n",
      "Epoch 155/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3552 - accuracy: 0.5966 - val_loss: 1.6021 - val_accuracy: 0.4736\n",
      "Epoch 156/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3576 - accuracy: 0.6098 - val_loss: 1.6031 - val_accuracy: 0.4688\n",
      "Epoch 157/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3525 - accuracy: 0.6056 - val_loss: 1.5959 - val_accuracy: 0.4639\n",
      "Epoch 158/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3416 - accuracy: 0.6061 - val_loss: 1.5937 - val_accuracy: 0.4736\n",
      "Epoch 159/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.3177 - accuracy: 0.6287 - val_loss: 1.5930 - val_accuracy: 0.4639\n",
      "Epoch 160/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3261 - accuracy: 0.6297 - val_loss: 1.5861 - val_accuracy: 0.4663\n",
      "Epoch 161/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.3155 - accuracy: 0.6134 - val_loss: 1.5824 - val_accuracy: 0.4688\n",
      "Epoch 162/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.3211 - accuracy: 0.6140 - val_loss: 1.5828 - val_accuracy: 0.4663\n",
      "Epoch 163/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.3076 - accuracy: 0.6197 - val_loss: 1.5753 - val_accuracy: 0.4688\n",
      "Epoch 164/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2999 - accuracy: 0.6313 - val_loss: 1.5761 - val_accuracy: 0.4688\n",
      "Epoch 165/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.3049 - accuracy: 0.6061 - val_loss: 1.5710 - val_accuracy: 0.4688\n",
      "Epoch 166/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2913 - accuracy: 0.6255 - val_loss: 1.5714 - val_accuracy: 0.4663\n",
      "Epoch 167/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2942 - accuracy: 0.6255 - val_loss: 1.5691 - val_accuracy: 0.4663\n",
      "Epoch 168/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2835 - accuracy: 0.6313 - val_loss: 1.5715 - val_accuracy: 0.4663\n",
      "Epoch 169/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.2830 - accuracy: 0.6245 - val_loss: 1.5629 - val_accuracy: 0.4639\n",
      "Epoch 170/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2717 - accuracy: 0.6245 - val_loss: 1.5602 - val_accuracy: 0.4712\n",
      "Epoch 171/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2738 - accuracy: 0.6355 - val_loss: 1.5629 - val_accuracy: 0.4639\n",
      "Epoch 172/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2701 - accuracy: 0.6224 - val_loss: 1.5583 - val_accuracy: 0.4736\n",
      "Epoch 173/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2533 - accuracy: 0.6376 - val_loss: 1.5528 - val_accuracy: 0.4663\n",
      "Epoch 174/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.2578 - accuracy: 0.6287 - val_loss: 1.5547 - val_accuracy: 0.4712\n",
      "Epoch 175/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2486 - accuracy: 0.6366 - val_loss: 1.5502 - val_accuracy: 0.4712\n",
      "Epoch 176/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2363 - accuracy: 0.6408 - val_loss: 1.5463 - val_accuracy: 0.4712\n",
      "Epoch 177/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2396 - accuracy: 0.6339 - val_loss: 1.5437 - val_accuracy: 0.4736\n",
      "Epoch 178/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2410 - accuracy: 0.6255 - val_loss: 1.5418 - val_accuracy: 0.4712\n",
      "Epoch 179/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2326 - accuracy: 0.6297 - val_loss: 1.5461 - val_accuracy: 0.4639\n",
      "Epoch 180/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2274 - accuracy: 0.6371 - val_loss: 1.5381 - val_accuracy: 0.4688\n",
      "Epoch 181/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2182 - accuracy: 0.6497 - val_loss: 1.5354 - val_accuracy: 0.4760\n",
      "Epoch 182/500\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 1.2302 - accuracy: 0.6381 - val_loss: 1.5330 - val_accuracy: 0.4615\n",
      "Epoch 183/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2112 - accuracy: 0.6339 - val_loss: 1.5292 - val_accuracy: 0.4688\n",
      "Epoch 184/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2070 - accuracy: 0.6481 - val_loss: 1.5323 - val_accuracy: 0.4639\n",
      "Epoch 185/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1995 - accuracy: 0.6597 - val_loss: 1.5270 - val_accuracy: 0.4639\n",
      "Epoch 186/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1906 - accuracy: 0.6471 - val_loss: 1.5257 - val_accuracy: 0.4663\n",
      "Epoch 187/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.1971 - accuracy: 0.6544 - val_loss: 1.5302 - val_accuracy: 0.4663\n",
      "Epoch 188/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1856 - accuracy: 0.6460 - val_loss: 1.5247 - val_accuracy: 0.4688\n",
      "Epoch 189/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1798 - accuracy: 0.6539 - val_loss: 1.5294 - val_accuracy: 0.4591\n",
      "Epoch 190/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1790 - accuracy: 0.6591 - val_loss: 1.5223 - val_accuracy: 0.4688\n",
      "Epoch 191/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1763 - accuracy: 0.6497 - val_loss: 1.5193 - val_accuracy: 0.4736\n",
      "Epoch 192/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.1687 - accuracy: 0.6607 - val_loss: 1.5187 - val_accuracy: 0.4760\n",
      "Epoch 193/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1587 - accuracy: 0.6707 - val_loss: 1.5153 - val_accuracy: 0.4688\n",
      "Epoch 194/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1691 - accuracy: 0.6486 - val_loss: 1.5143 - val_accuracy: 0.4808\n",
      "Epoch 195/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1527 - accuracy: 0.6476 - val_loss: 1.5163 - val_accuracy: 0.4832\n",
      "Epoch 196/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1466 - accuracy: 0.6691 - val_loss: 1.5133 - val_accuracy: 0.4904\n",
      "Epoch 197/500\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.1559 - accuracy: 0.6612 - val_loss: 1.5116 - val_accuracy: 0.4880\n",
      "Epoch 198/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1501 - accuracy: 0.6591 - val_loss: 1.5146 - val_accuracy: 0.4808\n",
      "Epoch 199/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1363 - accuracy: 0.6639 - val_loss: 1.5041 - val_accuracy: 0.4856\n",
      "Epoch 200/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1394 - accuracy: 0.6644 - val_loss: 1.5072 - val_accuracy: 0.4904\n",
      "Epoch 201/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1257 - accuracy: 0.6702 - val_loss: 1.5065 - val_accuracy: 0.4904\n",
      "Epoch 202/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1269 - accuracy: 0.6696 - val_loss: 1.5049 - val_accuracy: 0.4904\n",
      "Epoch 203/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1235 - accuracy: 0.6597 - val_loss: 1.5056 - val_accuracy: 0.5024\n",
      "Epoch 204/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1252 - accuracy: 0.6686 - val_loss: 1.5068 - val_accuracy: 0.4880\n",
      "Epoch 205/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1051 - accuracy: 0.6817 - val_loss: 1.5013 - val_accuracy: 0.4976\n",
      "Epoch 206/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1140 - accuracy: 0.6754 - val_loss: 1.5057 - val_accuracy: 0.4952\n",
      "Epoch 207/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.1054 - accuracy: 0.6728 - val_loss: 1.4999 - val_accuracy: 0.5024\n",
      "Epoch 208/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0977 - accuracy: 0.6833 - val_loss: 1.5006 - val_accuracy: 0.4976\n",
      "Epoch 209/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0924 - accuracy: 0.6849 - val_loss: 1.4945 - val_accuracy: 0.5072\n",
      "Epoch 210/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0894 - accuracy: 0.6833 - val_loss: 1.4981 - val_accuracy: 0.5000\n",
      "Epoch 211/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0932 - accuracy: 0.6786 - val_loss: 1.4945 - val_accuracy: 0.5048\n",
      "Epoch 212/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0773 - accuracy: 0.6859 - val_loss: 1.4905 - val_accuracy: 0.5024\n",
      "Epoch 213/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0827 - accuracy: 0.6801 - val_loss: 1.4934 - val_accuracy: 0.5048\n",
      "Epoch 214/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0808 - accuracy: 0.6854 - val_loss: 1.4940 - val_accuracy: 0.4976\n",
      "Epoch 215/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0779 - accuracy: 0.6812 - val_loss: 1.4903 - val_accuracy: 0.5024\n",
      "Epoch 216/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0735 - accuracy: 0.6801 - val_loss: 1.4916 - val_accuracy: 0.5048\n",
      "Epoch 217/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0654 - accuracy: 0.6896 - val_loss: 1.4944 - val_accuracy: 0.5000\n",
      "Epoch 218/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0605 - accuracy: 0.6959 - val_loss: 1.4888 - val_accuracy: 0.5048\n",
      "Epoch 219/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0643 - accuracy: 0.6891 - val_loss: 1.4911 - val_accuracy: 0.5048\n",
      "Epoch 220/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0435 - accuracy: 0.6943 - val_loss: 1.4884 - val_accuracy: 0.5048\n",
      "Epoch 221/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0565 - accuracy: 0.6912 - val_loss: 1.4867 - val_accuracy: 0.5048\n",
      "Epoch 222/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0473 - accuracy: 0.6891 - val_loss: 1.4863 - val_accuracy: 0.5024\n",
      "Epoch 223/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0428 - accuracy: 0.6849 - val_loss: 1.4887 - val_accuracy: 0.4976\n",
      "Epoch 224/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0394 - accuracy: 0.6907 - val_loss: 1.4837 - val_accuracy: 0.5024\n",
      "Epoch 225/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0443 - accuracy: 0.6849 - val_loss: 1.4865 - val_accuracy: 0.5048\n",
      "Epoch 226/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0275 - accuracy: 0.7038 - val_loss: 1.4833 - val_accuracy: 0.5048\n",
      "Epoch 227/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0289 - accuracy: 0.6949 - val_loss: 1.4854 - val_accuracy: 0.5000\n",
      "Epoch 228/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0212 - accuracy: 0.6907 - val_loss: 1.4808 - val_accuracy: 0.5072\n",
      "Epoch 229/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0165 - accuracy: 0.7048 - val_loss: 1.4816 - val_accuracy: 0.5072\n",
      "Epoch 230/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0087 - accuracy: 0.6975 - val_loss: 1.4792 - val_accuracy: 0.5144\n",
      "Epoch 231/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.0122 - accuracy: 0.7064 - val_loss: 1.4859 - val_accuracy: 0.5024\n",
      "Epoch 232/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0035 - accuracy: 0.7033 - val_loss: 1.4797 - val_accuracy: 0.5120\n",
      "Epoch 233/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0119 - accuracy: 0.6896 - val_loss: 1.4812 - val_accuracy: 0.5048\n",
      "Epoch 234/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0020 - accuracy: 0.7117 - val_loss: 1.4768 - val_accuracy: 0.5120\n",
      "Epoch 235/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9927 - accuracy: 0.7180 - val_loss: 1.4826 - val_accuracy: 0.5096\n",
      "Epoch 236/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9936 - accuracy: 0.7127 - val_loss: 1.4822 - val_accuracy: 0.5024\n",
      "Epoch 237/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9944 - accuracy: 0.7080 - val_loss: 1.4807 - val_accuracy: 0.5120\n",
      "Epoch 238/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9867 - accuracy: 0.7012 - val_loss: 1.4804 - val_accuracy: 0.5072\n",
      "Epoch 239/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9808 - accuracy: 0.7038 - val_loss: 1.4811 - val_accuracy: 0.5000\n",
      "Epoch 240/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9792 - accuracy: 0.7111 - val_loss: 1.4717 - val_accuracy: 0.5120\n",
      "Epoch 241/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9722 - accuracy: 0.7080 - val_loss: 1.4788 - val_accuracy: 0.4976\n",
      "Epoch 242/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.9687 - accuracy: 0.7258 - val_loss: 1.4777 - val_accuracy: 0.5096\n",
      "Epoch 243/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9678 - accuracy: 0.7132 - val_loss: 1.4786 - val_accuracy: 0.5048\n",
      "Epoch 244/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9619 - accuracy: 0.7232 - val_loss: 1.4813 - val_accuracy: 0.5048\n",
      "Epoch 245/500\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.9655 - accuracy: 0.7153 - val_loss: 1.4740 - val_accuracy: 0.5072\n",
      "Epoch 246/500\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9525 - accuracy: 0.7195 - val_loss: 1.4823 - val_accuracy: 0.4976\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"train\")\n",
    "\n",
    "\n",
    "#y_train_ohe  = one_hot_encoder(y_train)\n",
    "#y_valid_ohe = one_hot_encoder(y_valid)\n",
    "#y_test_ohe = one_hot_encoder(y_test)\n",
    "\n",
    "R = lstm.rnnLSTM(X_train, y_train_ohe, lr=0.001, dropout_rate=0.2, patience=6)\n",
    "R.train(X_train, y_train_ohe, X_valid, y_valid_ohe, epochs=500, batch_size=64)\n",
    "R.plot_learning_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2533 - accuracy: 0.5930\n",
      "Test Loss: 1.2532864809036255\n",
      "Test Accuracy: 0.5930232405662537\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "test_loss, test_accuracy = R.evaluate(X_test, y_test_ohe)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM con pythorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_size = 3       # Número de características de entrada\\nhidden_size = 64     # Número de características en el estado oculto\\nnum_classes = 8      # Número de clases de salida\\nnum_layers = 1       # Número de capas de la LSTM\\nlearning_rate = 0.001\\nbatch_size = 32\\nnum_epochs = 50\\n\\nX_train_batch, y_train_batch = DL.create_batches(X_train, y_train, batch_size)\\nlstm_ = LSTM2.LSTMClassifier(input_size, hidden_size, num_classes, num_layers)\\n\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.Adam(lstm_.parameters(), lr=learning_rate)\\nlstm_.train_model(X_train_batch, y_train_batch, criterion, optimizer, num_epochs=20)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"input_size = 3       # Número de características de entrada\n",
    "hidden_size = 64     # Número de características en el estado oculto\n",
    "num_classes = 8      # Número de clases de salida\n",
    "num_layers = 1       # Número de capas de la LSTM\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "X_train_batch, y_train_batch = DL.create_batches(X_train, y_train, batch_size)\n",
    "lstm_ = LSTM2.LSTMClassifier(input_size, hidden_size, num_classes, num_layers)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_.parameters(), lr=learning_rate)\n",
    "lstm_.train_model(X_train_batch, y_train_batch, criterion, optimizer, num_epochs=20)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"x, y, actors = AP.get_dataset([speech8_dataset])\n",
    "X_train, X_test, y_train, y_test, actors_train, actors_test = AP.split_dataset(x, y, test_size=0.2, actors=actors)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(actors_train.shape)\n",
    "print(actors_test.shape)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid, actors_train, actors_valid = AP.split_dataset(X_train, y_train, test_size=0.2, actors=actors_train)\n",
    "print(\"train:\", X_train.shape)\n",
    "print(\"valid:\", X_valid.shape)\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.show()\n",
    "\n",
    "y_train = one_hot_encoder(y_train)\n",
    "y_valid = one_hot_encoder(y_valid)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "shape_train = X_train.shape\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "X_train = X_train_scaled.reshape(shape_train[0], shape_train[1], shape_train[2])\n",
    "\n",
    "shape_valid = X_valid.shape\n",
    "X_val_reshaped = X_valid.reshape(-1, X_valid.shape[-1])\n",
    "X_val_scaled = scaler.transform(X_val_reshaped)\n",
    "X_val = X_val_scaled.reshape(shape_valid[0], shape_valid[1], shape_valid[2])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"y_test = one_hot_encoder(y_test)\n",
    "\n",
    "shape = X_test.shape\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "X_test_scaled = scaler.transform(X_test_reshaped)\n",
    "X_test = X_test_scaled.reshape(shape[0], shape[1], shape[2])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convertir las predicciones de one-hot encoding a etiquetas\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(y_pred_labels)\n",
    "print(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO CORRER, USAR Dataloader.get_dataset() y Dataloader.split_dataset()\n",
    "DL.process_dataset(speech_unprocessed_path, speech_dataset_path)\n",
    "DL.process_dataset(song_unprocessed_path, song_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir de aca el TEST no se toca mas.\n",
    "# Hay que hacer otra division del dev set para formar el train set y valid set.\n",
    "\n",
    "x_speech, y_speech, actors_speech = DL.get_dataset([speech_dataset_path])\n",
    "x_song, y_song, actors_song = DL.get_dataset([song_dataset_path])\n",
    "x_both, y_both, actors_both = DL.get_dataset([speech_dataset_path, song_dataset_path])\n",
    "\n",
    "# Estos son los datasets DIVIDIDOS POR ACTORES para el dev set y test set.\n",
    "X_speech_byactors_dev, X_speech_byactors_test, y_speech_byactors_dev, y_speech_byactors_test, actors_speech_dev, actors_speech_test = DL.split_dataset(x_speech, y_speech, actors_speech)\n",
    "X_song_byactors_dev, X_song_byactors_test, y_song_byactors_dev, y_song_byactors_test, actors_song_dev, actors_song_test = DL.split_dataset(x_song, y_song, actors_song)\n",
    "X_both_byactors_dev, X_both_byactors_test, y_both_byactors_dev, y_both_byactors_test, actors_both_dev, actors_both_test = DL.split_dataset(x_both, y_both, actors_both)\n",
    "\n",
    "# Estos son los datasets NO divididos por actores para el dev set y test set.\n",
    "X_speech_dev, X_speech_test, y_speech_dev, y_speech_test, _ , _ = DL.split_dataset(x_speech, y_speech)\n",
    "X_song_dev, X_song_test, y_song_dev, y_song_test, _ , _ = DL.split_dataset(x_song, y_song)\n",
    "X_both_dev, X_both_test, y_both_dev, y_both_test, _ , _ = DL.split_dataset(x_both, y_both)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVISION ENTRE TRAIN SET Y VALIDATION SET\n",
    "\n",
    "X_speech_byactors_train, X_speech_byactors_valid, y_speech_byactors_train, y_speech_byactors_valid, actors_speech_train, actors_speech_valid = DL.split_dataset(X_speech_byactors_dev, y_speech_byactors_dev, actors_speech_dev)\n",
    "X_song_byactors_train, X_song_byactors_valid, y_song_byactors_train, y_song_byactors_valid, actors_song_train, actors_song_valid = DL.split_dataset(X_song_byactors_dev, y_song_byactors_dev, actors_song_dev)\n",
    "X_both_byactors_train, X_both_byactors_valid, y_both_byactors_train, y_both_byactors_valid, actors_both_train, actors_both_valid = DL.split_dataset(X_both_byactors_dev, y_both_byactors_dev, actors_both_dev)\n",
    "\n",
    "X_speech_train, X_speech_valid, y_speech_train, y_speech_valid, _ , _ = DL.split_dataset(X_speech_dev, y_speech_dev)\n",
    "X_song_train, X_song_valid, y_song_train, y_song_valid, _ , _ = DL.split_dataset(X_song_dev, y_song_dev)\n",
    "X_both_train, X_both_valid, y_both_train, y_both_valid, _ , _ = DL.split_dataset(X_both_dev, y_both_dev)\n",
    "\n",
    "\n",
    "### habria que hacer una funcion que devuelva especificamente el train, valid del dataset que queremos. Ahora lo hice asi para ya tenerlos todos creados y poder probarlos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_norm = normalization(X_speech_byactors_train, np.mean(X_speech_byactors_train, axis=0), np.std(X_speech_byactors_train, axis=0))\n",
    "x_valid_norm = normalization(X_speech_byactors_valid, np.mean(X_speech_byactors_train, axis=0), np.std(X_speech_byactors_train, axis=0))\n",
    "print(x_train_norm.shape)\n",
    "print(x_valid_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_speech, classes_count_speech = np.unique(y_speech, return_counts=True)\n",
    "classes_song, classes_count_song = np.unique(y_song, return_counts=True)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4)) \n",
    "\n",
    "axs[0].bar(classes_speech, classes_count_speech)\n",
    "axs[0].set_title('Speech dataset')\n",
    "axs[0].set_xlabel('Clase')\n",
    "axs[0].set_ylabel('Cantidad de muestras')\n",
    "axs[0].set_xticks(classes_speech) \n",
    "\n",
    "axs[1].bar(classes_song, classes_count_song)\n",
    "axs[1].set_title('Song dataset')\n",
    "axs[1].set_xlabel('Clase')\n",
    "axs[1].set_ylabel('Cantidad de muestras')\n",
    "axs[1].set_xticks(classes_song)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#NOTE: There is no strong intensity for the 'neutral' emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y_speech))\n",
    "print(np.unique(y_song))\n",
    "\n",
    "# y_speech = y_speech.astype(int)\n",
    "# y_song = y_song.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_speech = StandardScaler()\n",
    "x_speech_scaled = scaler_speech.fit_transform(x_speech)\n",
    "\n",
    "scaler_song = StandardScaler()\n",
    "x_song_scaled = scaler_song.fit_transform(x_song)\n",
    "\n",
    "pca_speech = PCA(n_components=2)\n",
    "pca_speech_result = pca_speech.fit_transform(x_speech_scaled)\n",
    "pca_speech_df = pd.DataFrame(data=pca_speech_result, columns=['PCA1', 'PCA2'])\n",
    "pca_speech_df['Label'] = y_speech\n",
    "\n",
    "pca_song = PCA(n_components=2)\n",
    "pca_song_result = pca_song.fit_transform(x_song_scaled)\n",
    "pca_song_df = pd.DataFrame(data=pca_song_result, columns=['PCA1', 'PCA2'])\n",
    "pca_song_df['Label'] = y_song\n",
    "\n",
    "sns.scatterplot(x='PCA1', y='PCA2', hue='Label', data=pca_speech_df, palette='viridis')\n",
    "plt.title('PCA of Speech Features')\n",
    "plt.legend(title='Emotion')\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x='PCA1', y='PCA2', hue='Label', data=pca_song_df, palette='viridis')\n",
    "plt.title('PCA of Song Features')\n",
    "plt.legend(title='Emotion')\n",
    "plt.show()\n",
    "\n",
    "tsne_speech = TSNE(n_components=2, random_state=42)\n",
    "tsne_speech_result = tsne_speech.fit_transform(x_speech_scaled)\n",
    "tsne_speech_df = pd.DataFrame(data=tsne_speech_result, columns=['TSNE1', 'TSNE2'])\n",
    "tsne_speech_df['Label'] = y_speech\n",
    "\n",
    "tsne_song = TSNE(n_components=2, random_state=42)\n",
    "tsne_song_result = tsne_song.fit_transform(x_song_scaled)\n",
    "tsne_song_df = pd.DataFrame(data=tsne_song_result, columns=['TSNE1', 'TSNE2'])\n",
    "tsne_song_df['Label'] = y_song\n",
    "\n",
    "sns.scatterplot(x='TSNE1', y='TSNE2', hue='Label', data=tsne_speech_df, palette='viridis')\n",
    "plt.title('t-SNE of Speech Features')\n",
    "plt.legend(title='Emotion')\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x='TSNE1', y='TSNE2', hue='Label', data=tsne_song_df, palette='viridis')\n",
    "plt.title('t-SNE of Song Features')\n",
    "plt.legend(title='Emotion')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filename identifiers \n",
    "\n",
    "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "* Vocal channel (01 = speech, 02 = song).\n",
    "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_both_train, X_both_test, y_both_train, y_both_test\n",
    "\n",
    "num_trees = range(150, 200)\n",
    "max_depth = range(3, 9, 2)\n",
    "tree_model_accuracy = []\n",
    "opt_md = 0\n",
    "opt_n = 0\n",
    "for md in range(len(max_depth)):\n",
    "    for n in range(len(num_trees)):\n",
    "        random_forest = RandomForestClassifier(n_estimators=num_trees[n], max_depth=max_depth[md],random_state= 32)\n",
    "        random_forest.fit(X_speech_train, y_speech_train)\n",
    "        y_predict = random_forest.predict(X_speech_test)\n",
    "        acc = accuracy_score(y_speech_test, y_predict)\n",
    "        tree_model_accuracy.append(acc)\n",
    "        if np.max(tree_model_accuracy) == acc:\n",
    "            opt_md = md\n",
    "            opt_n = n\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"opt md: {max_depth[opt_md]}, opt n: {num_trees[opt_n]}\")\n",
    "print(f\"Max accuracy: {np.max(tree_model_accuracy)}\")\n",
    "plt.plot(range(len(tree_model_accuracy)), tree_model_accuracy)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier( random_state= 32)\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_predict = random_forest.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_predict)\n",
    "print(f\" trees --> Accuracy {acc}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAutoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(MLPAutoencoder, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Linear(88, encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim, 88)\n",
    "        #self.unflatten = torch.nn.Unflatten(1, 88)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        out = F.relu(self.encoder(x))\n",
    "        out = torch.sigmoid(self.decoder(out))\n",
    "        return out\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        return F.relu(self.encoder(x))\n",
    "d = torch.from_numpy(x_train)\n",
    "print(d.shape)\n",
    "print(nn.Flatten(d))\n",
    "print(d[0].shape)\n",
    "print(d)\n",
    "print(d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPAutoencoder(33).double()\n",
    "pred = model(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.1\n",
    "device = \"cpu\"\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "n_epochs = 20\n",
    "model.to(device)\n",
    "t_losses, v_losses = [], []\n",
    "x_train_tensor = torch.from_numpy(x_train_norm)\n",
    "x_test_tensor = torch.from_numpy(x_test_norm)\n",
    "\n",
    "for epoch in tqdm(range(1, n_epochs+1)):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    for (X, y) in zip(x_train_tensor, y_train):\n",
    "        X = torch.squeeze(X).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "            \n",
    "    # Eval        \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in zip(x_test_tensor, y_test):\n",
    "            X = torch.squeeze(X).to(device)\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, X)\n",
    "            test_loss += loss.item()        \n",
    "            \n",
    "    train_loss = train_loss/len(x_train)\n",
    "    test_loss = test_loss/len(x_test)\n",
    "    t_losses.append(train_loss)\n",
    "    v_losses.append(test_loss)\n",
    "    \n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(np.arange(1,len(t_losses)+1), t_losses, label='Train loss')\n",
    "plt.plot(np.arange(1,len(v_losses)+1),v_losses, label='Validation loss')\n",
    "plt.xticks(np.arange(1,len(t_losses)+1))\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales\n",
    "\n",
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "emotion_labels = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "def extract_spectrogram(audio_path, sr=22050, n_mels=224, fmax=8000):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    return log_spectrogram\n",
    "\n",
    "def save_spectrogram(spectrogram, save_path):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    librosa.display.specshow(spectrogram, sr=22050, x_axis='time', y_axis='mel', fmax=8000)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "def process_files(files, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    for audio_path in files:\n",
    "        filename = os.path.basename(audio_path)\n",
    "        emotion_code = filename.split('-')[2] \n",
    "        emotion = emotion_labels.get(emotion_code, 'unknown')\n",
    "        \n",
    "        class_dir = os.path.join(output_path, emotion)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "        \n",
    "        spectrogram = extract_spectrogram(audio_path)\n",
    "        save_path = os.path.join(class_dir, filename.replace('.wav', '.png'))\n",
    "        save_spectrogram(spectrogram, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path = \"data/data_dev/speech/*/*.wav\"\n",
    "test_path = \"data/data_test/speech/*/*.wav\"\n",
    "\n",
    "files = glob(dev_path)\n",
    "output_path = \"data/spectrograms/speech\"\n",
    "process_files(files, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 28 * 28, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 32 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "momentum = 0.8\n",
    "epochs = 20\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=output_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model = CNN()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(dataloader, 0):\n",
    "#         inputs, labels = data\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#         if i % 10 == 9:  \n",
    "#             print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 10:.3f}\")\n",
    "#             running_loss = 0.0\n",
    "\n",
    "model = CNN()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99: \n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "CUDA is not available. Ensure that you have installed the correct drivers and CUDA version.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob(test_path)\n",
    "test_output_path = \"data/spectrograms_test/speech\"\n",
    "process_files(test_files, test_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 13.333333333333334%\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n",
      "[[0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]\n",
      " [0.2797081  0.10289886 0.10289886 0.10289886 0.10289886 0.10289886\n",
      "  0.10289886 0.10289886]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.ImageFolder(root=test_output_path, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        print(probabilities.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'emotion_net.pth')\n",
    "\n",
    "# model.load_state_dict(torch.load('emotion_net.pth'))\n",
    "# model.eval()\n",
    "\n",
    "# test_dataset = datasets.ImageFolder(root=\"pathdeltest\", transform=transform)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in test_dataloader:\n",
    "#         images, labels = data\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f'Accuracy of the network on the test images: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN_X(Model):\n",
    "#     def __init__(self):\n",
    "#         super(CNN_X, self).__init__()\n",
    "#         self.conv1 = Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 1))\n",
    "#         self.avgpool1 = AveragePooling2D(pool_size=(2, 2))\n",
    "#         self.conv2 = Conv2D(16, kernel_size=(3, 3), activation='relu')\n",
    "#         self.avgpool2 = AveragePooling2D(pool_size=(2, 2))\n",
    "#         self.conv3 = Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "#         self.avgpool3 = AveragePooling2D(pool_size=(2, 2))\n",
    "#         self.flatten = Flatten()\n",
    "#         self.fc1 = Dense(2048, activation='relu')\n",
    "#         self.fc2 = Dense(2048, activation='relu')\n",
    "#         self.fc3 = Dense(8, activation='softmax')\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x = self.conv1(inputs)\n",
    "#         x = self.avgpool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.avgpool2(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.avgpool3(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return self.fc3(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
